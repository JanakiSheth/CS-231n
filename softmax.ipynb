{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "    \n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_test, y_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **cs231n/classifiers/softmax.py**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.342041\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs231n/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: 0.202928 analytic: 0.202928, relative error: 3.076489e-07\n",
      "numerical: -0.605186 analytic: -0.605187, relative error: 2.534313e-08\n",
      "numerical: 1.141405 analytic: 1.141405, relative error: 1.089222e-08\n",
      "numerical: 0.666348 analytic: 0.666347, relative error: 4.503819e-08\n",
      "numerical: -0.285008 analytic: -0.285008, relative error: 3.920443e-08\n",
      "numerical: -0.687791 analytic: -0.687791, relative error: 1.662353e-08\n",
      "numerical: 1.177700 analytic: 1.177700, relative error: 1.284297e-08\n",
      "numerical: -0.796385 analytic: -0.796385, relative error: 6.790314e-08\n",
      "numerical: -4.449977 analytic: -4.449977, relative error: 1.411990e-08\n",
      "numerical: -1.322764 analytic: -1.322764, relative error: 4.024968e-08\n",
      "numerical: 4.336077 analytic: 4.336077, relative error: 2.639210e-09\n",
      "numerical: -6.254694 analytic: -6.254694, relative error: 1.179826e-10\n",
      "numerical: 1.626069 analytic: 1.626069, relative error: 3.967857e-08\n",
      "numerical: -3.143679 analytic: -3.143679, relative error: 2.347331e-08\n",
      "numerical: 1.536981 analytic: 1.536981, relative error: 2.728865e-08\n",
      "numerical: 3.802893 analytic: 3.802892, relative error: 1.295862e-08\n",
      "numerical: 3.714503 analytic: 3.714503, relative error: 4.199767e-09\n",
      "numerical: 4.344348 analytic: 4.344347, relative error: 9.019013e-10\n",
      "numerical: 1.009061 analytic: 1.009061, relative error: 8.823123e-09\n",
      "numerical: 0.999194 analytic: 0.999194, relative error: 3.481546e-08\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 2.342041e+00 computed in 0.059948s\n",
      "vectorized loss: 2.342041e+00 computed in 0.013995s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-07 10.0 [0.2335918367346939, 0.231]\n",
      "1e-07 110.0 [0.2294081632653061, 0.242]\n",
      "1e-07 210.0 [0.2370612244897959, 0.233]\n",
      "1e-07 310.0 [0.2297142857142857, 0.237]\n",
      "1e-07 410.0 [0.22957142857142857, 0.225]\n",
      "1e-07 510.0 [0.23679591836734695, 0.244]\n",
      "1e-07 610.0 [0.2383265306122449, 0.253]\n",
      "1e-07 710.0 [0.22920408163265307, 0.233]\n",
      "1e-07 810.0 [0.2399387755102041, 0.239]\n",
      "1e-07 910.0 [0.24020408163265305, 0.259]\n",
      "1e-07 1010.0 [0.21914285714285714, 0.214]\n",
      "1e-07 1110.0 [0.23551020408163265, 0.227]\n",
      "1e-07 1210.0 [0.2267142857142857, 0.225]\n",
      "1e-07 1310.0 [0.2426734693877551, 0.234]\n",
      "1e-07 1410.0 [0.23948979591836736, 0.255]\n",
      "1e-07 1510.0 [0.22995918367346938, 0.239]\n",
      "1e-07 1610.0 [0.2317551020408163, 0.24]\n",
      "1e-07 1710.0 [0.24385714285714286, 0.249]\n",
      "1e-07 1810.0 [0.23485714285714285, 0.206]\n",
      "1e-07 1910.0 [0.23604081632653062, 0.272]\n",
      "1e-07 2010.0 [0.23281632653061224, 0.24]\n",
      "1e-07 2110.0 [0.24728571428571428, 0.255]\n",
      "1e-07 2210.0 [0.24287755102040817, 0.245]\n",
      "1e-07 2310.0 [0.24314285714285713, 0.247]\n",
      "1e-07 2410.0 [0.24471428571428572, 0.241]\n",
      "1e-07 2510.0 [0.24508163265306124, 0.255]\n",
      "1e-07 2610.0 [0.23685714285714285, 0.257]\n",
      "1e-07 2710.0 [0.24289795918367346, 0.249]\n",
      "1e-07 2810.0 [0.24555102040816326, 0.24]\n",
      "1e-07 2910.0 [0.23918367346938776, 0.228]\n",
      "1e-07 3010.0 [0.23785714285714285, 0.25]\n",
      "1e-07 3110.0 [0.24414285714285713, 0.249]\n",
      "1e-07 3210.0 [0.23677551020408164, 0.228]\n",
      "1e-07 3310.0 [0.24251020408163265, 0.25]\n",
      "1e-07 3410.0 [0.25255102040816324, 0.264]\n",
      "1e-07 3510.0 [0.24951020408163266, 0.264]\n",
      "1e-07 3610.0 [0.24912244897959185, 0.27]\n",
      "1e-07 3710.0 [0.2510816326530612, 0.254]\n",
      "1e-07 3810.0 [0.25295918367346937, 0.258]\n",
      "1e-07 3910.0 [0.24453061224489797, 0.248]\n",
      "1e-07 4010.0 [0.2507142857142857, 0.283]\n",
      "1e-07 4110.0 [0.2460816326530612, 0.236]\n",
      "1e-07 4210.0 [0.26077551020408163, 0.27]\n",
      "1e-07 4310.0 [0.25018367346938775, 0.25]\n",
      "1e-07 4410.0 [0.24875510204081633, 0.244]\n",
      "1e-07 4510.0 [0.25516326530612243, 0.259]\n",
      "1e-07 4610.0 [0.24240816326530612, 0.225]\n",
      "1e-07 4710.0 [0.26042857142857145, 0.262]\n",
      "1e-07 4810.0 [0.25318367346938775, 0.245]\n",
      "1e-07 4910.0 [0.24893877551020407, 0.26]\n",
      "1e-07 5010.0 [0.2543061224489796, 0.286]\n",
      "1e-07 5110.0 [0.26516326530612244, 0.268]\n",
      "1e-07 5210.0 [0.26155102040816325, 0.277]\n",
      "1e-07 5310.0 [0.26081632653061226, 0.256]\n",
      "1e-07 5410.0 [0.2583061224489796, 0.27]\n",
      "1e-07 5510.0 [0.2644285714285714, 0.261]\n",
      "1e-07 5610.0 [0.25951020408163267, 0.256]\n",
      "1e-07 5710.0 [0.26040816326530614, 0.265]\n",
      "1e-07 5810.0 [0.25873469387755105, 0.239]\n",
      "1e-07 5910.0 [0.2696734693877551, 0.285]\n",
      "1e-07 6010.0 [0.26140816326530614, 0.249]\n",
      "1e-07 6110.0 [0.261734693877551, 0.248]\n",
      "1e-07 6210.0 [0.2683265306122449, 0.27]\n",
      "1e-07 6310.0 [0.26571428571428574, 0.276]\n",
      "1e-07 6410.0 [0.2639183673469388, 0.257]\n",
      "1e-07 6510.0 [0.25918367346938775, 0.263]\n",
      "1e-07 6610.0 [0.2640408163265306, 0.261]\n",
      "1e-07 6710.0 [0.2736938775510204, 0.273]\n",
      "1e-07 6810.0 [0.26253061224489793, 0.275]\n",
      "1e-07 6910.0 [0.26493877551020406, 0.258]\n",
      "1e-07 7010.0 [0.2739795918367347, 0.303]\n",
      "1e-07 7110.0 [0.2601428571428571, 0.276]\n",
      "1e-07 7210.0 [0.27122448979591834, 0.283]\n",
      "1e-07 7310.0 [0.26510204081632655, 0.265]\n",
      "1e-07 7410.0 [0.26563265306122447, 0.273]\n",
      "1e-07 7510.0 [0.269265306122449, 0.267]\n",
      "1e-07 7610.0 [0.2718979591836735, 0.283]\n",
      "1e-07 7710.0 [0.26655102040816325, 0.275]\n",
      "1e-07 7810.0 [0.2795714285714286, 0.264]\n",
      "1e-07 7910.0 [0.28253061224489795, 0.273]\n",
      "1e-07 8010.0 [0.275, 0.271]\n",
      "1e-07 8110.0 [0.2715102040816327, 0.276]\n",
      "1e-07 8210.0 [0.28283673469387755, 0.27]\n",
      "1e-07 8310.0 [0.26753061224489794, 0.277]\n",
      "1e-07 8410.0 [0.26971428571428574, 0.289]\n",
      "1e-07 8510.0 [0.2751224489795918, 0.289]\n",
      "1e-07 8610.0 [0.2759795918367347, 0.274]\n",
      "1e-07 8710.0 [0.2773673469387755, 0.273]\n",
      "1e-07 8810.0 [0.28191836734693876, 0.278]\n",
      "1e-07 8910.0 [0.27808163265306124, 0.269]\n",
      "1e-07 9010.0 [0.2763673469387755, 0.286]\n",
      "1e-07 9110.0 [0.2830612244897959, 0.279]\n",
      "1e-07 9210.0 [0.28438775510204084, 0.3]\n",
      "1e-07 9310.0 [0.29185714285714287, 0.283]\n",
      "1e-07 9410.0 [0.28077551020408165, 0.255]\n",
      "1e-07 9510.0 [0.2863673469387755, 0.306]\n",
      "1e-07 9610.0 [0.28246938775510205, 0.302]\n",
      "1e-07 9710.0 [0.28461224489795917, 0.31]\n",
      "1e-07 9810.0 [0.2913877551020408, 0.273]\n",
      "1e-07 9910.0 [0.2862857142857143, 0.308]\n",
      "6e-07 10.0 [0.308, 0.317]\n",
      "6e-07 110.0 [0.312, 0.312]\n",
      "6e-07 210.0 [0.31748979591836735, 0.303]\n",
      "6e-07 310.0 [0.3202244897959184, 0.328]\n",
      "6e-07 410.0 [0.3215918367346939, 0.305]\n",
      "6e-07 510.0 [0.3225918367346939, 0.33]\n",
      "6e-07 610.0 [0.3323877551020408, 0.321]\n",
      "6e-07 710.0 [0.33324489795918366, 0.32]\n",
      "6e-07 810.0 [0.33848979591836736, 0.349]\n",
      "6e-07 910.0 [0.34444897959183673, 0.358]\n",
      "6e-07 1010.0 [0.3441836734693878, 0.338]\n",
      "6e-07 1110.0 [0.34730612244897957, 0.345]\n",
      "6e-07 1210.0 [0.35153061224489796, 0.343]\n",
      "6e-07 1310.0 [0.35677551020408166, 0.369]\n",
      "6e-07 1410.0 [0.35983673469387756, 0.375]\n",
      "6e-07 1510.0 [0.36306122448979594, 0.375]\n",
      "6e-07 1610.0 [0.36306122448979594, 0.361]\n",
      "6e-07 1710.0 [0.3638571428571429, 0.374]\n",
      "6e-07 1810.0 [0.3697142857142857, 0.364]\n",
      "6e-07 1910.0 [0.3703061224489796, 0.375]\n",
      "6e-07 2010.0 [0.3777142857142857, 0.369]\n",
      "6e-07 2110.0 [0.37495918367346937, 0.388]\n",
      "6e-07 2210.0 [0.3783265306122449, 0.399]\n",
      "6e-07 2310.0 [0.37714285714285717, 0.382]\n",
      "6e-07 2410.0 [0.3803469387755102, 0.377]\n",
      "6e-07 2510.0 [0.38340816326530613, 0.379]\n",
      "6e-07 2610.0 [0.38295918367346937, 0.391]\n",
      "6e-07 2710.0 [0.3836122448979592, 0.388]\n",
      "6e-07 2810.0 [0.3839183673469388, 0.38]\n",
      "6e-07 2910.0 [0.38173469387755105, 0.389]\n",
      "6e-07 3010.0 [0.38393877551020406, 0.391]\n",
      "6e-07 3110.0 [0.3822857142857143, 0.396]\n",
      "6e-07 3210.0 [0.38777551020408163, 0.402]\n",
      "6e-07 3310.0 [0.3878367346938775, 0.383]\n",
      "6e-07 3410.0 [0.38655102040816325, 0.379]\n",
      "6e-07 3510.0 [0.385530612244898, 0.37]\n",
      "6e-07 3610.0 [0.38816326530612244, 0.403]\n",
      "6e-07 3710.0 [0.3889591836734694, 0.392]\n",
      "6e-07 3810.0 [0.3842857142857143, 0.403]\n",
      "6e-07 3910.0 [0.3869183673469388, 0.391]\n",
      "6e-07 4010.0 [0.38677551020408163, 0.403]\n",
      "6e-07 4110.0 [0.3856326530612245, 0.401]\n",
      "6e-07 4210.0 [0.387, 0.398]\n",
      "6e-07 4310.0 [0.38616326530612244, 0.397]\n",
      "6e-07 4410.0 [0.38681632653061226, 0.396]\n",
      "6e-07 4510.0 [0.388, 0.392]\n",
      "6e-07 4610.0 [0.3850612244897959, 0.395]\n",
      "6e-07 4710.0 [0.3856326530612245, 0.388]\n",
      "6e-07 4810.0 [0.3849795918367347, 0.401]\n",
      "6e-07 4910.0 [0.3818367346938776, 0.396]\n",
      "6e-07 5010.0 [0.38657142857142857, 0.403]\n",
      "6e-07 5110.0 [0.3850816326530612, 0.396]\n",
      "6e-07 5210.0 [0.3866938775510204, 0.384]\n",
      "6e-07 5310.0 [0.38085714285714284, 0.389]\n",
      "6e-07 5410.0 [0.37920408163265307, 0.389]\n",
      "6e-07 5510.0 [0.3882857142857143, 0.389]\n",
      "6e-07 5610.0 [0.3838979591836735, 0.39]\n",
      "6e-07 5710.0 [0.38273469387755105, 0.397]\n",
      "6e-07 5810.0 [0.3853265306122449, 0.396]\n",
      "6e-07 5910.0 [0.38010204081632654, 0.379]\n",
      "6e-07 6010.0 [0.38081632653061226, 0.38]\n",
      "6e-07 6110.0 [0.378469387755102, 0.386]\n",
      "6e-07 6210.0 [0.38110204081632654, 0.393]\n",
      "6e-07 6310.0 [0.38124489795918365, 0.391]\n",
      "6e-07 6410.0 [0.37995918367346937, 0.388]\n",
      "6e-07 6510.0 [0.3801428571428571, 0.391]\n",
      "6e-07 6610.0 [0.38085714285714284, 0.377]\n",
      "6e-07 6710.0 [0.38212244897959186, 0.382]\n",
      "6e-07 6810.0 [0.3798367346938776, 0.391]\n",
      "6e-07 6910.0 [0.3754081632653061, 0.398]\n",
      "6e-07 7010.0 [0.3786938775510204, 0.401]\n",
      "6e-07 7110.0 [0.37926530612244896, 0.393]\n",
      "6e-07 7210.0 [0.3769387755102041, 0.388]\n",
      "6e-07 7310.0 [0.37920408163265307, 0.384]\n",
      "6e-07 7410.0 [0.3790204081632653, 0.394]\n",
      "6e-07 7510.0 [0.3732448979591837, 0.374]\n",
      "6e-07 7610.0 [0.37726530612244896, 0.376]\n",
      "6e-07 7710.0 [0.37520408163265306, 0.391]\n",
      "6e-07 7810.0 [0.37620408163265306, 0.388]\n",
      "6e-07 7910.0 [0.3763673469387755, 0.382]\n",
      "6e-07 8010.0 [0.38018367346938775, 0.378]\n",
      "6e-07 8110.0 [0.37381632653061225, 0.38]\n",
      "6e-07 8210.0 [0.37389795918367347, 0.4]\n",
      "6e-07 8310.0 [0.37485714285714283, 0.375]\n",
      "6e-07 8410.0 [0.37344897959183676, 0.39]\n",
      "6e-07 8510.0 [0.37181632653061225, 0.387]\n",
      "6e-07 8610.0 [0.3730204081632653, 0.389]\n",
      "6e-07 8710.0 [0.3760204081632653, 0.386]\n",
      "6e-07 8810.0 [0.3688571428571429, 0.374]\n",
      "6e-07 8910.0 [0.3689183673469388, 0.379]\n",
      "6e-07 9010.0 [0.37420408163265306, 0.389]\n",
      "6e-07 9110.0 [0.375, 0.381]\n",
      "6e-07 9210.0 [0.3709795918367347, 0.378]\n",
      "6e-07 9310.0 [0.37018367346938774, 0.385]\n",
      "6e-07 9410.0 [0.37087755102040815, 0.383]\n",
      "6e-07 9510.0 [0.37418367346938775, 0.387]\n",
      "6e-07 9610.0 [0.3701020408163265, 0.38]\n",
      "6e-07 9710.0 [0.3736122448979592, 0.388]\n",
      "6e-07 9810.0 [0.3747142857142857, 0.391]\n",
      "6e-07 9910.0 [0.3699387755102041, 0.376]\n",
      "1.1e-06 10.0 [0.33185714285714285, 0.319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1e-06 110.0 [0.3403265306122449, 0.355]\n",
      "1.1e-06 210.0 [0.3475714285714286, 0.343]\n",
      "1.1e-06 310.0 [0.35914285714285715, 0.343]\n",
      "1.1e-06 410.0 [0.3610408163265306, 0.366]\n",
      "1.1e-06 510.0 [0.3686734693877551, 0.367]\n",
      "1.1e-06 610.0 [0.37151020408163266, 0.362]\n",
      "1.1e-06 710.0 [0.3816734693877551, 0.373]\n",
      "1.1e-06 810.0 [0.3813877551020408, 0.383]\n",
      "1.1e-06 910.0 [0.3825918367346939, 0.386]\n",
      "1.1e-06 1010.0 [0.3882244897959184, 0.401]\n",
      "1.1e-06 1110.0 [0.3912040816326531, 0.387]\n",
      "1.1e-06 1210.0 [0.3894285714285714, 0.382]\n",
      "1.1e-06 1310.0 [0.3930612244897959, 0.393]\n",
      "1.1e-06 1410.0 [0.3922857142857143, 0.397]\n",
      "1.1e-06 1510.0 [0.3923673469387755, 0.388]\n",
      "1.1e-06 1610.0 [0.39514285714285713, 0.396]\n",
      "1.1e-06 1710.0 [0.39485714285714285, 0.385]\n",
      "1.1e-06 1810.0 [0.39577551020408164, 0.385]\n",
      "1.1e-06 1910.0 [0.398734693877551, 0.4]\n",
      "1.1e-06 2010.0 [0.39548979591836736, 0.395]\n",
      "1.1e-06 2110.0 [0.3969591836734694, 0.398]\n",
      "1.1e-06 2210.0 [0.3970204081632653, 0.398]\n",
      "1.1e-06 2310.0 [0.39687755102040817, 0.391]\n",
      "1.1e-06 2410.0 [0.3963265306122449, 0.398]\n",
      "1.1e-06 2510.0 [0.39371428571428574, 0.4]\n",
      "1.1e-06 2610.0 [0.3942040816326531, 0.392]\n",
      "1.1e-06 2710.0 [0.3933469387755102, 0.385]\n",
      "1.1e-06 2810.0 [0.3876530612244898, 0.399]\n",
      "1.1e-06 2910.0 [0.3948979591836735, 0.391]\n",
      "1.1e-06 3010.0 [0.38781632653061227, 0.386]\n",
      "1.1e-06 3110.0 [0.3860408163265306, 0.407]\n",
      "1.1e-06 3210.0 [0.3914489795918367, 0.412]\n",
      "1.1e-06 3310.0 [0.3919795918367347, 0.374]\n",
      "1.1e-06 3410.0 [0.38785714285714284, 0.403]\n",
      "1.1e-06 3510.0 [0.3880612244897959, 0.398]\n",
      "1.1e-06 3610.0 [0.38857142857142857, 0.393]\n",
      "1.1e-06 3710.0 [0.3870816326530612, 0.391]\n",
      "1.1e-06 3810.0 [0.38751020408163267, 0.375]\n",
      "1.1e-06 3910.0 [0.3893877551020408, 0.392]\n",
      "1.1e-06 4010.0 [0.3859183673469388, 0.393]\n",
      "1.1e-06 4110.0 [0.3827755102040816, 0.387]\n",
      "1.1e-06 4210.0 [0.38610204081632654, 0.409]\n",
      "1.1e-06 4310.0 [0.3896530612244898, 0.391]\n",
      "1.1e-06 4410.0 [0.3868979591836735, 0.386]\n",
      "1.1e-06 4510.0 [0.38257142857142856, 0.399]\n",
      "1.1e-06 4610.0 [0.38357142857142856, 0.39]\n",
      "1.1e-06 4710.0 [0.38210204081632654, 0.4]\n",
      "1.1e-06 4810.0 [0.38112244897959185, 0.395]\n",
      "1.1e-06 4910.0 [0.38626530612244897, 0.381]\n",
      "1.1e-06 5010.0 [0.3816122448979592, 0.393]\n",
      "1.1e-06 5110.0 [0.37985714285714284, 0.381]\n",
      "1.1e-06 5210.0 [0.3812857142857143, 0.382]\n",
      "1.1e-06 5310.0 [0.3829795918367347, 0.398]\n",
      "1.1e-06 5410.0 [0.3786734693877551, 0.376]\n",
      "1.1e-06 5510.0 [0.3807551020408163, 0.386]\n",
      "1.1e-06 5610.0 [0.3797551020408163, 0.372]\n",
      "1.1e-06 5710.0 [0.37714285714285717, 0.393]\n",
      "1.1e-06 5810.0 [0.37689795918367347, 0.393]\n",
      "1.1e-06 5910.0 [0.37283673469387757, 0.364]\n",
      "1.1e-06 6010.0 [0.37081632653061225, 0.382]\n",
      "1.1e-06 6110.0 [0.37179591836734693, 0.387]\n",
      "1.1e-06 6210.0 [0.3776938775510204, 0.376]\n",
      "1.1e-06 6310.0 [0.36912244897959184, 0.37]\n",
      "1.1e-06 6410.0 [0.37404081632653063, 0.381]\n",
      "1.1e-06 6510.0 [0.3763265306122449, 0.386]\n",
      "1.1e-06 6610.0 [0.37295918367346936, 0.375]\n",
      "1.1e-06 6710.0 [0.37583673469387757, 0.39]\n",
      "1.1e-06 6810.0 [0.37451020408163266, 0.388]\n",
      "1.1e-06 6910.0 [0.3701632653061224, 0.369]\n",
      "1.1e-06 7010.0 [0.37712244897959185, 0.39]\n",
      "1.1e-06 7110.0 [0.3673061224489796, 0.373]\n",
      "1.1e-06 7210.0 [0.3766122448979592, 0.39]\n",
      "1.1e-06 7310.0 [0.3776122448979592, 0.392]\n",
      "1.1e-06 7410.0 [0.37365306122448977, 0.378]\n",
      "1.1e-06 7510.0 [0.37285714285714283, 0.381]\n",
      "1.1e-06 7610.0 [0.3703469387755102, 0.385]\n",
      "1.1e-06 7710.0 [0.3750816326530612, 0.391]\n",
      "1.1e-06 7810.0 [0.37520408163265306, 0.382]\n",
      "1.1e-06 7910.0 [0.35859183673469386, 0.369]\n",
      "1.1e-06 8010.0 [0.36918367346938774, 0.372]\n",
      "1.1e-06 8110.0 [0.3682244897959184, 0.373]\n",
      "1.1e-06 8210.0 [0.36687755102040814, 0.369]\n",
      "1.1e-06 8310.0 [0.3739795918367347, 0.392]\n",
      "1.1e-06 8410.0 [0.3686326530612245, 0.379]\n",
      "1.1e-06 8510.0 [0.37173469387755104, 0.377]\n",
      "1.1e-06 8610.0 [0.37314285714285716, 0.381]\n",
      "1.1e-06 8710.0 [0.3730612244897959, 0.388]\n",
      "1.1e-06 8810.0 [0.3689591836734694, 0.38]\n",
      "1.1e-06 8910.0 [0.3662448979591837, 0.362]\n",
      "1.1e-06 9010.0 [0.3653877551020408, 0.372]\n",
      "1.1e-06 9110.0 [0.37226530612244896, 0.392]\n",
      "1.1e-06 9210.0 [0.3656326530612245, 0.378]\n",
      "1.1e-06 9310.0 [0.3712857142857143, 0.364]\n",
      "1.1e-06 9410.0 [0.36957142857142855, 0.381]\n",
      "1.1e-06 9510.0 [0.3663877551020408, 0.382]\n",
      "1.1e-06 9610.0 [0.36606122448979594, 0.381]\n",
      "1.1e-06 9710.0 [0.36289795918367346, 0.361]\n",
      "1.1e-06 9810.0 [0.37087755102040815, 0.388]\n",
      "1.1e-06 9910.0 [0.37173469387755104, 0.38]\n",
      "1.6e-06 10.0 [0.3402857142857143, 0.337]\n",
      "1.6e-06 110.0 [0.36387755102040814, 0.364]\n",
      "1.6e-06 210.0 [0.3646530612244898, 0.349]\n",
      "1.6e-06 310.0 [0.3756734693877551, 0.35]\n",
      "1.6e-06 410.0 [0.3846938775510204, 0.365]\n",
      "1.6e-06 510.0 [0.38593877551020406, 0.382]\n",
      "1.6e-06 610.0 [0.3959591836734694, 0.378]\n",
      "1.6e-06 710.0 [0.3936734693877551, 0.38]\n",
      "1.6e-06 810.0 [0.4003469387755102, 0.406]\n",
      "1.6e-06 910.0 [0.39818367346938777, 0.393]\n",
      "1.6e-06 1010.0 [0.39914285714285713, 0.391]\n",
      "1.6e-06 1110.0 [0.39510204081632655, 0.404]\n",
      "1.6e-06 1210.0 [0.3997551020408163, 0.402]\n",
      "1.6e-06 1310.0 [0.40546938775510205, 0.405]\n",
      "1.6e-06 1410.0 [0.3962040816326531, 0.41]\n",
      "1.6e-06 1510.0 [0.3992040816326531, 0.405]\n",
      "1.6e-06 1610.0 [0.3958979591836735, 0.397]\n",
      "1.6e-06 1710.0 [0.39693877551020407, 0.398]\n",
      "1.6e-06 1810.0 [0.40269387755102043, 0.404]\n",
      "1.6e-06 1910.0 [0.4022857142857143, 0.415]\n",
      "1.6e-06 2010.0 [0.3849183673469388, 0.376]\n",
      "1.6e-06 2110.0 [0.3933061224489796, 0.383]\n",
      "1.6e-06 2210.0 [0.3956734693877551, 0.407]\n",
      "1.6e-06 2310.0 [0.3889795918367347, 0.393]\n",
      "1.6e-06 2410.0 [0.39257142857142857, 0.401]\n",
      "1.6e-06 2510.0 [0.39422448979591834, 0.389]\n",
      "1.6e-06 2610.0 [0.39018367346938776, 0.394]\n",
      "1.6e-06 2710.0 [0.39132653061224487, 0.393]\n",
      "1.6e-06 2810.0 [0.38977551020408163, 0.386]\n",
      "1.6e-06 2910.0 [0.3869183673469388, 0.388]\n",
      "1.6e-06 3010.0 [0.39081632653061227, 0.388]\n",
      "1.6e-06 3110.0 [0.39083673469387753, 0.387]\n",
      "1.6e-06 3210.0 [0.3830408163265306, 0.379]\n",
      "1.6e-06 3310.0 [0.38983673469387753, 0.4]\n",
      "1.6e-06 3410.0 [0.3810408163265306, 0.389]\n",
      "1.6e-06 3510.0 [0.3840408163265306, 0.376]\n",
      "1.6e-06 3610.0 [0.3862244897959184, 0.399]\n",
      "1.6e-06 3710.0 [0.38871428571428573, 0.385]\n",
      "1.6e-06 3810.0 [0.3862244897959184, 0.4]\n",
      "1.6e-06 3910.0 [0.3824489795918367, 0.387]\n",
      "1.6e-06 4010.0 [0.3808367346938776, 0.382]\n",
      "1.6e-06 4110.0 [0.38487755102040816, 0.39]\n",
      "1.6e-06 4210.0 [0.38540816326530614, 0.382]\n",
      "1.6e-06 4310.0 [0.37942857142857145, 0.382]\n",
      "1.6e-06 4410.0 [0.3834489795918367, 0.38]\n",
      "1.6e-06 4510.0 [0.3856530612244898, 0.393]\n",
      "1.6e-06 4610.0 [0.38210204081632654, 0.389]\n",
      "1.6e-06 4710.0 [0.3713673469387755, 0.389]\n",
      "1.6e-06 4810.0 [0.3806122448979592, 0.376]\n",
      "1.6e-06 4910.0 [0.3835918367346939, 0.4]\n",
      "1.6e-06 5010.0 [0.38373469387755105, 0.375]\n",
      "1.6e-06 5110.0 [0.3730816326530612, 0.38]\n",
      "1.6e-06 5210.0 [0.3700816326530612, 0.365]\n",
      "1.6e-06 5310.0 [0.3778367346938776, 0.392]\n",
      "1.6e-06 5410.0 [0.36475510204081635, 0.38]\n",
      "1.6e-06 5510.0 [0.3726326530612245, 0.378]\n",
      "1.6e-06 5610.0 [0.3760204081632653, 0.39]\n",
      "1.6e-06 5710.0 [0.37051020408163265, 0.372]\n",
      "1.6e-06 5810.0 [0.3800816326530612, 0.395]\n",
      "1.6e-06 5910.0 [0.37604081632653064, 0.38]\n",
      "1.6e-06 6010.0 [0.36983673469387757, 0.368]\n",
      "1.6e-06 6110.0 [0.37118367346938774, 0.372]\n",
      "1.6e-06 6210.0 [0.3657142857142857, 0.365]\n",
      "1.6e-06 6310.0 [0.37610204081632653, 0.391]\n",
      "1.6e-06 6410.0 [0.3747142857142857, 0.393]\n",
      "1.6e-06 6510.0 [0.3783061224489796, 0.402]\n",
      "1.6e-06 6610.0 [0.36757142857142855, 0.347]\n",
      "1.6e-06 6710.0 [0.3716122448979592, 0.376]\n",
      "1.6e-06 6810.0 [0.36283673469387756, 0.37]\n",
      "1.6e-06 6910.0 [0.36889795918367346, 0.376]\n",
      "1.6e-06 7010.0 [0.364, 0.377]\n",
      "1.6e-06 7110.0 [0.37379591836734694, 0.37]\n",
      "1.6e-06 7210.0 [0.3696938775510204, 0.37]\n",
      "1.6e-06 7310.0 [0.3606734693877551, 0.355]\n",
      "1.6e-06 7410.0 [0.3676326530612245, 0.379]\n",
      "1.6e-06 7510.0 [0.37310204081632653, 0.363]\n",
      "1.6e-06 7610.0 [0.3703265306122449, 0.378]\n",
      "1.6e-06 7710.0 [0.37073469387755104, 0.373]\n",
      "1.6e-06 7810.0 [0.3723673469387755, 0.377]\n",
      "1.6e-06 7910.0 [0.36451020408163265, 0.347]\n",
      "1.6e-06 8010.0 [0.3663265306122449, 0.37]\n",
      "1.6e-06 8110.0 [0.375530612244898, 0.373]\n",
      "1.6e-06 8210.0 [0.371, 0.368]\n",
      "1.6e-06 8310.0 [0.3609387755102041, 0.359]\n",
      "1.6e-06 8410.0 [0.36887755102040815, 0.358]\n",
      "1.6e-06 8510.0 [0.3696734693877551, 0.357]\n",
      "1.6e-06 8610.0 [0.36257142857142854, 0.37]\n",
      "1.6e-06 8710.0 [0.3673469387755102, 0.379]\n",
      "1.6e-06 8810.0 [0.356265306122449, 0.371]\n",
      "1.6e-06 8910.0 [0.3651632653061225, 0.378]\n",
      "1.6e-06 9010.0 [0.3636122448979592, 0.373]\n",
      "1.6e-06 9110.0 [0.363469387755102, 0.354]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6e-06 9210.0 [0.3633877551020408, 0.368]\n",
      "1.6e-06 9310.0 [0.3576734693877551, 0.374]\n",
      "1.6e-06 9410.0 [0.3656530612244898, 0.375]\n",
      "1.6e-06 9510.0 [0.3557142857142857, 0.371]\n",
      "1.6e-06 9610.0 [0.3643265306122449, 0.379]\n",
      "1.6e-06 9710.0 [0.35722448979591837, 0.361]\n",
      "1.6e-06 9810.0 [0.3686122448979592, 0.371]\n",
      "1.6e-06 9910.0 [0.3419591836734694, 0.336]\n",
      "2.1e-06 10.0 [0.357, 0.334]\n",
      "2.1e-06 110.0 [0.37544897959183676, 0.367]\n",
      "2.1e-06 210.0 [0.3808979591836735, 0.383]\n",
      "2.1e-06 310.0 [0.38693877551020406, 0.384]\n",
      "2.1e-06 410.0 [0.3978979591836735, 0.394]\n",
      "2.1e-06 510.0 [0.39210204081632655, 0.386]\n",
      "2.1e-06 610.0 [0.40122448979591835, 0.395]\n",
      "2.1e-06 710.0 [0.40561224489795916, 0.393]\n",
      "2.1e-06 810.0 [0.38687755102040816, 0.372]\n",
      "2.1e-06 910.0 [0.4021224489795918, 0.393]\n",
      "2.1e-06 1010.0 [0.3782857142857143, 0.37]\n",
      "2.1e-06 1110.0 [0.39755102040816326, 0.4]\n",
      "2.1e-06 1210.0 [0.39155102040816325, 0.405]\n",
      "2.1e-06 1310.0 [0.3919183673469388, 0.393]\n",
      "2.1e-06 1410.0 [0.40261224489795916, 0.399]\n",
      "2.1e-06 1510.0 [0.3965918367346939, 0.404]\n",
      "2.1e-06 1610.0 [0.396265306122449, 0.376]\n",
      "2.1e-06 1710.0 [0.3958979591836735, 0.408]\n",
      "2.1e-06 1810.0 [0.3924285714285714, 0.398]\n",
      "2.1e-06 1910.0 [0.3916122448979592, 0.407]\n",
      "2.1e-06 2010.0 [0.3860612244897959, 0.385]\n",
      "2.1e-06 2110.0 [0.3932040816326531, 0.385]\n",
      "2.1e-06 2210.0 [0.39346938775510204, 0.404]\n",
      "2.1e-06 2310.0 [0.38981632653061227, 0.389]\n",
      "2.1e-06 2410.0 [0.3828367346938776, 0.374]\n",
      "2.1e-06 2510.0 [0.3838979591836735, 0.382]\n",
      "2.1e-06 2610.0 [0.3943673469387755, 0.404]\n",
      "2.1e-06 2710.0 [0.3866938775510204, 0.401]\n",
      "2.1e-06 2810.0 [0.3730816326530612, 0.373]\n",
      "2.1e-06 2910.0 [0.3883265306122449, 0.395]\n",
      "2.1e-06 3010.0 [0.38642857142857145, 0.396]\n",
      "2.1e-06 3110.0 [0.37710204081632653, 0.383]\n",
      "2.1e-06 3210.0 [0.37326530612244896, 0.385]\n",
      "2.1e-06 3310.0 [0.38346938775510203, 0.396]\n",
      "2.1e-06 3410.0 [0.3779387755102041, 0.382]\n",
      "2.1e-06 3510.0 [0.37318367346938774, 0.378]\n",
      "2.1e-06 3610.0 [0.3840612244897959, 0.382]\n",
      "2.1e-06 3710.0 [0.3683877551020408, 0.376]\n",
      "2.1e-06 3810.0 [0.37695918367346937, 0.379]\n",
      "2.1e-06 3910.0 [0.3830612244897959, 0.379]\n",
      "2.1e-06 4010.0 [0.378530612244898, 0.392]\n",
      "2.1e-06 4110.0 [0.385, 0.393]\n",
      "2.1e-06 4210.0 [0.3740612244897959, 0.358]\n",
      "2.1e-06 4310.0 [0.3811428571428571, 0.385]\n",
      "2.1e-06 4410.0 [0.37755102040816324, 0.388]\n",
      "2.1e-06 4510.0 [0.3666122448979592, 0.359]\n",
      "2.1e-06 4610.0 [0.365469387755102, 0.353]\n",
      "2.1e-06 4710.0 [0.376469387755102, 0.373]\n",
      "2.1e-06 4810.0 [0.3770612244897959, 0.377]\n",
      "2.1e-06 4910.0 [0.3716734693877551, 0.391]\n",
      "2.1e-06 5010.0 [0.38046938775510203, 0.387]\n",
      "2.1e-06 5110.0 [0.36706122448979595, 0.381]\n",
      "2.1e-06 5210.0 [0.3726122448979592, 0.376]\n",
      "2.1e-06 5310.0 [0.3807142857142857, 0.398]\n",
      "2.1e-06 5410.0 [0.37379591836734694, 0.392]\n",
      "2.1e-06 5510.0 [0.36781632653061225, 0.372]\n",
      "2.1e-06 5610.0 [0.36981632653061225, 0.378]\n",
      "2.1e-06 5710.0 [0.36953061224489797, 0.373]\n",
      "2.1e-06 5810.0 [0.3700816326530612, 0.369]\n",
      "2.1e-06 5910.0 [0.3640408163265306, 0.365]\n",
      "2.1e-06 6010.0 [0.35851020408163264, 0.366]\n",
      "2.1e-06 6110.0 [0.3660816326530612, 0.382]\n",
      "2.1e-06 6210.0 [0.36875510204081635, 0.379]\n",
      "2.1e-06 6310.0 [0.3693877551020408, 0.367]\n",
      "2.1e-06 6410.0 [0.3706122448979592, 0.36]\n",
      "2.1e-06 6510.0 [0.36489795918367346, 0.358]\n",
      "2.1e-06 6610.0 [0.3655510204081633, 0.366]\n",
      "2.1e-06 6710.0 [0.36173469387755103, 0.357]\n",
      "2.1e-06 6810.0 [0.3676326530612245, 0.381]\n",
      "2.1e-06 6910.0 [0.3666734693877551, 0.379]\n",
      "2.1e-06 7010.0 [0.36128571428571427, 0.362]\n",
      "2.1e-06 7110.0 [0.3646734693877551, 0.378]\n",
      "2.1e-06 7210.0 [0.37210204081632653, 0.374]\n",
      "2.1e-06 7310.0 [0.364265306122449, 0.354]\n",
      "2.1e-06 7410.0 [0.3666122448979592, 0.379]\n",
      "2.1e-06 7510.0 [0.3491836734693878, 0.37]\n",
      "2.1e-06 7610.0 [0.35391836734693877, 0.351]\n",
      "2.1e-06 7710.0 [0.35914285714285715, 0.355]\n",
      "2.1e-06 7810.0 [0.3688571428571429, 0.381]\n",
      "2.1e-06 7910.0 [0.34383673469387754, 0.355]\n",
      "2.1e-06 8010.0 [0.35914285714285715, 0.35]\n",
      "2.1e-06 8110.0 [0.34616326530612246, 0.357]\n",
      "2.1e-06 8210.0 [0.36189795918367346, 0.375]\n",
      "2.1e-06 8310.0 [0.36036734693877553, 0.359]\n",
      "2.1e-06 8410.0 [0.35846938775510206, 0.357]\n",
      "2.1e-06 8510.0 [0.3653877551020408, 0.363]\n",
      "2.1e-06 8610.0 [0.35646938775510206, 0.357]\n",
      "2.1e-06 8710.0 [0.35867346938775513, 0.363]\n",
      "2.1e-06 8810.0 [0.3474897959183674, 0.338]\n",
      "2.1e-06 8910.0 [0.352265306122449, 0.35]\n",
      "2.1e-06 9010.0 [0.3620204081632653, 0.387]\n",
      "2.1e-06 9110.0 [0.36006122448979594, 0.371]\n",
      "2.1e-06 9210.0 [0.35528571428571426, 0.359]\n",
      "2.1e-06 9310.0 [0.3559387755102041, 0.344]\n",
      "2.1e-06 9410.0 [0.3547959183673469, 0.369]\n",
      "2.1e-06 9510.0 [0.3523469387755102, 0.356]\n",
      "2.1e-06 9610.0 [0.3620408163265306, 0.359]\n",
      "2.1e-06 9710.0 [0.34916326530612246, 0.359]\n",
      "2.1e-06 9810.0 [0.36228571428571427, 0.367]\n",
      "2.1e-06 9910.0 [0.3461020408163265, 0.355]\n",
      "2.5999999999999997e-06 10.0 [0.36506122448979594, 0.373]\n",
      "2.5999999999999997e-06 110.0 [0.3809387755102041, 0.362]\n",
      "2.5999999999999997e-06 210.0 [0.38381632653061226, 0.36]\n",
      "2.5999999999999997e-06 310.0 [0.393265306122449, 0.398]\n",
      "2.5999999999999997e-06 410.0 [0.40583673469387754, 0.38]\n",
      "2.5999999999999997e-06 510.0 [0.3933877551020408, 0.391]\n",
      "2.5999999999999997e-06 610.0 [0.4007142857142857, 0.388]\n",
      "2.5999999999999997e-06 710.0 [0.385734693877551, 0.387]\n",
      "2.5999999999999997e-06 810.0 [0.4057142857142857, 0.409]\n",
      "2.5999999999999997e-06 910.0 [0.40324489795918367, 0.401]\n",
      "2.5999999999999997e-06 1010.0 [0.39593877551020407, 0.387]\n",
      "2.5999999999999997e-06 1110.0 [0.386530612244898, 0.391]\n",
      "2.5999999999999997e-06 1210.0 [0.40210204081632656, 0.398]\n",
      "2.5999999999999997e-06 1310.0 [0.39408163265306123, 0.387]\n",
      "2.5999999999999997e-06 1410.0 [0.3950204081632653, 0.4]\n",
      "2.5999999999999997e-06 1510.0 [0.39779591836734696, 0.389]\n",
      "2.5999999999999997e-06 1610.0 [0.3707755102040816, 0.362]\n",
      "2.5999999999999997e-06 1710.0 [0.3892244897959184, 0.375]\n",
      "2.5999999999999997e-06 1810.0 [0.36948979591836734, 0.366]\n",
      "2.5999999999999997e-06 1910.0 [0.3767755102040816, 0.377]\n",
      "2.5999999999999997e-06 2010.0 [0.39346938775510204, 0.407]\n",
      "2.5999999999999997e-06 2110.0 [0.3896122448979592, 0.382]\n",
      "2.5999999999999997e-06 2210.0 [0.3893469387755102, 0.387]\n",
      "2.5999999999999997e-06 2310.0 [0.3727755102040816, 0.384]\n",
      "2.5999999999999997e-06 2410.0 [0.38140816326530613, 0.377]\n",
      "2.5999999999999997e-06 2510.0 [0.36220408163265305, 0.357]\n",
      "2.5999999999999997e-06 2610.0 [0.3757551020408163, 0.382]\n",
      "2.5999999999999997e-06 2710.0 [0.37548979591836734, 0.392]\n",
      "2.5999999999999997e-06 2810.0 [0.37612244897959185, 0.373]\n",
      "2.5999999999999997e-06 2910.0 [0.3730612244897959, 0.37]\n",
      "2.5999999999999997e-06 3010.0 [0.3811428571428571, 0.385]\n",
      "2.5999999999999997e-06 3110.0 [0.37557142857142856, 0.379]\n",
      "2.5999999999999997e-06 3210.0 [0.38612244897959186, 0.397]\n",
      "2.5999999999999997e-06 3310.0 [0.35289795918367345, 0.362]\n",
      "2.5999999999999997e-06 3410.0 [0.3560816326530612, 0.373]\n",
      "2.5999999999999997e-06 3510.0 [0.37420408163265306, 0.375]\n",
      "2.5999999999999997e-06 3610.0 [0.3809183673469388, 0.397]\n",
      "2.5999999999999997e-06 3710.0 [0.37104081632653063, 0.376]\n",
      "2.5999999999999997e-06 3810.0 [0.375, 0.384]\n",
      "2.5999999999999997e-06 3910.0 [0.376, 0.38]\n",
      "2.5999999999999997e-06 4010.0 [0.376, 0.378]\n",
      "2.5999999999999997e-06 4110.0 [0.36987755102040815, 0.36]\n",
      "2.5999999999999997e-06 4210.0 [0.36653061224489797, 0.375]\n",
      "2.5999999999999997e-06 4310.0 [0.37626530612244896, 0.375]\n",
      "2.5999999999999997e-06 4410.0 [0.3635510204081633, 0.376]\n",
      "2.5999999999999997e-06 4510.0 [0.36359183673469386, 0.364]\n",
      "2.5999999999999997e-06 4610.0 [0.3587142857142857, 0.365]\n",
      "2.5999999999999997e-06 4710.0 [0.3616122448979592, 0.358]\n",
      "2.5999999999999997e-06 4810.0 [0.3666938775510204, 0.368]\n",
      "2.5999999999999997e-06 4910.0 [0.3753265306122449, 0.361]\n",
      "2.5999999999999997e-06 5010.0 [0.3627959183673469, 0.375]\n",
      "2.5999999999999997e-06 5110.0 [0.355, 0.351]\n",
      "2.5999999999999997e-06 5210.0 [0.36581632653061225, 0.37]\n",
      "2.5999999999999997e-06 5310.0 [0.3699795918367347, 0.38]\n",
      "2.5999999999999997e-06 5410.0 [0.3759795918367347, 0.382]\n",
      "2.5999999999999997e-06 5510.0 [0.36718367346938774, 0.386]\n",
      "2.5999999999999997e-06 5610.0 [0.3474081632653061, 0.353]\n",
      "2.5999999999999997e-06 5710.0 [0.36383673469387756, 0.353]\n",
      "2.5999999999999997e-06 5810.0 [0.3642448979591837, 0.375]\n",
      "2.5999999999999997e-06 5910.0 [0.3633469387755102, 0.365]\n",
      "2.5999999999999997e-06 6010.0 [0.3663469387755102, 0.372]\n",
      "2.5999999999999997e-06 6110.0 [0.3626530612244898, 0.366]\n",
      "2.5999999999999997e-06 6210.0 [0.37385714285714283, 0.374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5999999999999997e-06 6310.0 [0.36828571428571427, 0.373]\n",
      "2.5999999999999997e-06 6410.0 [0.3584081632653061, 0.367]\n",
      "2.5999999999999997e-06 6510.0 [0.3601020408163265, 0.375]\n",
      "2.5999999999999997e-06 6610.0 [0.3686530612244898, 0.376]\n",
      "2.5999999999999997e-06 6710.0 [0.3629387755102041, 0.366]\n",
      "2.5999999999999997e-06 6810.0 [0.356, 0.362]\n",
      "2.5999999999999997e-06 6910.0 [0.35946938775510207, 0.367]\n",
      "2.5999999999999997e-06 7010.0 [0.3543877551020408, 0.362]\n",
      "2.5999999999999997e-06 7110.0 [0.3484285714285714, 0.363]\n",
      "2.5999999999999997e-06 7210.0 [0.3579387755102041, 0.363]\n",
      "2.5999999999999997e-06 7310.0 [0.3529387755102041, 0.353]\n",
      "2.5999999999999997e-06 7410.0 [0.35606122448979594, 0.366]\n",
      "2.5999999999999997e-06 7510.0 [0.3344489795918367, 0.332]\n",
      "2.5999999999999997e-06 7610.0 [0.34191836734693876, 0.343]\n",
      "2.5999999999999997e-06 7710.0 [0.357734693877551, 0.375]\n",
      "2.5999999999999997e-06 7810.0 [0.3424081632653061, 0.363]\n",
      "2.5999999999999997e-06 7910.0 [0.36353061224489797, 0.362]\n",
      "2.5999999999999997e-06 8010.0 [0.35681632653061224, 0.354]\n",
      "2.5999999999999997e-06 8110.0 [0.3496326530612245, 0.348]\n",
      "2.5999999999999997e-06 8210.0 [0.365265306122449, 0.375]\n",
      "2.5999999999999997e-06 8310.0 [0.36087755102040814, 0.364]\n",
      "2.5999999999999997e-06 8410.0 [0.3585714285714286, 0.35]\n",
      "2.5999999999999997e-06 8510.0 [0.361, 0.367]\n",
      "2.5999999999999997e-06 8610.0 [0.3452857142857143, 0.358]\n",
      "2.5999999999999997e-06 8710.0 [0.349, 0.36]\n",
      "2.5999999999999997e-06 8810.0 [0.3506734693877551, 0.353]\n",
      "2.5999999999999997e-06 8910.0 [0.3643061224489796, 0.368]\n",
      "2.5999999999999997e-06 9010.0 [0.3586122448979592, 0.365]\n",
      "2.5999999999999997e-06 9110.0 [0.3413265306122449, 0.339]\n",
      "2.5999999999999997e-06 9210.0 [0.3509795918367347, 0.371]\n",
      "2.5999999999999997e-06 9310.0 [0.3503061224489796, 0.35]\n",
      "2.5999999999999997e-06 9410.0 [0.35014285714285714, 0.361]\n",
      "2.5999999999999997e-06 9510.0 [0.3243673469387755, 0.328]\n",
      "2.5999999999999997e-06 9610.0 [0.35416326530612247, 0.357]\n",
      "2.5999999999999997e-06 9710.0 [0.3472448979591837, 0.362]\n",
      "2.5999999999999997e-06 9810.0 [0.3399795918367347, 0.342]\n",
      "2.5999999999999997e-06 9910.0 [0.34446938775510205, 0.356]\n",
      "3.1e-06 10.0 [0.3733061224489796, 0.339]\n",
      "3.1e-06 110.0 [0.3836530612244898, 0.347]\n",
      "3.1e-06 210.0 [0.391, 0.379]\n",
      "3.1e-06 310.0 [0.3946938775510204, 0.394]\n",
      "3.1e-06 410.0 [0.40185714285714286, 0.393]\n",
      "3.1e-06 510.0 [0.4034081632653061, 0.392]\n",
      "3.1e-06 610.0 [0.40193877551020407, 0.389]\n",
      "3.1e-06 710.0 [0.3998979591836735, 0.392]\n",
      "3.1e-06 810.0 [0.4034081632653061, 0.413]\n",
      "3.1e-06 910.0 [0.39940816326530615, 0.401]\n",
      "3.1e-06 1010.0 [0.3980204081632653, 0.413]\n",
      "3.1e-06 1110.0 [0.3916938775510204, 0.389]\n",
      "3.1e-06 1210.0 [0.3803877551020408, 0.391]\n",
      "3.1e-06 1310.0 [0.39248979591836736, 0.396]\n",
      "3.1e-06 1410.0 [0.3848979591836735, 0.37]\n",
      "3.1e-06 1510.0 [0.3924285714285714, 0.387]\n",
      "3.1e-06 1610.0 [0.38210204081632654, 0.377]\n",
      "3.1e-06 1710.0 [0.3796734693877551, 0.362]\n",
      "3.1e-06 1810.0 [0.39493877551020407, 0.394]\n",
      "3.1e-06 1910.0 [0.3839183673469388, 0.395]\n",
      "3.1e-06 2010.0 [0.38151020408163266, 0.368]\n",
      "3.1e-06 2110.0 [0.3813877551020408, 0.39]\n",
      "3.1e-06 2210.0 [0.38095918367346937, 0.367]\n",
      "3.1e-06 2310.0 [0.38955102040816325, 0.398]\n",
      "3.1e-06 2410.0 [0.3686122448979592, 0.362]\n",
      "3.1e-06 2510.0 [0.378, 0.382]\n",
      "3.1e-06 2610.0 [0.3838367346938775, 0.397]\n",
      "3.1e-06 2710.0 [0.3752244897959184, 0.373]\n",
      "3.1e-06 2810.0 [0.37048979591836734, 0.359]\n",
      "3.1e-06 2910.0 [0.37244897959183676, 0.369]\n",
      "3.1e-06 3010.0 [0.3617755102040816, 0.358]\n",
      "3.1e-06 3110.0 [0.3806122448979592, 0.369]\n",
      "3.1e-06 3210.0 [0.3663673469387755, 0.37]\n",
      "3.1e-06 3310.0 [0.3723877551020408, 0.365]\n",
      "3.1e-06 3410.0 [0.3647755102040816, 0.372]\n",
      "3.1e-06 3510.0 [0.3583061224489796, 0.358]\n",
      "3.1e-06 3610.0 [0.36220408163265305, 0.37]\n",
      "3.1e-06 3710.0 [0.365265306122449, 0.361]\n",
      "3.1e-06 3810.0 [0.34906122448979593, 0.342]\n",
      "3.1e-06 3910.0 [0.3652244897959184, 0.371]\n",
      "3.1e-06 4010.0 [0.3678571428571429, 0.359]\n",
      "3.1e-06 4110.0 [0.36148979591836733, 0.375]\n",
      "3.1e-06 4210.0 [0.35677551020408166, 0.357]\n",
      "3.1e-06 4310.0 [0.36228571428571427, 0.371]\n",
      "3.1e-06 4410.0 [0.3739387755102041, 0.395]\n",
      "3.1e-06 4510.0 [0.35981632653061224, 0.353]\n",
      "3.1e-06 4610.0 [0.36144897959183675, 0.358]\n",
      "3.1e-06 4710.0 [0.36506122448979594, 0.353]\n",
      "3.1e-06 4810.0 [0.3619591836734694, 0.366]\n",
      "3.1e-06 4910.0 [0.35906122448979594, 0.352]\n",
      "3.1e-06 5010.0 [0.35328571428571426, 0.367]\n",
      "3.1e-06 5110.0 [0.33777551020408164, 0.34]\n",
      "3.1e-06 5210.0 [0.35206122448979593, 0.346]\n",
      "3.1e-06 5310.0 [0.34846938775510206, 0.347]\n",
      "3.1e-06 5410.0 [0.34320408163265304, 0.343]\n",
      "3.1e-06 5510.0 [0.3526938775510204, 0.354]\n",
      "3.1e-06 5610.0 [0.35959183673469386, 0.369]\n",
      "3.1e-06 5710.0 [0.3601020408163265, 0.346]\n",
      "3.1e-06 5810.0 [0.366469387755102, 0.382]\n",
      "3.1e-06 5910.0 [0.3566326530612245, 0.353]\n",
      "3.1e-06 6010.0 [0.35451020408163264, 0.347]\n",
      "3.1e-06 6110.0 [0.3564897959183673, 0.363]\n",
      "3.1e-06 6210.0 [0.3579387755102041, 0.362]\n",
      "3.1e-06 6310.0 [0.3395102040816326, 0.357]\n",
      "3.1e-06 6410.0 [0.36087755102040814, 0.364]\n",
      "3.1e-06 6510.0 [0.3459591836734694, 0.357]\n",
      "3.1e-06 6610.0 [0.3601020408163265, 0.373]\n",
      "3.1e-06 6710.0 [0.35946938775510207, 0.368]\n",
      "3.1e-06 6810.0 [0.3443673469387755, 0.343]\n",
      "3.1e-06 6910.0 [0.3480204081632653, 0.353]\n",
      "3.1e-06 7010.0 [0.36028571428571426, 0.357]\n",
      "3.1e-06 7110.0 [0.34775510204081633, 0.367]\n",
      "3.1e-06 7210.0 [0.365265306122449, 0.38]\n",
      "3.1e-06 7310.0 [0.3514081632653061, 0.349]\n",
      "3.1e-06 7410.0 [0.36051020408163265, 0.365]\n",
      "3.1e-06 7510.0 [0.3587959183673469, 0.368]\n",
      "3.1e-06 7610.0 [0.34544897959183674, 0.356]\n",
      "3.1e-06 7710.0 [0.3546530612244898, 0.37]\n",
      "3.1e-06 7810.0 [0.3386326530612245, 0.322]\n",
      "3.1e-06 7910.0 [0.3553061224489796, 0.362]\n",
      "3.1e-06 8010.0 [0.3419591836734694, 0.365]\n",
      "3.1e-06 8110.0 [0.3106326530612245, 0.333]\n",
      "3.1e-06 8210.0 [0.3435918367346939, 0.353]\n",
      "3.1e-06 8310.0 [0.34385714285714286, 0.359]\n",
      "3.1e-06 8410.0 [0.3536938775510204, 0.378]\n",
      "3.1e-06 8510.0 [0.3387142857142857, 0.342]\n",
      "3.1e-06 8610.0 [0.34461224489795916, 0.346]\n",
      "3.1e-06 8710.0 [0.3389795918367347, 0.369]\n",
      "3.1e-06 8810.0 [0.34675510204081633, 0.346]\n",
      "3.1e-06 8910.0 [0.34453061224489795, 0.346]\n",
      "3.1e-06 9010.0 [0.3356122448979592, 0.35]\n",
      "3.1e-06 9110.0 [0.3356326530612245, 0.363]\n",
      "3.1e-06 9210.0 [0.3543265306122449, 0.367]\n",
      "3.1e-06 9310.0 [0.34430612244897957, 0.352]\n",
      "3.1e-06 9410.0 [0.34638775510204084, 0.339]\n",
      "3.1e-06 9510.0 [0.348, 0.352]\n",
      "3.1e-06 9610.0 [0.3526734693877551, 0.354]\n",
      "3.1e-06 9710.0 [0.34261224489795916, 0.347]\n",
      "3.1e-06 9810.0 [0.35742857142857143, 0.367]\n",
      "3.1e-06 9910.0 [0.33246938775510204, 0.346]\n",
      "3.6e-06 10.0 [0.37840816326530613, 0.36]\n",
      "3.6e-06 110.0 [0.3847755102040816, 0.376]\n",
      "3.6e-06 210.0 [0.39093877551020406, 0.381]\n",
      "3.6e-06 310.0 [0.3927551020408163, 0.372]\n",
      "3.6e-06 410.0 [0.4024081632653061, 0.384]\n",
      "3.6e-06 510.0 [0.4013061224489796, 0.401]\n",
      "3.6e-06 610.0 [0.39016326530612244, 0.376]\n",
      "3.6e-06 710.0 [0.40114285714285713, 0.399]\n",
      "3.6e-06 810.0 [0.39108163265306123, 0.387]\n",
      "3.6e-06 910.0 [0.38557142857142856, 0.381]\n",
      "3.6e-06 1010.0 [0.3854489795918367, 0.373]\n",
      "3.6e-06 1110.0 [0.39322448979591834, 0.376]\n",
      "3.6e-06 1210.0 [0.38418367346938775, 0.379]\n",
      "3.6e-06 1310.0 [0.37395918367346936, 0.359]\n",
      "3.6e-06 1410.0 [0.3886122448979592, 0.392]\n",
      "3.6e-06 1510.0 [0.3759183673469388, 0.377]\n",
      "3.6e-06 1610.0 [0.38210204081632654, 0.384]\n",
      "3.6e-06 1710.0 [0.3841428571428571, 0.38]\n",
      "3.6e-06 1810.0 [0.38702040816326533, 0.375]\n",
      "3.6e-06 1910.0 [0.3713061224489796, 0.373]\n",
      "3.6e-06 2010.0 [0.3640408163265306, 0.358]\n",
      "3.6e-06 2110.0 [0.3778367346938776, 0.388]\n",
      "3.6e-06 2210.0 [0.3626530612244898, 0.354]\n",
      "3.6e-06 2310.0 [0.36112244897959184, 0.364]\n",
      "3.6e-06 2410.0 [0.3801428571428571, 0.385]\n",
      "3.6e-06 2510.0 [0.3716530612244898, 0.364]\n",
      "3.6e-06 2610.0 [0.36981632653061225, 0.366]\n",
      "3.6e-06 2710.0 [0.3630408163265306, 0.356]\n",
      "3.6e-06 2810.0 [0.3687755102040816, 0.372]\n",
      "3.6e-06 2910.0 [0.37348979591836734, 0.38]\n",
      "3.6e-06 3010.0 [0.37444897959183676, 0.373]\n",
      "3.6e-06 3110.0 [0.3651632653061225, 0.388]\n",
      "3.6e-06 3210.0 [0.365469387755102, 0.366]\n",
      "3.6e-06 3310.0 [0.3675510204081633, 0.374]\n",
      "3.6e-06 3410.0 [0.35853061224489796, 0.338]\n",
      "3.6e-06 3510.0 [0.36344897959183675, 0.35]\n",
      "3.6e-06 3610.0 [0.38351020408163267, 0.384]\n",
      "3.6e-06 3710.0 [0.35981632653061224, 0.362]\n",
      "3.6e-06 3810.0 [0.364265306122449, 0.367]\n",
      "3.6e-06 3910.0 [0.3436734693877551, 0.355]\n",
      "3.6e-06 4010.0 [0.36614285714285716, 0.388]\n",
      "3.6e-06 4110.0 [0.3569387755102041, 0.377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6e-06 4210.0 [0.36844897959183676, 0.371]\n",
      "3.6e-06 4310.0 [0.35038775510204084, 0.346]\n",
      "3.6e-06 4410.0 [0.33691836734693875, 0.342]\n",
      "3.6e-06 4510.0 [0.36206122448979594, 0.379]\n",
      "3.6e-06 4610.0 [0.3636938775510204, 0.356]\n",
      "3.6e-06 4710.0 [0.357734693877551, 0.358]\n",
      "3.6e-06 4810.0 [0.36518367346938774, 0.361]\n",
      "3.6e-06 4910.0 [0.35051020408163264, 0.347]\n",
      "3.6e-06 5010.0 [0.36220408163265305, 0.38]\n",
      "3.6e-06 5110.0 [0.35444897959183674, 0.367]\n",
      "3.6e-06 5210.0 [0.35485714285714287, 0.373]\n",
      "3.6e-06 5310.0 [0.3611020408163265, 0.382]\n",
      "3.6e-06 5410.0 [0.3485918367346939, 0.378]\n",
      "3.6e-06 5510.0 [0.3399591836734694, 0.345]\n",
      "3.6e-06 5610.0 [0.351, 0.347]\n",
      "3.6e-06 5710.0 [0.35091836734693876, 0.365]\n",
      "3.6e-06 5810.0 [0.34575510204081633, 0.354]\n",
      "3.6e-06 5910.0 [0.37159183673469387, 0.362]\n",
      "3.6e-06 6010.0 [0.3610816326530612, 0.367]\n",
      "3.6e-06 6110.0 [0.34651020408163263, 0.341]\n",
      "3.6e-06 6210.0 [0.33838775510204083, 0.345]\n",
      "3.6e-06 6310.0 [0.3183877551020408, 0.337]\n",
      "3.6e-06 6410.0 [0.3226122448979592, 0.337]\n",
      "3.6e-06 6510.0 [0.3336938775510204, 0.358]\n",
      "3.6e-06 6610.0 [0.339734693877551, 0.35]\n",
      "3.6e-06 6710.0 [0.32677551020408163, 0.326]\n",
      "3.6e-06 6810.0 [0.35281632653061223, 0.357]\n",
      "3.6e-06 6910.0 [0.35728571428571426, 0.364]\n",
      "3.6e-06 7010.0 [0.34689795918367344, 0.341]\n",
      "3.6e-06 7110.0 [0.3335102040816327, 0.317]\n",
      "3.6e-06 7210.0 [0.3302040816326531, 0.331]\n",
      "3.6e-06 7310.0 [0.32155102040816325, 0.321]\n",
      "3.6e-06 7410.0 [0.35677551020408166, 0.38]\n",
      "3.6e-06 7510.0 [0.34379591836734696, 0.346]\n",
      "3.6e-06 7610.0 [0.3348979591836735, 0.341]\n",
      "3.6e-06 7710.0 [0.34146938775510205, 0.345]\n",
      "3.6e-06 7810.0 [0.3438775510204082, 0.351]\n",
      "3.6e-06 7910.0 [0.35585714285714287, 0.357]\n",
      "3.6e-06 8010.0 [0.3463469387755102, 0.326]\n",
      "3.6e-06 8110.0 [0.3506734693877551, 0.356]\n",
      "3.6e-06 8210.0 [0.3406530612244898, 0.352]\n",
      "3.6e-06 8310.0 [0.3466530612244898, 0.359]\n",
      "3.6e-06 8410.0 [0.3435714285714286, 0.36]\n",
      "3.6e-06 8510.0 [0.34808163265306125, 0.369]\n",
      "3.6e-06 8610.0 [0.35161224489795917, 0.352]\n",
      "3.6e-06 8710.0 [0.3363265306122449, 0.325]\n",
      "3.6e-06 8810.0 [0.3605510204081633, 0.363]\n",
      "3.6e-06 8910.0 [0.33355102040816326, 0.354]\n",
      "3.6e-06 9010.0 [0.3375102040816326, 0.342]\n",
      "3.6e-06 9110.0 [0.33391836734693875, 0.326]\n",
      "3.6e-06 9210.0 [0.315, 0.311]\n",
      "3.6e-06 9310.0 [0.33661224489795916, 0.333]\n",
      "3.6e-06 9410.0 [0.3263061224489796, 0.341]\n",
      "3.6e-06 9510.0 [0.32173469387755105, 0.332]\n",
      "3.6e-06 9610.0 [0.3097142857142857, 0.312]\n",
      "3.6e-06 9710.0 [0.3169183673469388, 0.302]\n",
      "3.6e-06 9810.0 [0.3243877551020408, 0.339]\n",
      "3.6e-06 9910.0 [0.3323673469387755, 0.337]\n",
      "4.1e-06 10.0 [0.3595510204081633, 0.34]\n",
      "4.1e-06 110.0 [0.3746326530612245, 0.348]\n",
      "4.1e-06 210.0 [0.39610204081632655, 0.388]\n",
      "4.1e-06 310.0 [0.3894489795918367, 0.37]\n",
      "4.1e-06 410.0 [0.37604081632653064, 0.358]\n",
      "4.1e-06 510.0 [0.39355102040816325, 0.398]\n",
      "4.1e-06 610.0 [0.37957142857142856, 0.364]\n",
      "4.1e-06 710.0 [0.40010204081632655, 0.385]\n",
      "4.1e-06 810.0 [0.3809387755102041, 0.368]\n",
      "4.1e-06 910.0 [0.37681632653061226, 0.386]\n",
      "4.1e-06 1010.0 [0.3843265306122449, 0.378]\n",
      "4.1e-06 1110.0 [0.3894489795918367, 0.385]\n",
      "4.1e-06 1210.0 [0.375, 0.372]\n",
      "4.1e-06 1310.0 [0.394265306122449, 0.392]\n",
      "4.1e-06 1410.0 [0.37112244897959185, 0.371]\n",
      "4.1e-06 1510.0 [0.37510204081632653, 0.388]\n",
      "4.1e-06 1610.0 [0.375469387755102, 0.387]\n",
      "4.1e-06 1710.0 [0.3577142857142857, 0.345]\n",
      "4.1e-06 1810.0 [0.3459387755102041, 0.345]\n",
      "4.1e-06 1910.0 [0.3714081632653061, 0.366]\n",
      "4.1e-06 2010.0 [0.3763877551020408, 0.378]\n",
      "4.1e-06 2110.0 [0.3681632653061224, 0.405]\n",
      "4.1e-06 2210.0 [0.3709183673469388, 0.369]\n",
      "4.1e-06 2310.0 [0.37918367346938775, 0.382]\n",
      "4.1e-06 2410.0 [0.3526530612244898, 0.33]\n",
      "4.1e-06 2510.0 [0.3539387755102041, 0.346]\n",
      "4.1e-06 2610.0 [0.37679591836734694, 0.386]\n",
      "4.1e-06 2710.0 [0.3747551020408163, 0.379]\n",
      "4.1e-06 2810.0 [0.37159183673469387, 0.375]\n",
      "4.1e-06 2910.0 [0.3637959183673469, 0.372]\n",
      "4.1e-06 3010.0 [0.3569387755102041, 0.362]\n",
      "4.1e-06 3110.0 [0.3133877551020408, 0.324]\n",
      "4.1e-06 3210.0 [0.3490204081632653, 0.365]\n",
      "4.1e-06 3310.0 [0.34814285714285714, 0.356]\n",
      "4.1e-06 3410.0 [0.37157142857142855, 0.383]\n",
      "4.1e-06 3510.0 [0.3673265306122449, 0.365]\n",
      "4.1e-06 3610.0 [0.3574081632653061, 0.38]\n",
      "4.1e-06 3710.0 [0.34681632653061223, 0.342]\n",
      "4.1e-06 3810.0 [0.3326734693877551, 0.317]\n",
      "4.1e-06 3910.0 [0.36242857142857143, 0.376]\n",
      "4.1e-06 4010.0 [0.3476326530612245, 0.362]\n",
      "4.1e-06 4110.0 [0.3529795918367347, 0.358]\n",
      "4.1e-06 4210.0 [0.3466530612244898, 0.352]\n",
      "4.1e-06 4310.0 [0.37075510204081635, 0.363]\n",
      "4.1e-06 4410.0 [0.3423673469387755, 0.345]\n",
      "4.1e-06 4510.0 [0.3653265306122449, 0.374]\n",
      "4.1e-06 4610.0 [0.32216326530612244, 0.329]\n",
      "4.1e-06 4710.0 [0.3355714285714286, 0.326]\n",
      "4.1e-06 4810.0 [0.3448163265306122, 0.351]\n",
      "4.1e-06 4910.0 [0.34151020408163263, 0.348]\n",
      "4.1e-06 5010.0 [0.3217551020408163, 0.312]\n",
      "4.1e-06 5110.0 [0.331, 0.331]\n",
      "4.1e-06 5210.0 [0.34955102040816327, 0.356]\n",
      "4.1e-06 5310.0 [0.3646530612244898, 0.368]\n",
      "4.1e-06 5410.0 [0.3436530612244898, 0.357]\n",
      "4.1e-06 5510.0 [0.34883673469387755, 0.363]\n",
      "4.1e-06 5610.0 [0.33961224489795916, 0.36]\n",
      "4.1e-06 5710.0 [0.34916326530612246, 0.365]\n",
      "4.1e-06 5810.0 [0.35408163265306125, 0.346]\n",
      "4.1e-06 5910.0 [0.34938775510204084, 0.361]\n",
      "4.1e-06 6010.0 [0.3603061224489796, 0.349]\n",
      "4.1e-06 6110.0 [0.34155102040816326, 0.361]\n",
      "4.1e-06 6210.0 [0.3295102040816327, 0.341]\n",
      "4.1e-06 6310.0 [0.34046938775510205, 0.346]\n",
      "4.1e-06 6410.0 [0.33177551020408164, 0.352]\n",
      "4.1e-06 6510.0 [0.3502857142857143, 0.354]\n",
      "4.1e-06 6610.0 [0.33146938775510204, 0.343]\n",
      "4.1e-06 6710.0 [0.33738775510204083, 0.351]\n",
      "4.1e-06 6810.0 [0.3153469387755102, 0.33]\n",
      "4.1e-06 6910.0 [0.3300612244897959, 0.332]\n",
      "4.1e-06 7010.0 [0.33153061224489794, 0.341]\n",
      "4.1e-06 7110.0 [0.3450408163265306, 0.363]\n",
      "4.1e-06 7210.0 [0.32908163265306123, 0.333]\n",
      "4.1e-06 7310.0 [0.2992448979591837, 0.332]\n",
      "4.1e-06 7410.0 [0.3325918367346939, 0.341]\n",
      "4.1e-06 7510.0 [0.3399591836734694, 0.341]\n",
      "4.1e-06 7610.0 [0.34675510204081633, 0.346]\n",
      "4.1e-06 7710.0 [0.3040408163265306, 0.308]\n",
      "4.1e-06 7810.0 [0.31742857142857145, 0.319]\n",
      "4.1e-06 7910.0 [0.34646938775510205, 0.345]\n",
      "4.1e-06 8010.0 [0.3373265306122449, 0.327]\n",
      "4.1e-06 8110.0 [0.34177551020408165, 0.353]\n",
      "4.1e-06 8210.0 [0.355265306122449, 0.354]\n",
      "4.1e-06 8310.0 [0.34169387755102043, 0.317]\n",
      "4.1e-06 8410.0 [0.33614285714285713, 0.324]\n",
      "4.1e-06 8510.0 [0.3368979591836735, 0.345]\n",
      "4.1e-06 8610.0 [0.3315102040816327, 0.345]\n",
      "4.1e-06 8710.0 [0.345265306122449, 0.365]\n",
      "4.1e-06 8810.0 [0.32246938775510203, 0.329]\n",
      "4.1e-06 8910.0 [0.32848979591836736, 0.341]\n",
      "4.1e-06 9010.0 [0.33646938775510205, 0.345]\n",
      "4.1e-06 9110.0 [0.3276938775510204, 0.345]\n",
      "4.1e-06 9210.0 [0.3304489795918367, 0.326]\n",
      "4.1e-06 9310.0 [0.3395714285714286, 0.346]\n",
      "4.1e-06 9410.0 [0.34014285714285714, 0.356]\n",
      "4.1e-06 9510.0 [0.32710204081632654, 0.33]\n",
      "4.1e-06 9610.0 [0.2969387755102041, 0.301]\n",
      "4.1e-06 9710.0 [0.32553061224489793, 0.326]\n",
      "4.1e-06 9810.0 [0.33710204081632655, 0.349]\n",
      "4.1e-06 9910.0 [0.30681632653061225, 0.316]\n",
      "4.6e-06 10.0 [0.37942857142857145, 0.355]\n",
      "4.6e-06 110.0 [0.3856938775510204, 0.364]\n",
      "4.6e-06 210.0 [0.3939795918367347, 0.395]\n",
      "4.6e-06 310.0 [0.38853061224489793, 0.38]\n",
      "4.6e-06 410.0 [0.3729795918367347, 0.365]\n",
      "4.6e-06 510.0 [0.3943673469387755, 0.374]\n",
      "4.6e-06 610.0 [0.38887755102040816, 0.385]\n",
      "4.6e-06 710.0 [0.36448979591836733, 0.356]\n",
      "4.6e-06 810.0 [0.3924489795918367, 0.387]\n",
      "4.6e-06 910.0 [0.3617959183673469, 0.351]\n",
      "4.6e-06 1010.0 [0.3626326530612245, 0.366]\n",
      "4.6e-06 1110.0 [0.3617755102040816, 0.352]\n",
      "4.6e-06 1210.0 [0.38546938775510203, 0.395]\n",
      "4.6e-06 1310.0 [0.37681632653061226, 0.388]\n",
      "4.6e-06 1410.0 [0.377469387755102, 0.376]\n",
      "4.6e-06 1510.0 [0.37026530612244896, 0.377]\n",
      "4.6e-06 1610.0 [0.35791836734693877, 0.358]\n",
      "4.6e-06 1710.0 [0.358, 0.341]\n",
      "4.6e-06 1810.0 [0.35346938775510206, 0.344]\n",
      "4.6e-06 1910.0 [0.35, 0.331]\n",
      "4.6e-06 2010.0 [0.3392040816326531, 0.335]\n",
      "4.6e-06 2110.0 [0.3586122448979592, 0.367]\n",
      "4.6e-06 2210.0 [0.33955102040816326, 0.337]\n",
      "4.6e-06 2310.0 [0.3476530612244898, 0.338]\n",
      "4.6e-06 2410.0 [0.3556122448979592, 0.343]\n",
      "4.6e-06 2510.0 [0.3469591836734694, 0.352]\n",
      "4.6e-06 2610.0 [0.3700816326530612, 0.347]\n",
      "4.6e-06 2710.0 [0.36518367346938774, 0.352]\n",
      "4.6e-06 2810.0 [0.33210204081632655, 0.349]\n",
      "4.6e-06 2910.0 [0.3313265306122449, 0.34]\n",
      "4.6e-06 3010.0 [0.3404081632653061, 0.344]\n",
      "4.6e-06 3110.0 [0.36089795918367346, 0.363]\n",
      "4.6e-06 3210.0 [0.3610408163265306, 0.385]\n",
      "4.6e-06 3310.0 [0.3523877551020408, 0.358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6e-06 3410.0 [0.3451836734693878, 0.358]\n",
      "4.6e-06 3510.0 [0.3671020408163265, 0.374]\n",
      "4.6e-06 3610.0 [0.3344489795918367, 0.32]\n",
      "4.6e-06 3710.0 [0.33479591836734696, 0.34]\n",
      "4.6e-06 3810.0 [0.33271428571428574, 0.348]\n",
      "4.6e-06 3910.0 [0.349, 0.356]\n",
      "4.6e-06 4010.0 [0.3389591836734694, 0.337]\n",
      "4.6e-06 4110.0 [0.3357551020408163, 0.34]\n",
      "4.6e-06 4210.0 [0.3026326530612245, 0.308]\n",
      "4.6e-06 4310.0 [0.3452857142857143, 0.339]\n",
      "4.6e-06 4410.0 [0.34085714285714286, 0.362]\n",
      "4.6e-06 4510.0 [0.33116326530612245, 0.322]\n",
      "4.6e-06 4610.0 [0.3036734693877551, 0.311]\n",
      "4.6e-06 4710.0 [0.34353061224489795, 0.346]\n",
      "4.6e-06 4810.0 [0.34479591836734697, 0.353]\n",
      "4.6e-06 4910.0 [0.3094081632653061, 0.321]\n",
      "4.6e-06 5010.0 [0.35077551020408165, 0.339]\n",
      "4.6e-06 5110.0 [0.3406326530612245, 0.372]\n",
      "4.6e-06 5210.0 [0.31779591836734694, 0.318]\n",
      "4.6e-06 5310.0 [0.34469387755102043, 0.351]\n",
      "4.6e-06 5410.0 [0.32085714285714284, 0.334]\n",
      "4.6e-06 5510.0 [0.31157142857142855, 0.309]\n",
      "4.6e-06 5610.0 [0.32220408163265307, 0.326]\n",
      "4.6e-06 5710.0 [0.31648979591836734, 0.33]\n",
      "4.6e-06 5810.0 [0.3353265306122449, 0.343]\n",
      "4.6e-06 5910.0 [0.3388163265306122, 0.358]\n",
      "4.6e-06 6010.0 [0.3250816326530612, 0.332]\n",
      "4.6e-06 6110.0 [0.3330204081632653, 0.352]\n",
      "4.6e-06 6210.0 [0.3158367346938776, 0.324]\n",
      "4.6e-06 6310.0 [0.317, 0.335]\n",
      "4.6e-06 6410.0 [0.3019387755102041, 0.32]\n",
      "4.6e-06 6510.0 [0.31057142857142855, 0.32]\n",
      "4.6e-06 6610.0 [0.33577551020408164, 0.33]\n",
      "4.6e-06 6710.0 [0.30306122448979594, 0.328]\n",
      "4.6e-06 6810.0 [0.3419591836734694, 0.351]\n",
      "4.6e-06 6910.0 [0.3419795918367347, 0.36]\n",
      "4.6e-06 7010.0 [0.31220408163265306, 0.336]\n",
      "4.6e-06 7110.0 [0.3229183673469388, 0.32]\n",
      "4.6e-06 7210.0 [0.32548979591836735, 0.307]\n",
      "4.6e-06 7310.0 [0.33777551020408164, 0.36]\n",
      "4.6e-06 7410.0 [0.30657142857142855, 0.322]\n",
      "4.6e-06 7510.0 [0.31995918367346937, 0.337]\n",
      "4.6e-06 7610.0 [0.34053061224489795, 0.344]\n",
      "4.6e-06 7710.0 [0.31348979591836734, 0.326]\n",
      "4.6e-06 7810.0 [0.33277551020408164, 0.339]\n",
      "4.6e-06 7910.0 [0.32612244897959186, 0.337]\n",
      "4.6e-06 8010.0 [0.3079795918367347, 0.317]\n",
      "4.6e-06 8110.0 [0.3046530612244898, 0.309]\n",
      "4.6e-06 8210.0 [0.30281632653061225, 0.317]\n",
      "4.6e-06 8310.0 [0.34255102040816326, 0.37]\n",
      "4.6e-06 8410.0 [0.30504081632653063, 0.296]\n",
      "4.6e-06 8510.0 [0.3176734693877551, 0.309]\n",
      "4.6e-06 8610.0 [0.33410204081632655, 0.341]\n",
      "4.6e-06 8710.0 [0.31351020408163266, 0.324]\n",
      "4.6e-06 8810.0 [0.3309795918367347, 0.342]\n",
      "4.6e-06 8910.0 [0.32224489795918365, 0.297]\n",
      "4.6e-06 9010.0 [0.3104081632653061, 0.328]\n",
      "4.6e-06 9110.0 [0.3359795918367347, 0.349]\n",
      "4.6e-06 9210.0 [0.3260612244897959, 0.333]\n",
      "4.6e-06 9310.0 [0.29683673469387756, 0.3]\n",
      "4.6e-06 9410.0 [0.27424489795918366, 0.287]\n",
      "4.6e-06 9510.0 [0.3003265306122449, 0.301]\n",
      "4.6e-06 9610.0 [0.312, 0.307]\n",
      "4.6e-06 9710.0 [0.3212244897959184, 0.33]\n",
      "4.6e-06 9810.0 [0.321530612244898, 0.319]\n",
      "4.6e-06 9910.0 [0.27553061224489794, 0.294]\n",
      "5.0999999999999995e-06 10.0 [0.3666326530612245, 0.334]\n",
      "5.0999999999999995e-06 110.0 [0.3883061224489796, 0.382]\n",
      "5.0999999999999995e-06 210.0 [0.38320408163265307, 0.39]\n",
      "5.0999999999999995e-06 310.0 [0.3830204081632653, 0.367]\n",
      "5.0999999999999995e-06 410.0 [0.3959795918367347, 0.391]\n",
      "5.0999999999999995e-06 510.0 [0.3860612244897959, 0.385]\n",
      "5.0999999999999995e-06 610.0 [0.3720816326530612, 0.376]\n",
      "5.0999999999999995e-06 710.0 [0.3673877551020408, 0.369]\n",
      "5.0999999999999995e-06 810.0 [0.35436734693877553, 0.355]\n",
      "5.0999999999999995e-06 910.0 [0.3633877551020408, 0.348]\n",
      "5.0999999999999995e-06 1010.0 [0.3574897959183673, 0.369]\n",
      "5.0999999999999995e-06 1110.0 [0.3592448979591837, 0.358]\n",
      "5.0999999999999995e-06 1210.0 [0.3593877551020408, 0.347]\n",
      "5.0999999999999995e-06 1310.0 [0.3580204081632653, 0.345]\n",
      "5.0999999999999995e-06 1410.0 [0.35181632653061223, 0.353]\n",
      "5.0999999999999995e-06 1510.0 [0.35212244897959183, 0.339]\n",
      "5.0999999999999995e-06 1610.0 [0.35922448979591837, 0.361]\n",
      "5.0999999999999995e-06 1710.0 [0.345734693877551, 0.34]\n",
      "5.0999999999999995e-06 1810.0 [0.36453061224489797, 0.375]\n",
      "5.0999999999999995e-06 1910.0 [0.36748979591836733, 0.367]\n",
      "5.0999999999999995e-06 2010.0 [0.3431020408163265, 0.346]\n",
      "5.0999999999999995e-06 2110.0 [0.34322448979591835, 0.345]\n",
      "5.0999999999999995e-06 2210.0 [0.3303265306122449, 0.32]\n",
      "5.0999999999999995e-06 2310.0 [0.309469387755102, 0.298]\n",
      "5.0999999999999995e-06 2410.0 [0.356265306122449, 0.377]\n",
      "5.0999999999999995e-06 2510.0 [0.352, 0.377]\n",
      "5.0999999999999995e-06 2610.0 [0.3499591836734694, 0.346]\n",
      "5.0999999999999995e-06 2710.0 [0.3351224489795918, 0.344]\n",
      "5.0999999999999995e-06 2810.0 [0.31118367346938774, 0.322]\n",
      "5.0999999999999995e-06 2910.0 [0.34053061224489795, 0.322]\n",
      "5.0999999999999995e-06 3010.0 [0.3629183673469388, 0.366]\n",
      "5.0999999999999995e-06 3110.0 [0.32922448979591834, 0.313]\n",
      "5.0999999999999995e-06 3210.0 [0.35014285714285714, 0.362]\n",
      "5.0999999999999995e-06 3310.0 [0.34161224489795916, 0.338]\n",
      "5.0999999999999995e-06 3410.0 [0.32324489795918365, 0.344]\n",
      "5.0999999999999995e-06 3510.0 [0.3288979591836735, 0.313]\n",
      "5.0999999999999995e-06 3610.0 [0.34253061224489795, 0.345]\n",
      "5.0999999999999995e-06 3710.0 [0.3496734693877551, 0.354]\n",
      "5.0999999999999995e-06 3810.0 [0.3561020408163265, 0.374]\n",
      "5.0999999999999995e-06 3910.0 [0.3586326530612245, 0.371]\n",
      "5.0999999999999995e-06 4010.0 [0.28753061224489795, 0.306]\n",
      "5.0999999999999995e-06 4110.0 [0.3103061224489796, 0.311]\n",
      "5.0999999999999995e-06 4210.0 [0.27448979591836736, 0.273]\n",
      "5.0999999999999995e-06 4310.0 [0.3137142857142857, 0.317]\n",
      "5.0999999999999995e-06 4410.0 [0.34648979591836737, 0.345]\n",
      "5.0999999999999995e-06 4510.0 [0.30573469387755103, 0.318]\n",
      "5.0999999999999995e-06 4610.0 [0.33316326530612245, 0.333]\n",
      "5.0999999999999995e-06 4710.0 [0.3305102040816327, 0.324]\n",
      "5.0999999999999995e-06 4810.0 [0.33179591836734695, 0.363]\n",
      "5.0999999999999995e-06 4910.0 [0.31020408163265306, 0.336]\n",
      "5.0999999999999995e-06 5010.0 [0.2979387755102041, 0.287]\n",
      "5.0999999999999995e-06 5110.0 [0.2939795918367347, 0.304]\n",
      "5.0999999999999995e-06 5210.0 [0.33555102040816326, 0.322]\n",
      "5.0999999999999995e-06 5310.0 [0.32542857142857146, 0.331]\n",
      "5.0999999999999995e-06 5410.0 [0.33322448979591834, 0.341]\n",
      "5.0999999999999995e-06 5510.0 [0.320530612244898, 0.313]\n",
      "5.0999999999999995e-06 5610.0 [0.3566938775510204, 0.373]\n",
      "5.0999999999999995e-06 5710.0 [0.3060204081632653, 0.288]\n",
      "5.0999999999999995e-06 5810.0 [0.31504081632653064, 0.318]\n",
      "5.0999999999999995e-06 5910.0 [0.3230204081632653, 0.325]\n",
      "5.0999999999999995e-06 6010.0 [0.33377551020408164, 0.349]\n",
      "5.0999999999999995e-06 6110.0 [0.32112244897959186, 0.318]\n",
      "5.0999999999999995e-06 6210.0 [0.2953877551020408, 0.29]\n",
      "5.0999999999999995e-06 6310.0 [0.324530612244898, 0.325]\n",
      "5.0999999999999995e-06 6410.0 [0.23681632653061224, 0.252]\n",
      "5.0999999999999995e-06 6510.0 [0.2748163265306122, 0.279]\n",
      "5.0999999999999995e-06 6610.0 [0.3033061224489796, 0.316]\n",
      "5.0999999999999995e-06 6710.0 [0.3113265306122449, 0.332]\n",
      "5.0999999999999995e-06 6810.0 [0.29812244897959184, 0.313]\n",
      "5.0999999999999995e-06 6910.0 [0.3191428571428571, 0.314]\n",
      "5.0999999999999995e-06 7010.0 [0.29020408163265304, 0.312]\n",
      "5.0999999999999995e-06 7110.0 [0.2893469387755102, 0.288]\n",
      "5.0999999999999995e-06 7210.0 [0.29106122448979593, 0.302]\n",
      "5.0999999999999995e-06 7310.0 [0.2720408163265306, 0.276]\n",
      "5.0999999999999995e-06 7410.0 [0.29942857142857143, 0.307]\n",
      "5.0999999999999995e-06 7510.0 [0.31951020408163266, 0.32]\n",
      "5.0999999999999995e-06 7610.0 [0.3180204081632653, 0.329]\n",
      "5.0999999999999995e-06 7710.0 [0.2320612244897959, 0.246]\n",
      "5.0999999999999995e-06 7810.0 [0.32712244897959186, 0.328]\n",
      "5.0999999999999995e-06 7910.0 [0.3033673469387755, 0.318]\n",
      "5.0999999999999995e-06 8010.0 [0.29836734693877554, 0.318]\n",
      "5.0999999999999995e-06 8110.0 [0.32802040816326533, 0.318]\n",
      "5.0999999999999995e-06 8210.0 [0.2642857142857143, 0.288]\n",
      "5.0999999999999995e-06 8310.0 [0.31012244897959185, 0.302]\n",
      "5.0999999999999995e-06 8410.0 [0.31095918367346936, 0.317]\n",
      "5.0999999999999995e-06 8510.0 [0.27377551020408164, 0.271]\n",
      "5.0999999999999995e-06 8610.0 [0.3134489795918367, 0.315]\n",
      "5.0999999999999995e-06 8710.0 [0.30814285714285716, 0.324]\n",
      "5.0999999999999995e-06 8810.0 [0.31273469387755104, 0.312]\n",
      "5.0999999999999995e-06 8910.0 [0.3001020408163265, 0.29]\n",
      "5.0999999999999995e-06 9010.0 [0.3342040816326531, 0.34]\n",
      "5.0999999999999995e-06 9110.0 [0.3162244897959184, 0.328]\n",
      "5.0999999999999995e-06 9210.0 [0.3001020408163265, 0.312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0999999999999995e-06 9310.0 [0.29081632653061223, 0.304]\n",
      "5.0999999999999995e-06 9410.0 [0.29948979591836733, 0.32]\n",
      "5.0999999999999995e-06 9510.0 [0.29185714285714287, 0.291]\n",
      "5.0999999999999995e-06 9610.0 [0.2574489795918367, 0.274]\n",
      "5.0999999999999995e-06 9710.0 [0.2973265306122449, 0.314]\n",
      "5.0999999999999995e-06 9810.0 [0.305469387755102, 0.311]\n",
      "5.0999999999999995e-06 9910.0 [0.2871020408163265, 0.293]\n",
      "5.6e-06 10.0 [0.3679387755102041, 0.359]\n",
      "5.6e-06 110.0 [0.3706122448979592, 0.371]\n",
      "5.6e-06 210.0 [0.3957551020408163, 0.375]\n",
      "5.6e-06 310.0 [0.37481632653061225, 0.366]\n",
      "5.6e-06 410.0 [0.3906938775510204, 0.378]\n",
      "5.6e-06 510.0 [0.3637755102040816, 0.343]\n",
      "5.6e-06 610.0 [0.38324489795918365, 0.38]\n",
      "5.6e-06 710.0 [0.3720204081632653, 0.37]\n",
      "5.6e-06 810.0 [0.3586122448979592, 0.353]\n",
      "5.6e-06 910.0 [0.34185714285714286, 0.346]\n",
      "5.6e-06 1010.0 [0.356734693877551, 0.352]\n",
      "5.6e-06 1110.0 [0.3431224489795918, 0.336]\n",
      "5.6e-06 1210.0 [0.35775510204081634, 0.367]\n",
      "5.6e-06 1310.0 [0.3689795918367347, 0.343]\n",
      "5.6e-06 1410.0 [0.3380612244897959, 0.351]\n",
      "5.6e-06 1510.0 [0.32481632653061226, 0.339]\n",
      "5.6e-06 1610.0 [0.32493877551020406, 0.318]\n",
      "5.6e-06 1710.0 [0.33183673469387753, 0.323]\n",
      "5.6e-06 1810.0 [0.362, 0.359]\n",
      "5.6e-06 1910.0 [0.35061224489795917, 0.364]\n",
      "5.6e-06 2010.0 [0.3543061224489796, 0.363]\n",
      "5.6e-06 2110.0 [0.3037142857142857, 0.317]\n",
      "5.6e-06 2210.0 [0.32977551020408163, 0.328]\n",
      "5.6e-06 2310.0 [0.31779591836734694, 0.308]\n",
      "5.6e-06 2410.0 [0.32448979591836735, 0.31]\n",
      "5.6e-06 2510.0 [0.29689795918367345, 0.304]\n",
      "5.6e-06 2610.0 [0.33448979591836736, 0.349]\n",
      "5.6e-06 2710.0 [0.3200204081632653, 0.333]\n",
      "5.6e-06 2810.0 [0.3112857142857143, 0.33]\n",
      "5.6e-06 2910.0 [0.3536530612244898, 0.353]\n",
      "5.6e-06 3010.0 [0.3087142857142857, 0.318]\n",
      "5.6e-06 3110.0 [0.3390612244897959, 0.355]\n",
      "5.6e-06 3210.0 [0.3382857142857143, 0.339]\n",
      "5.6e-06 3310.0 [0.2786326530612245, 0.261]\n",
      "5.6e-06 3410.0 [0.2986734693877551, 0.28]\n",
      "5.6e-06 3510.0 [0.34085714285714286, 0.334]\n",
      "5.6e-06 3610.0 [0.3472448979591837, 0.358]\n",
      "5.6e-06 3710.0 [0.3419387755102041, 0.353]\n",
      "5.6e-06 3810.0 [0.26383673469387753, 0.277]\n",
      "5.6e-06 3910.0 [0.3303673469387755, 0.345]\n",
      "5.6e-06 4010.0 [0.2974081632653061, 0.306]\n",
      "5.6e-06 4110.0 [0.29853061224489796, 0.311]\n",
      "5.6e-06 4210.0 [0.32585714285714285, 0.338]\n",
      "5.6e-06 4310.0 [0.3216122448979592, 0.316]\n",
      "5.6e-06 4410.0 [0.2994081632653061, 0.301]\n",
      "5.6e-06 4510.0 [0.29689795918367345, 0.308]\n",
      "5.6e-06 4610.0 [0.3295102040816327, 0.354]\n",
      "5.6e-06 4710.0 [0.2923265306122449, 0.288]\n",
      "5.6e-06 4810.0 [0.33363265306122447, 0.335]\n",
      "5.6e-06 4910.0 [0.309, 0.333]\n",
      "5.6e-06 5010.0 [0.29587755102040814, 0.312]\n",
      "5.6e-06 5110.0 [0.29216326530612247, 0.289]\n",
      "5.6e-06 5210.0 [0.32073469387755105, 0.328]\n",
      "5.6e-06 5310.0 [0.29646938775510207, 0.294]\n",
      "5.6e-06 5410.0 [0.33510204081632655, 0.332]\n",
      "5.6e-06 5510.0 [0.2926326530612245, 0.322]\n",
      "5.6e-06 5610.0 [0.3304285714285714, 0.337]\n",
      "5.6e-06 5710.0 [0.29753061224489796, 0.317]\n",
      "5.6e-06 5810.0 [0.3415918367346939, 0.347]\n",
      "5.6e-06 5910.0 [0.3193061224489796, 0.316]\n",
      "5.6e-06 6010.0 [0.29006122448979593, 0.287]\n",
      "5.6e-06 6110.0 [0.33155102040816326, 0.339]\n",
      "5.6e-06 6210.0 [0.31020408163265306, 0.303]\n",
      "5.6e-06 6310.0 [0.329265306122449, 0.321]\n",
      "5.6e-06 6410.0 [0.30228571428571427, 0.31]\n",
      "5.6e-06 6510.0 [0.2929795918367347, 0.299]\n",
      "5.6e-06 6610.0 [0.26581632653061227, 0.314]\n",
      "5.6e-06 6710.0 [0.3232857142857143, 0.326]\n",
      "5.6e-06 6810.0 [0.2956326530612245, 0.286]\n",
      "5.6e-06 6910.0 [0.2917142857142857, 0.325]\n",
      "5.6e-06 7010.0 [0.2780612244897959, 0.3]\n",
      "5.6e-06 7110.0 [0.2573469387755102, 0.265]\n",
      "5.6e-06 7210.0 [0.3243265306122449, 0.336]\n",
      "5.6e-06 7310.0 [0.2886530612244898, 0.308]\n",
      "5.6e-06 7410.0 [0.2733469387755102, 0.273]\n",
      "5.6e-06 7510.0 [0.29667346938775513, 0.3]\n",
      "5.6e-06 7610.0 [0.2740612244897959, 0.273]\n",
      "5.6e-06 7710.0 [0.29046938775510206, 0.297]\n",
      "5.6e-06 7810.0 [0.27846938775510205, 0.285]\n",
      "5.6e-06 7910.0 [0.2973469387755102, 0.322]\n",
      "5.6e-06 8010.0 [0.339734693877551, 0.358]\n",
      "5.6e-06 8110.0 [0.28585714285714287, 0.301]\n",
      "5.6e-06 8210.0 [0.29889795918367346, 0.298]\n",
      "5.6e-06 8310.0 [0.2723673469387755, 0.29]\n",
      "5.6e-06 8410.0 [0.31373469387755104, 0.326]\n",
      "5.6e-06 8510.0 [0.24420408163265306, 0.256]\n",
      "5.6e-06 8610.0 [0.29946938775510207, 0.294]\n",
      "5.6e-06 8710.0 [0.26293877551020406, 0.27]\n",
      "5.6e-06 8810.0 [0.2240204081632653, 0.234]\n",
      "5.6e-06 8910.0 [0.2403673469387755, 0.265]\n",
      "5.6e-06 9010.0 [0.2913061224489796, 0.291]\n",
      "5.6e-06 9110.0 [0.3063469387755102, 0.318]\n",
      "5.6e-06 9210.0 [0.3033061224489796, 0.339]\n",
      "5.6e-06 9310.0 [0.3040408163265306, 0.321]\n",
      "5.6e-06 9410.0 [0.2874285714285714, 0.286]\n",
      "5.6e-06 9510.0 [0.25618367346938775, 0.269]\n",
      "5.6e-06 9610.0 [0.2583469387755102, 0.262]\n",
      "5.6e-06 9710.0 [0.29085714285714287, 0.302]\n",
      "5.6e-06 9810.0 [0.2893673469387755, 0.287]\n",
      "5.6e-06 9910.0 [0.2979387755102041, 0.322]\n",
      "6.1e-06 10.0 [0.358265306122449, 0.364]\n",
      "6.1e-06 110.0 [0.3770204081632653, 0.358]\n",
      "6.1e-06 210.0 [0.36912244897959184, 0.352]\n",
      "6.1e-06 310.0 [0.38140816326530613, 0.354]\n",
      "6.1e-06 410.0 [0.3484081632653061, 0.372]\n",
      "6.1e-06 510.0 [0.33979591836734696, 0.338]\n",
      "6.1e-06 610.0 [0.3652448979591837, 0.363]\n",
      "6.1e-06 710.0 [0.3763061224489796, 0.367]\n",
      "6.1e-06 810.0 [0.325734693877551, 0.329]\n",
      "6.1e-06 910.0 [0.3510204081632653, 0.333]\n",
      "6.1e-06 1010.0 [0.32181632653061226, 0.334]\n",
      "6.1e-06 1110.0 [0.33308163265306123, 0.318]\n",
      "6.1e-06 1210.0 [0.33122448979591834, 0.334]\n",
      "6.1e-06 1310.0 [0.35789795918367345, 0.351]\n",
      "6.1e-06 1410.0 [0.3090816326530612, 0.311]\n",
      "6.1e-06 1510.0 [0.33155102040816326, 0.329]\n",
      "6.1e-06 1610.0 [0.33783673469387754, 0.328]\n",
      "6.1e-06 1710.0 [0.3290408163265306, 0.33]\n",
      "6.1e-06 1810.0 [0.32385714285714284, 0.329]\n",
      "6.1e-06 1910.0 [0.34120408163265303, 0.346]\n",
      "6.1e-06 2010.0 [0.33424489795918366, 0.336]\n",
      "6.1e-06 2110.0 [0.32787755102040816, 0.321]\n",
      "6.1e-06 2210.0 [0.31095918367346936, 0.314]\n",
      "6.1e-06 2310.0 [0.31651020408163266, 0.332]\n",
      "6.1e-06 2410.0 [0.3150204081632653, 0.332]\n",
      "6.1e-06 2510.0 [0.30381632653061225, 0.316]\n",
      "6.1e-06 2610.0 [0.3239591836734694, 0.297]\n",
      "6.1e-06 2710.0 [0.32802040816326533, 0.318]\n",
      "6.1e-06 2810.0 [0.30518367346938774, 0.296]\n",
      "6.1e-06 2910.0 [0.2476734693877551, 0.265]\n",
      "6.1e-06 3010.0 [0.33346938775510204, 0.338]\n",
      "6.1e-06 3110.0 [0.30779591836734693, 0.313]\n",
      "6.1e-06 3210.0 [0.34716326530612246, 0.355]\n",
      "6.1e-06 3310.0 [0.3196938775510204, 0.327]\n",
      "6.1e-06 3410.0 [0.30128571428571427, 0.292]\n",
      "6.1e-06 3510.0 [0.30220408163265305, 0.294]\n",
      "6.1e-06 3610.0 [0.3197551020408163, 0.311]\n",
      "6.1e-06 3710.0 [0.2990408163265306, 0.324]\n",
      "6.1e-06 3810.0 [0.267, 0.26]\n",
      "6.1e-06 3910.0 [0.30087755102040814, 0.324]\n",
      "6.1e-06 4010.0 [0.3020204081632653, 0.299]\n",
      "6.1e-06 4110.0 [0.3000408163265306, 0.326]\n",
      "6.1e-06 4210.0 [0.3047755102040816, 0.323]\n",
      "6.1e-06 4310.0 [0.2947959183673469, 0.278]\n",
      "6.1e-06 4410.0 [0.298265306122449, 0.302]\n",
      "6.1e-06 4510.0 [0.27183673469387754, 0.291]\n",
      "6.1e-06 4610.0 [0.29775510204081634, 0.319]\n",
      "6.1e-06 4710.0 [0.27324489795918366, 0.292]\n",
      "6.1e-06 4810.0 [0.27277551020408164, 0.273]\n",
      "6.1e-06 4910.0 [0.30036734693877554, 0.299]\n",
      "6.1e-06 5010.0 [0.3039387755102041, 0.313]\n",
      "6.1e-06 5110.0 [0.24932653061224488, 0.259]\n",
      "6.1e-06 5210.0 [0.2970204081632653, 0.299]\n",
      "6.1e-06 5310.0 [0.26493877551020406, 0.265]\n",
      "6.1e-06 5410.0 [0.3183469387755102, 0.346]\n",
      "6.1e-06 5510.0 [0.2812857142857143, 0.273]\n",
      "6.1e-06 5610.0 [0.2549387755102041, 0.264]\n",
      "6.1e-06 5710.0 [0.2738163265306122, 0.291]\n",
      "6.1e-06 5810.0 [0.30612244897959184, 0.318]\n",
      "6.1e-06 5910.0 [0.2732857142857143, 0.291]\n",
      "6.1e-06 6010.0 [0.298, 0.303]\n",
      "6.1e-06 6110.0 [0.28746938775510206, 0.287]\n",
      "6.1e-06 6210.0 [0.26363265306122446, 0.273]\n",
      "6.1e-06 6310.0 [0.27279591836734696, 0.267]\n",
      "6.1e-06 6410.0 [0.3063265306122449, 0.304]\n",
      "6.1e-06 6510.0 [0.2844081632653061, 0.285]\n",
      "6.1e-06 6610.0 [0.21140816326530612, 0.213]\n",
      "6.1e-06 6710.0 [0.2990204081632653, 0.301]\n",
      "6.1e-06 6810.0 [0.24440816326530612, 0.253]\n",
      "6.1e-06 6910.0 [0.2682857142857143, 0.27]\n",
      "6.1e-06 7010.0 [0.2841836734693878, 0.285]\n",
      "6.1e-06 7110.0 [0.30981632653061225, 0.299]\n",
      "6.1e-06 7210.0 [0.2801836734693878, 0.27]\n",
      "6.1e-06 7310.0 [0.228, 0.253]\n",
      "6.1e-06 7410.0 [0.28453061224489795, 0.274]\n",
      "6.1e-06 7510.0 [0.28024489795918367, 0.288]\n",
      "6.1e-06 7610.0 [0.2790408163265306, 0.292]\n",
      "6.1e-06 7710.0 [0.29553061224489796, 0.299]\n",
      "6.1e-06 7810.0 [0.2789387755102041, 0.302]\n",
      "6.1e-06 7910.0 [0.25657142857142856, 0.256]\n",
      "6.1e-06 8010.0 [0.2913877551020408, 0.281]\n",
      "6.1e-06 8110.0 [0.28620408163265304, 0.313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.1e-06 8210.0 [0.28469387755102044, 0.279]\n",
      "6.1e-06 8310.0 [0.2758979591836735, 0.292]\n",
      "6.1e-06 8410.0 [0.2065918367346939, 0.192]\n",
      "6.1e-06 8510.0 [0.25671428571428573, 0.286]\n",
      "6.1e-06 8610.0 [0.24485714285714286, 0.266]\n",
      "6.1e-06 8710.0 [0.2802857142857143, 0.287]\n",
      "6.1e-06 8810.0 [0.2901020408163265, 0.311]\n",
      "6.1e-06 8910.0 [0.2869591836734694, 0.29]\n",
      "6.1e-06 9010.0 [0.27414285714285713, 0.287]\n",
      "6.1e-06 9110.0 [0.267265306122449, 0.281]\n",
      "6.1e-06 9210.0 [0.3053061224489796, 0.307]\n",
      "6.1e-06 9310.0 [0.2765102040816326, 0.288]\n",
      "6.1e-06 9410.0 [0.2997142857142857, 0.322]\n",
      "6.1e-06 9510.0 [0.27579591836734696, 0.292]\n",
      "6.1e-06 9610.0 [0.2621428571428571, 0.27]\n",
      "6.1e-06 9710.0 [0.22159183673469388, 0.221]\n",
      "6.1e-06 9810.0 [0.23795918367346938, 0.244]\n",
      "6.1e-06 9910.0 [0.26587755102040816, 0.269]\n",
      "6.5999999999999995e-06 10.0 [0.32126530612244897, 0.319]\n",
      "6.5999999999999995e-06 110.0 [0.35114285714285715, 0.328]\n",
      "6.5999999999999995e-06 210.0 [0.3566938775510204, 0.318]\n",
      "6.5999999999999995e-06 310.0 [0.3565714285714286, 0.31]\n",
      "6.5999999999999995e-06 410.0 [0.3293877551020408, 0.342]\n",
      "6.5999999999999995e-06 510.0 [0.3423469387755102, 0.319]\n",
      "6.5999999999999995e-06 610.0 [0.34814285714285714, 0.349]\n",
      "6.5999999999999995e-06 710.0 [0.2803265306122449, 0.282]\n",
      "6.5999999999999995e-06 810.0 [0.3414081632653061, 0.326]\n",
      "6.5999999999999995e-06 910.0 [0.3679183673469388, 0.358]\n",
      "6.5999999999999995e-06 1010.0 [0.3263877551020408, 0.311]\n",
      "6.5999999999999995e-06 1110.0 [0.3274489795918367, 0.313]\n",
      "6.5999999999999995e-06 1210.0 [0.3190204081632653, 0.316]\n",
      "6.5999999999999995e-06 1310.0 [0.3089387755102041, 0.302]\n",
      "6.5999999999999995e-06 1410.0 [0.2931020408163265, 0.295]\n",
      "6.5999999999999995e-06 1510.0 [0.31955102040816324, 0.331]\n",
      "6.5999999999999995e-06 1610.0 [0.33822448979591835, 0.348]\n",
      "6.5999999999999995e-06 1710.0 [0.3057755102040816, 0.313]\n",
      "6.5999999999999995e-06 1810.0 [0.2847142857142857, 0.291]\n",
      "6.5999999999999995e-06 1910.0 [0.3169183673469388, 0.325]\n",
      "6.5999999999999995e-06 2010.0 [0.27361224489795916, 0.279]\n",
      "6.5999999999999995e-06 2110.0 [0.33593877551020407, 0.343]\n",
      "6.5999999999999995e-06 2210.0 [0.30920408163265306, 0.295]\n",
      "6.5999999999999995e-06 2310.0 [0.32379591836734695, 0.315]\n",
      "6.5999999999999995e-06 2410.0 [0.31165306122448977, 0.327]\n",
      "6.5999999999999995e-06 2510.0 [0.3029795918367347, 0.315]\n",
      "6.5999999999999995e-06 2610.0 [0.29989795918367346, 0.33]\n",
      "6.5999999999999995e-06 2710.0 [0.31612244897959185, 0.313]\n",
      "6.5999999999999995e-06 2810.0 [0.3146122448979592, 0.332]\n",
      "6.5999999999999995e-06 2910.0 [0.34708163265306125, 0.352]\n",
      "6.5999999999999995e-06 3010.0 [0.30048979591836733, 0.29]\n",
      "6.5999999999999995e-06 3110.0 [0.31183673469387757, 0.329]\n",
      "6.5999999999999995e-06 3210.0 [0.2979387755102041, 0.309]\n",
      "6.5999999999999995e-06 3310.0 [0.2967755102040816, 0.302]\n",
      "6.5999999999999995e-06 3410.0 [0.2957959183673469, 0.315]\n",
      "6.5999999999999995e-06 3510.0 [0.2806530612244898, 0.293]\n",
      "6.5999999999999995e-06 3610.0 [0.3223061224489796, 0.314]\n",
      "6.5999999999999995e-06 3710.0 [0.31165306122448977, 0.321]\n",
      "6.5999999999999995e-06 3810.0 [0.28738775510204084, 0.292]\n",
      "6.5999999999999995e-06 3910.0 [0.2881224489795918, 0.282]\n",
      "6.5999999999999995e-06 4010.0 [0.3405918367346939, 0.348]\n",
      "6.5999999999999995e-06 4110.0 [0.3203877551020408, 0.307]\n",
      "6.5999999999999995e-06 4210.0 [0.31326530612244896, 0.317]\n",
      "6.5999999999999995e-06 4310.0 [0.26971428571428574, 0.268]\n",
      "6.5999999999999995e-06 4410.0 [0.22973469387755102, 0.253]\n",
      "6.5999999999999995e-06 4510.0 [0.26648979591836736, 0.268]\n",
      "6.5999999999999995e-06 4610.0 [0.315469387755102, 0.331]\n",
      "6.5999999999999995e-06 4710.0 [0.24716326530612245, 0.256]\n",
      "6.5999999999999995e-06 4810.0 [0.2944897959183673, 0.305]\n",
      "6.5999999999999995e-06 4910.0 [0.3258367346938775, 0.325]\n",
      "6.5999999999999995e-06 5010.0 [0.2977755102040816, 0.305]\n",
      "6.5999999999999995e-06 5110.0 [0.25971428571428573, 0.264]\n",
      "6.5999999999999995e-06 5210.0 [0.251469387755102, 0.257]\n",
      "6.5999999999999995e-06 5310.0 [0.2626122448979592, 0.274]\n",
      "6.5999999999999995e-06 5410.0 [0.2963877551020408, 0.318]\n",
      "6.5999999999999995e-06 5510.0 [0.24024489795918366, 0.238]\n",
      "6.5999999999999995e-06 5610.0 [0.25816326530612244, 0.262]\n",
      "6.5999999999999995e-06 5710.0 [0.3063673469387755, 0.318]\n",
      "6.5999999999999995e-06 5810.0 [0.2519795918367347, 0.257]\n",
      "6.5999999999999995e-06 5910.0 [0.2755918367346939, 0.288]\n",
      "6.5999999999999995e-06 6010.0 [0.2817142857142857, 0.294]\n",
      "6.5999999999999995e-06 6110.0 [0.32485714285714284, 0.346]\n",
      "6.5999999999999995e-06 6210.0 [0.2799387755102041, 0.296]\n",
      "6.5999999999999995e-06 6310.0 [0.28944897959183674, 0.301]\n",
      "6.5999999999999995e-06 6410.0 [0.24124489795918366, 0.242]\n",
      "6.5999999999999995e-06 6510.0 [0.25910204081632654, 0.254]\n",
      "6.5999999999999995e-06 6610.0 [0.26746938775510204, 0.281]\n",
      "6.5999999999999995e-06 6710.0 [0.264265306122449, 0.281]\n",
      "6.5999999999999995e-06 6810.0 [0.27769387755102043, 0.275]\n",
      "6.5999999999999995e-06 6910.0 [0.2243673469387755, 0.225]\n",
      "6.5999999999999995e-06 7010.0 [0.2746938775510204, 0.275]\n",
      "6.5999999999999995e-06 7110.0 [0.2855918367346939, 0.307]\n",
      "6.5999999999999995e-06 7210.0 [0.21548979591836734, 0.22]\n",
      "6.5999999999999995e-06 7310.0 [0.2597755102040816, 0.272]\n",
      "6.5999999999999995e-06 7410.0 [0.22975510204081634, 0.249]\n",
      "6.5999999999999995e-06 7510.0 [0.2126530612244898, 0.221]\n",
      "6.5999999999999995e-06 7610.0 [0.2979387755102041, 0.301]\n",
      "6.5999999999999995e-06 7710.0 [0.19789795918367348, 0.213]\n",
      "6.5999999999999995e-06 7810.0 [0.2629591836734694, 0.281]\n",
      "6.5999999999999995e-06 7910.0 [0.25120408163265306, 0.275]\n",
      "6.5999999999999995e-06 8010.0 [0.2563673469387755, 0.29]\n",
      "6.5999999999999995e-06 8110.0 [0.3136326530612245, 0.31]\n",
      "6.5999999999999995e-06 8210.0 [0.2543265306122449, 0.27]\n",
      "6.5999999999999995e-06 8310.0 [0.2516122448979592, 0.264]\n",
      "6.5999999999999995e-06 8410.0 [0.2287142857142857, 0.23]\n",
      "6.5999999999999995e-06 8510.0 [0.22859183673469388, 0.246]\n",
      "6.5999999999999995e-06 8610.0 [0.29046938775510206, 0.287]\n",
      "6.5999999999999995e-06 8710.0 [0.2571428571428571, 0.266]\n",
      "6.5999999999999995e-06 8810.0 [0.24724489795918367, 0.24]\n",
      "6.5999999999999995e-06 8910.0 [0.216, 0.219]\n",
      "6.5999999999999995e-06 9010.0 [0.24271428571428572, 0.249]\n",
      "6.5999999999999995e-06 9110.0 [0.2883061224489796, 0.289]\n",
      "6.5999999999999995e-06 9210.0 [0.2735714285714286, 0.267]\n",
      "6.5999999999999995e-06 9310.0 [0.26418367346938776, 0.28]\n",
      "6.5999999999999995e-06 9410.0 [0.23283673469387756, 0.258]\n",
      "6.5999999999999995e-06 9510.0 [0.23951020408163265, 0.249]\n",
      "6.5999999999999995e-06 9610.0 [0.2583673469387755, 0.266]\n",
      "6.5999999999999995e-06 9710.0 [0.24753061224489795, 0.269]\n",
      "6.5999999999999995e-06 9810.0 [0.25557142857142856, 0.24]\n",
      "6.5999999999999995e-06 9910.0 [0.24518367346938774, 0.248]\n",
      "7.1e-06 10.0 [0.33, 0.31]\n",
      "7.1e-06 110.0 [0.35653061224489796, 0.359]\n",
      "7.1e-06 210.0 [0.3475714285714286, 0.326]\n",
      "7.1e-06 310.0 [0.3216326530612245, 0.299]\n",
      "7.1e-06 410.0 [0.3773877551020408, 0.36]\n",
      "7.1e-06 510.0 [0.3240408163265306, 0.316]\n",
      "7.1e-06 610.0 [0.3097551020408163, 0.29]\n",
      "7.1e-06 710.0 [0.3279591836734694, 0.34]\n",
      "7.1e-06 810.0 [0.3117755102040816, 0.321]\n",
      "7.1e-06 910.0 [0.33708163265306124, 0.342]\n",
      "7.1e-06 1010.0 [0.30795918367346936, 0.319]\n",
      "7.1e-06 1110.0 [0.3425714285714286, 0.34]\n",
      "7.1e-06 1210.0 [0.2866530612244898, 0.31]\n",
      "7.1e-06 1310.0 [0.29581632653061224, 0.303]\n",
      "7.1e-06 1410.0 [0.30687755102040815, 0.312]\n",
      "7.1e-06 1510.0 [0.3017755102040816, 0.313]\n",
      "7.1e-06 1610.0 [0.29520408163265305, 0.297]\n",
      "7.1e-06 1710.0 [0.272, 0.288]\n",
      "7.1e-06 1810.0 [0.3057755102040816, 0.32]\n",
      "7.1e-06 1910.0 [0.30214285714285716, 0.28]\n",
      "7.1e-06 2010.0 [0.3329591836734694, 0.346]\n",
      "7.1e-06 2110.0 [0.2856530612244898, 0.295]\n",
      "7.1e-06 2210.0 [0.2619795918367347, 0.254]\n",
      "7.1e-06 2310.0 [0.30342857142857144, 0.303]\n",
      "7.1e-06 2410.0 [0.27744897959183673, 0.291]\n",
      "7.1e-06 2510.0 [0.24120408163265306, 0.243]\n",
      "7.1e-06 2610.0 [0.29606122448979594, 0.336]\n",
      "7.1e-06 2710.0 [0.30289795918367346, 0.317]\n",
      "7.1e-06 2810.0 [0.2590204081632653, 0.265]\n",
      "7.1e-06 2910.0 [0.2720408163265306, 0.276]\n",
      "7.1e-06 3010.0 [0.3152857142857143, 0.287]\n",
      "7.1e-06 3110.0 [0.24787755102040818, 0.258]\n",
      "7.1e-06 3210.0 [0.2742040816326531, 0.281]\n",
      "7.1e-06 3310.0 [0.2982448979591837, 0.3]\n",
      "7.1e-06 3410.0 [0.2850408163265306, 0.289]\n",
      "7.1e-06 3510.0 [0.2801020408163265, 0.291]\n",
      "7.1e-06 3610.0 [0.28946938775510206, 0.301]\n",
      "7.1e-06 3710.0 [0.30142857142857143, 0.286]\n",
      "7.1e-06 3810.0 [0.2516122448979592, 0.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.1e-06 3910.0 [0.2743265306122449, 0.276]\n",
      "7.1e-06 4010.0 [0.26416326530612244, 0.278]\n",
      "7.1e-06 4110.0 [0.2969387755102041, 0.293]\n",
      "7.1e-06 4210.0 [0.25940816326530614, 0.288]\n",
      "7.1e-06 4310.0 [0.28744897959183674, 0.297]\n",
      "7.1e-06 4410.0 [0.252530612244898, 0.259]\n",
      "7.1e-06 4510.0 [0.30044897959183675, 0.304]\n",
      "7.1e-06 4610.0 [0.23738775510204083, 0.248]\n",
      "7.1e-06 4710.0 [0.2719591836734694, 0.283]\n",
      "7.1e-06 4810.0 [0.2506734693877551, 0.257]\n",
      "7.1e-06 4910.0 [0.2423265306122449, 0.252]\n",
      "7.1e-06 5010.0 [0.2895510204081633, 0.304]\n",
      "7.1e-06 5110.0 [0.2526326530612245, 0.259]\n",
      "7.1e-06 5210.0 [0.2608979591836735, 0.283]\n",
      "7.1e-06 5310.0 [0.27830612244897956, 0.293]\n",
      "7.1e-06 5410.0 [0.2375918367346939, 0.259]\n",
      "7.1e-06 5510.0 [0.27622448979591835, 0.293]\n",
      "7.1e-06 5610.0 [0.26685714285714285, 0.27]\n",
      "7.1e-06 5710.0 [0.2820204081632653, 0.281]\n",
      "7.1e-06 5810.0 [0.3056122448979592, 0.312]\n",
      "7.1e-06 5910.0 [0.2116326530612245, 0.208]\n",
      "7.1e-06 6010.0 [0.2976938775510204, 0.314]\n",
      "7.1e-06 6110.0 [0.2517142857142857, 0.274]\n",
      "7.1e-06 6210.0 [0.23461224489795918, 0.259]\n",
      "7.1e-06 6310.0 [0.27293877551020407, 0.282]\n",
      "7.1e-06 6410.0 [0.2899591836734694, 0.293]\n",
      "7.1e-06 6510.0 [0.23334693877551022, 0.26]\n",
      "7.1e-06 6610.0 [0.2732040816326531, 0.285]\n",
      "7.1e-06 6710.0 [0.25955102040816325, 0.274]\n",
      "7.1e-06 6810.0 [0.22008163265306122, 0.231]\n",
      "7.1e-06 6910.0 [0.24346938775510205, 0.254]\n",
      "7.1e-06 7010.0 [0.23610204081632652, 0.256]\n",
      "7.1e-06 7110.0 [0.2636734693877551, 0.281]\n",
      "7.1e-06 7210.0 [0.21679591836734693, 0.221]\n",
      "7.1e-06 7310.0 [0.2609183673469388, 0.261]\n",
      "7.1e-06 7410.0 [0.29083673469387755, 0.287]\n",
      "7.1e-06 7510.0 [0.29816326530612247, 0.32]\n",
      "7.1e-06 7610.0 [0.2416938775510204, 0.246]\n",
      "7.1e-06 7710.0 [0.24222448979591837, 0.254]\n",
      "7.1e-06 7810.0 [0.23959183673469386, 0.241]\n",
      "7.1e-06 7910.0 [0.2609591836734694, 0.263]\n",
      "7.1e-06 8010.0 [0.22855102040816327, 0.239]\n",
      "7.1e-06 8110.0 [0.22075510204081633, 0.228]\n",
      "7.1e-06 8210.0 [0.2433061224489796, 0.254]\n",
      "7.1e-06 8310.0 [0.2890204081632653, 0.289]\n",
      "7.1e-06 8410.0 [0.24142857142857144, 0.245]\n",
      "7.1e-06 8510.0 [0.2100408163265306, 0.209]\n",
      "7.1e-06 8610.0 [0.21426530612244898, 0.234]\n",
      "7.1e-06 8710.0 [0.2206122448979592, 0.234]\n",
      "7.1e-06 8810.0 [0.27985714285714286, 0.305]\n",
      "7.1e-06 8910.0 [0.2800204081632653, 0.295]\n",
      "7.1e-06 9010.0 [0.2946938775510204, 0.298]\n",
      "7.1e-06 9110.0 [0.2625918367346939, 0.276]\n",
      "7.1e-06 9210.0 [0.2619795918367347, 0.284]\n",
      "7.1e-06 9310.0 [0.2466734693877551, 0.261]\n",
      "7.1e-06 9410.0 [0.20879591836734693, 0.201]\n",
      "7.1e-06 9510.0 [0.25526530612244897, 0.276]\n",
      "7.1e-06 9610.0 [0.20530612244897958, 0.21]\n",
      "7.1e-06 9710.0 [0.29344897959183674, 0.318]\n",
      "7.1e-06 9810.0 [0.23595918367346938, 0.249]\n",
      "7.1e-06 9910.0 [0.20989795918367346, 0.215]\n",
      "7.599999999999999e-06 10.0 [0.3375918367346939, 0.326]\n",
      "7.599999999999999e-06 110.0 [0.3410612244897959, 0.331]\n",
      "7.599999999999999e-06 210.0 [0.3735510204081633, 0.348]\n",
      "7.599999999999999e-06 310.0 [0.3175918367346939, 0.323]\n",
      "7.599999999999999e-06 410.0 [0.2958571428571429, 0.283]\n",
      "7.599999999999999e-06 510.0 [0.295, 0.295]\n",
      "7.599999999999999e-06 610.0 [0.3410612244897959, 0.338]\n",
      "7.599999999999999e-06 710.0 [0.23316326530612244, 0.242]\n",
      "7.599999999999999e-06 810.0 [0.29412244897959183, 0.293]\n",
      "7.599999999999999e-06 910.0 [0.31920408163265307, 0.326]\n",
      "7.599999999999999e-06 1010.0 [0.2824081632653061, 0.287]\n",
      "7.599999999999999e-06 1110.0 [0.30904081632653063, 0.326]\n",
      "7.599999999999999e-06 1210.0 [0.2984081632653061, 0.307]\n",
      "7.599999999999999e-06 1310.0 [0.2869387755102041, 0.295]\n",
      "7.599999999999999e-06 1410.0 [0.3206122448979592, 0.338]\n",
      "7.599999999999999e-06 1510.0 [0.28085714285714286, 0.273]\n",
      "7.599999999999999e-06 1610.0 [0.275734693877551, 0.295]\n",
      "7.599999999999999e-06 1710.0 [0.28616326530612246, 0.304]\n",
      "7.599999999999999e-06 1810.0 [0.33708163265306124, 0.303]\n",
      "7.599999999999999e-06 1910.0 [0.27010204081632655, 0.267]\n",
      "7.599999999999999e-06 2010.0 [0.286265306122449, 0.314]\n",
      "7.599999999999999e-06 2110.0 [0.28585714285714287, 0.298]\n",
      "7.599999999999999e-06 2210.0 [0.3119183673469388, 0.325]\n",
      "7.599999999999999e-06 2310.0 [0.2886326530612245, 0.302]\n",
      "7.599999999999999e-06 2410.0 [0.29491836734693877, 0.295]\n",
      "7.599999999999999e-06 2510.0 [0.24410204081632653, 0.255]\n",
      "7.599999999999999e-06 2610.0 [0.26763265306122447, 0.259]\n",
      "7.599999999999999e-06 2710.0 [0.2958571428571429, 0.309]\n",
      "7.599999999999999e-06 2810.0 [0.24897959183673468, 0.263]\n",
      "7.599999999999999e-06 2910.0 [0.2758979591836735, 0.295]\n",
      "7.599999999999999e-06 3010.0 [0.23951020408163265, 0.255]\n",
      "7.599999999999999e-06 3110.0 [0.2512448979591837, 0.254]\n",
      "7.599999999999999e-06 3210.0 [0.2547755102040816, 0.25]\n",
      "7.599999999999999e-06 3310.0 [0.2773061224489796, 0.274]\n",
      "7.599999999999999e-06 3410.0 [0.28689795918367345, 0.301]\n",
      "7.599999999999999e-06 3510.0 [0.27724489795918367, 0.265]\n",
      "7.599999999999999e-06 3610.0 [0.28216326530612246, 0.304]\n",
      "7.599999999999999e-06 3710.0 [0.24422448979591838, 0.24]\n",
      "7.599999999999999e-06 3810.0 [0.2609591836734694, 0.289]\n",
      "7.599999999999999e-06 3910.0 [0.21493877551020407, 0.217]\n",
      "7.599999999999999e-06 4010.0 [0.2622244897959184, 0.285]\n",
      "7.599999999999999e-06 4110.0 [0.25065306122448977, 0.28]\n",
      "7.599999999999999e-06 4210.0 [0.2386938775510204, 0.249]\n",
      "7.599999999999999e-06 4310.0 [0.23895918367346938, 0.253]\n",
      "7.599999999999999e-06 4410.0 [0.2763265306122449, 0.282]\n",
      "7.599999999999999e-06 4510.0 [0.19514285714285715, 0.202]\n",
      "7.599999999999999e-06 4610.0 [0.26848979591836736, 0.271]\n",
      "7.599999999999999e-06 4710.0 [0.3056122448979592, 0.291]\n",
      "7.599999999999999e-06 4810.0 [0.23304081632653062, 0.253]\n",
      "7.599999999999999e-06 4910.0 [0.2657551020408163, 0.286]\n",
      "7.599999999999999e-06 5010.0 [0.2859795918367347, 0.293]\n",
      "7.599999999999999e-06 5110.0 [0.2642040816326531, 0.271]\n",
      "7.599999999999999e-06 5210.0 [0.26057142857142856, 0.267]\n",
      "7.599999999999999e-06 5310.0 [0.26218367346938776, 0.267]\n",
      "7.599999999999999e-06 5410.0 [0.22528571428571428, 0.24]\n",
      "7.599999999999999e-06 5510.0 [0.24979591836734694, 0.259]\n",
      "7.599999999999999e-06 5610.0 [0.2933265306122449, 0.276]\n",
      "7.599999999999999e-06 5710.0 [0.2788163265306122, 0.268]\n",
      "7.599999999999999e-06 5810.0 [0.23504081632653062, 0.243]\n",
      "7.599999999999999e-06 5910.0 [0.23275510204081631, 0.248]\n",
      "7.599999999999999e-06 6010.0 [0.18979591836734694, 0.205]\n",
      "7.599999999999999e-06 6110.0 [0.28506122448979593, 0.292]\n",
      "7.599999999999999e-06 6210.0 [0.2139591836734694, 0.228]\n",
      "7.599999999999999e-06 6310.0 [0.22112244897959182, 0.228]\n",
      "7.599999999999999e-06 6410.0 [0.2705714285714286, 0.28]\n",
      "7.599999999999999e-06 6510.0 [0.2423061224489796, 0.24]\n",
      "7.599999999999999e-06 6610.0 [0.2777142857142857, 0.262]\n",
      "7.599999999999999e-06 6710.0 [0.19659183673469388, 0.211]\n",
      "7.599999999999999e-06 6810.0 [0.2037142857142857, 0.209]\n",
      "7.599999999999999e-06 6910.0 [0.2446530612244898, 0.245]\n",
      "7.599999999999999e-06 7010.0 [0.21177551020408164, 0.222]\n",
      "7.599999999999999e-06 7110.0 [0.20955102040816326, 0.217]\n",
      "7.599999999999999e-06 7210.0 [0.26202040816326533, 0.265]\n",
      "7.599999999999999e-06 7310.0 [0.22475510204081633, 0.219]\n",
      "7.599999999999999e-06 7410.0 [0.27975510204081633, 0.271]\n",
      "7.599999999999999e-06 7510.0 [0.23853061224489797, 0.236]\n",
      "7.599999999999999e-06 7610.0 [0.27414285714285713, 0.292]\n",
      "7.599999999999999e-06 7710.0 [0.19391836734693876, 0.19]\n",
      "7.599999999999999e-06 7810.0 [0.2897959183673469, 0.293]\n",
      "7.599999999999999e-06 7910.0 [0.246734693877551, 0.255]\n",
      "7.599999999999999e-06 8010.0 [0.2559387755102041, 0.255]\n",
      "7.599999999999999e-06 8110.0 [0.2335918367346939, 0.254]\n",
      "7.599999999999999e-06 8210.0 [0.27410204081632655, 0.299]\n",
      "7.599999999999999e-06 8310.0 [0.21906122448979592, 0.226]\n",
      "7.599999999999999e-06 8410.0 [0.20542857142857143, 0.207]\n",
      "7.599999999999999e-06 8510.0 [0.2307142857142857, 0.242]\n",
      "7.599999999999999e-06 8610.0 [0.20308163265306123, 0.215]\n",
      "7.599999999999999e-06 8710.0 [0.21924489795918367, 0.226]\n",
      "7.599999999999999e-06 8810.0 [0.2463265306122449, 0.288]\n",
      "7.599999999999999e-06 8910.0 [0.23465306122448978, 0.241]\n",
      "7.599999999999999e-06 9010.0 [0.2382857142857143, 0.25]\n",
      "7.599999999999999e-06 9110.0 [0.20942857142857144, 0.208]\n",
      "7.599999999999999e-06 9210.0 [0.25085714285714283, 0.252]\n",
      "7.599999999999999e-06 9310.0 [0.19981632653061224, 0.224]\n",
      "7.599999999999999e-06 9410.0 [0.22759183673469388, 0.242]\n",
      "7.599999999999999e-06 9510.0 [0.24181632653061225, 0.264]\n",
      "7.599999999999999e-06 9610.0 [0.2489591836734694, 0.237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.599999999999999e-06 9710.0 [0.19985714285714284, 0.211]\n",
      "7.599999999999999e-06 9810.0 [0.24026530612244898, 0.244]\n",
      "7.599999999999999e-06 9910.0 [0.22559183673469388, 0.225]\n",
      "8.1e-06 10.0 [0.3378775510204082, 0.344]\n",
      "8.1e-06 110.0 [0.3883673469387755, 0.365]\n",
      "8.1e-06 210.0 [0.2759591836734694, 0.284]\n",
      "8.1e-06 310.0 [0.2926530612244898, 0.273]\n",
      "8.1e-06 410.0 [0.3148367346938776, 0.315]\n",
      "8.1e-06 510.0 [0.31504081632653064, 0.312]\n",
      "8.1e-06 610.0 [0.34575510204081633, 0.328]\n",
      "8.1e-06 710.0 [0.3006938775510204, 0.304]\n",
      "8.1e-06 810.0 [0.2753673469387755, 0.284]\n",
      "8.1e-06 910.0 [0.2933265306122449, 0.277]\n",
      "8.1e-06 1010.0 [0.3240204081632653, 0.318]\n",
      "8.1e-06 1110.0 [0.27638775510204083, 0.292]\n",
      "8.1e-06 1210.0 [0.2808979591836735, 0.266]\n",
      "8.1e-06 1310.0 [0.3355714285714286, 0.359]\n",
      "8.1e-06 1410.0 [0.2626530612244898, 0.26]\n",
      "8.1e-06 1510.0 [0.24863265306122448, 0.257]\n",
      "8.1e-06 1610.0 [0.30118367346938774, 0.31]\n",
      "8.1e-06 1710.0 [0.26783673469387753, 0.272]\n",
      "8.1e-06 1810.0 [0.27114285714285713, 0.294]\n",
      "8.1e-06 1910.0 [0.25757142857142856, 0.267]\n",
      "8.1e-06 2010.0 [0.2864897959183674, 0.281]\n",
      "8.1e-06 2110.0 [0.2794285714285714, 0.287]\n",
      "8.1e-06 2210.0 [0.2756734693877551, 0.286]\n",
      "8.1e-06 2310.0 [0.26918367346938776, 0.27]\n",
      "8.1e-06 2410.0 [0.26010204081632654, 0.273]\n",
      "8.1e-06 2510.0 [0.27685714285714286, 0.298]\n",
      "8.1e-06 2610.0 [0.2629591836734694, 0.264]\n",
      "8.1e-06 2710.0 [0.28222448979591835, 0.284]\n",
      "8.1e-06 2810.0 [0.2697551020408163, 0.287]\n",
      "8.1e-06 2910.0 [0.28114285714285714, 0.281]\n",
      "8.1e-06 3010.0 [0.3316938775510204, 0.322]\n",
      "8.1e-06 3110.0 [0.29318367346938773, 0.311]\n",
      "8.1e-06 3210.0 [0.2143877551020408, 0.202]\n",
      "8.1e-06 3310.0 [0.2507755102040816, 0.256]\n",
      "8.1e-06 3410.0 [0.26863265306122447, 0.271]\n",
      "8.1e-06 3510.0 [0.26116326530612244, 0.261]\n",
      "8.1e-06 3610.0 [0.26185714285714284, 0.27]\n",
      "8.1e-06 3710.0 [0.25373469387755104, 0.281]\n",
      "8.1e-06 3810.0 [0.29083673469387755, 0.29]\n",
      "8.1e-06 3910.0 [0.28508163265306125, 0.308]\n",
      "8.1e-06 4010.0 [0.25079591836734694, 0.243]\n",
      "8.1e-06 4110.0 [0.24906122448979592, 0.268]\n",
      "8.1e-06 4210.0 [0.24942857142857142, 0.252]\n",
      "8.1e-06 4310.0 [0.2503061224489796, 0.265]\n",
      "8.1e-06 4410.0 [0.20789795918367346, 0.242]\n",
      "8.1e-06 4510.0 [0.22679591836734694, 0.237]\n",
      "8.1e-06 4610.0 [0.19787755102040816, 0.205]\n",
      "8.1e-06 4710.0 [0.26985714285714285, 0.297]\n",
      "8.1e-06 4810.0 [0.24651020408163266, 0.254]\n",
      "8.1e-06 4910.0 [0.23059183673469388, 0.254]\n",
      "8.1e-06 5010.0 [0.22189795918367347, 0.24]\n",
      "8.1e-06 5110.0 [0.24340816326530612, 0.228]\n",
      "8.1e-06 5210.0 [0.2269795918367347, 0.238]\n",
      "8.1e-06 5310.0 [0.2767551020408163, 0.285]\n",
      "8.1e-06 5410.0 [0.23269387755102042, 0.231]\n",
      "8.1e-06 5510.0 [0.24589795918367346, 0.263]\n",
      "8.1e-06 5610.0 [0.19914285714285715, 0.205]\n",
      "8.1e-06 5710.0 [0.28244897959183674, 0.292]\n",
      "8.1e-06 5810.0 [0.2372448979591837, 0.218]\n",
      "8.1e-06 5910.0 [0.20989795918367346, 0.205]\n",
      "8.1e-06 6010.0 [0.2349387755102041, 0.235]\n",
      "8.1e-06 6110.0 [0.22451020408163266, 0.234]\n",
      "8.1e-06 6210.0 [0.21520408163265306, 0.239]\n",
      "8.1e-06 6310.0 [0.2509387755102041, 0.239]\n",
      "8.1e-06 6410.0 [0.2570816326530612, 0.256]\n",
      "8.1e-06 6510.0 [0.23344897959183675, 0.253]\n",
      "8.1e-06 6610.0 [0.25687755102040816, 0.259]\n",
      "8.1e-06 6710.0 [0.2476530612244898, 0.281]\n",
      "8.1e-06 6810.0 [0.2102857142857143, 0.215]\n",
      "8.1e-06 6910.0 [0.22606122448979593, 0.235]\n",
      "8.1e-06 7010.0 [0.22483673469387755, 0.218]\n",
      "8.1e-06 7110.0 [0.24040816326530612, 0.247]\n",
      "8.1e-06 7210.0 [0.2263469387755102, 0.218]\n",
      "8.1e-06 7310.0 [0.2286938775510204, 0.239]\n",
      "8.1e-06 7410.0 [0.27455102040816326, 0.277]\n",
      "8.1e-06 7510.0 [0.19779591836734695, 0.208]\n",
      "8.1e-06 7610.0 [0.18355102040816326, 0.202]\n",
      "8.1e-06 7710.0 [0.2086938775510204, 0.232]\n",
      "8.1e-06 7810.0 [0.257530612244898, 0.269]\n",
      "8.1e-06 7910.0 [0.23242857142857143, 0.219]\n",
      "8.1e-06 8010.0 [0.25412244897959185, 0.246]\n",
      "8.1e-06 8110.0 [0.2007142857142857, 0.207]\n",
      "8.1e-06 8210.0 [0.2476530612244898, 0.243]\n",
      "8.1e-06 8310.0 [0.23283673469387756, 0.235]\n",
      "8.1e-06 8410.0 [0.24148979591836733, 0.258]\n",
      "8.1e-06 8510.0 [0.24728571428571428, 0.261]\n",
      "8.1e-06 8610.0 [0.27514285714285713, 0.29]\n",
      "8.1e-06 8710.0 [0.17551020408163265, 0.186]\n",
      "8.1e-06 8810.0 [0.23587755102040817, 0.245]\n",
      "8.1e-06 8910.0 [0.2256734693877551, 0.222]\n",
      "8.1e-06 9010.0 [0.2416326530612245, 0.239]\n",
      "8.1e-06 9110.0 [0.25918367346938775, 0.268]\n",
      "8.1e-06 9210.0 [0.2333265306122449, 0.252]\n",
      "8.1e-06 9310.0 [0.21906122448979592, 0.225]\n",
      "8.1e-06 9410.0 [0.20651020408163265, 0.201]\n",
      "8.1e-06 9510.0 [0.2326734693877551, 0.233]\n",
      "8.1e-06 9610.0 [0.26785714285714285, 0.27]\n",
      "8.1e-06 9710.0 [0.2263673469387755, 0.224]\n",
      "8.1e-06 9810.0 [0.21614285714285714, 0.231]\n",
      "8.1e-06 9910.0 [0.21342857142857144, 0.218]\n",
      "8.6e-06 10.0 [0.3621020408163265, 0.326]\n",
      "8.6e-06 110.0 [0.3560408163265306, 0.358]\n",
      "8.6e-06 210.0 [0.30114285714285716, 0.295]\n",
      "8.6e-06 310.0 [0.3372857142857143, 0.335]\n",
      "8.6e-06 410.0 [0.3367551020408163, 0.332]\n",
      "8.6e-06 510.0 [0.347, 0.345]\n",
      "8.6e-06 610.0 [0.25285714285714284, 0.248]\n",
      "8.6e-06 710.0 [0.2991632653061225, 0.3]\n",
      "8.6e-06 810.0 [0.28379591836734697, 0.287]\n",
      "8.6e-06 910.0 [0.3016734693877551, 0.31]\n",
      "8.6e-06 1010.0 [0.29567346938775513, 0.308]\n",
      "8.6e-06 1110.0 [0.2973265306122449, 0.309]\n",
      "8.6e-06 1210.0 [0.22585714285714287, 0.246]\n",
      "8.6e-06 1310.0 [0.27746938775510205, 0.267]\n",
      "8.6e-06 1410.0 [0.2623469387755102, 0.273]\n",
      "8.6e-06 1510.0 [0.3096938775510204, 0.332]\n",
      "8.6e-06 1610.0 [0.26718367346938776, 0.267]\n",
      "8.6e-06 1710.0 [0.29208163265306125, 0.313]\n",
      "8.6e-06 1810.0 [0.2881020408163265, 0.299]\n",
      "8.6e-06 1910.0 [0.25993877551020406, 0.29]\n",
      "8.6e-06 2010.0 [0.2626122448979592, 0.27]\n",
      "8.6e-06 2110.0 [0.26155102040816325, 0.271]\n",
      "8.6e-06 2210.0 [0.3027142857142857, 0.306]\n",
      "8.6e-06 2310.0 [0.24642857142857144, 0.247]\n",
      "8.6e-06 2410.0 [0.2689591836734694, 0.271]\n",
      "8.6e-06 2510.0 [0.23204081632653062, 0.222]\n",
      "8.6e-06 2610.0 [0.30959183673469387, 0.32]\n",
      "8.6e-06 2710.0 [0.2781224489795918, 0.258]\n",
      "8.6e-06 2810.0 [0.2825714285714286, 0.276]\n",
      "8.6e-06 2910.0 [0.3006734693877551, 0.298]\n",
      "8.6e-06 3010.0 [0.2573265306122449, 0.251]\n",
      "8.6e-06 3110.0 [0.2619591836734694, 0.265]\n",
      "8.6e-06 3210.0 [0.2728163265306122, 0.279]\n",
      "8.6e-06 3310.0 [0.26640816326530614, 0.266]\n",
      "8.6e-06 3410.0 [0.23691836734693877, 0.256]\n",
      "8.6e-06 3510.0 [0.2320204081632653, 0.253]\n",
      "8.6e-06 3610.0 [0.26985714285714285, 0.278]\n",
      "8.6e-06 3710.0 [0.23587755102040817, 0.218]\n",
      "8.6e-06 3810.0 [0.22206122448979593, 0.228]\n",
      "8.6e-06 3910.0 [0.28230612244897957, 0.292]\n",
      "8.6e-06 4010.0 [0.22281632653061226, 0.222]\n",
      "8.6e-06 4110.0 [0.2788775510204082, 0.303]\n",
      "8.6e-06 4210.0 [0.26455102040816325, 0.253]\n",
      "8.6e-06 4310.0 [0.2386734693877551, 0.254]\n",
      "8.6e-06 4410.0 [0.2748775510204082, 0.273]\n",
      "8.6e-06 4510.0 [0.23485714285714285, 0.246]\n",
      "8.6e-06 4610.0 [0.22755102040816327, 0.241]\n",
      "8.6e-06 4710.0 [0.2439591836734694, 0.243]\n",
      "8.6e-06 4810.0 [0.1919795918367347, 0.205]\n",
      "8.6e-06 4910.0 [0.2843469387755102, 0.31]\n",
      "8.6e-06 5010.0 [0.21193877551020407, 0.207]\n",
      "8.6e-06 5110.0 [0.2072857142857143, 0.23]\n",
      "8.6e-06 5210.0 [0.23373469387755103, 0.242]\n",
      "8.6e-06 5310.0 [0.26502040816326533, 0.266]\n",
      "8.6e-06 5410.0 [0.250469387755102, 0.25]\n",
      "8.6e-06 5510.0 [0.26012244897959186, 0.253]\n",
      "8.6e-06 5610.0 [0.22510204081632654, 0.225]\n",
      "8.6e-06 5710.0 [0.26318367346938776, 0.263]\n",
      "8.6e-06 5810.0 [0.23183673469387756, 0.234]\n",
      "8.6e-06 5910.0 [0.25189795918367347, 0.257]\n",
      "8.6e-06 6010.0 [0.220734693877551, 0.249]\n",
      "8.6e-06 6110.0 [0.24887755102040815, 0.271]\n",
      "8.6e-06 6210.0 [0.250530612244898, 0.266]\n",
      "8.6e-06 6310.0 [0.24289795918367346, 0.244]\n",
      "8.6e-06 6410.0 [0.22181632653061226, 0.231]\n",
      "8.6e-06 6510.0 [0.24897959183673468, 0.261]\n",
      "8.6e-06 6610.0 [0.2069387755102041, 0.217]\n",
      "8.6e-06 6710.0 [0.23838775510204083, 0.253]\n",
      "8.6e-06 6810.0 [0.253469387755102, 0.253]\n",
      "8.6e-06 6910.0 [0.19983673469387755, 0.207]\n",
      "8.6e-06 7010.0 [0.2806530612244898, 0.297]\n",
      "8.6e-06 7110.0 [0.2113265306122449, 0.238]\n",
      "8.6e-06 7210.0 [0.22973469387755102, 0.243]\n",
      "8.6e-06 7310.0 [0.21546938775510205, 0.227]\n",
      "8.6e-06 7410.0 [0.20687755102040817, 0.231]\n",
      "8.6e-06 7510.0 [0.22422448979591836, 0.233]\n",
      "8.6e-06 7610.0 [0.23516326530612244, 0.234]\n",
      "8.6e-06 7710.0 [0.27110204081632655, 0.285]\n",
      "8.6e-06 7810.0 [0.1943673469387755, 0.201]\n",
      "8.6e-06 7910.0 [0.23904081632653063, 0.247]\n",
      "8.6e-06 8010.0 [0.2086530612244898, 0.221]\n",
      "8.6e-06 8110.0 [0.24971428571428572, 0.252]\n",
      "8.6e-06 8210.0 [0.17375510204081632, 0.184]\n",
      "8.6e-06 8310.0 [0.24763265306122448, 0.266]\n",
      "8.6e-06 8410.0 [0.25204081632653064, 0.261]\n",
      "8.6e-06 8510.0 [0.2336734693877551, 0.254]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.6e-06 8610.0 [0.25718367346938775, 0.281]\n",
      "8.6e-06 8710.0 [0.2433469387755102, 0.257]\n",
      "8.6e-06 8810.0 [0.22944897959183674, 0.231]\n",
      "8.6e-06 8910.0 [0.25044897959183676, 0.251]\n",
      "8.6e-06 9010.0 [0.18818367346938775, 0.191]\n",
      "8.6e-06 9110.0 [0.19010204081632653, 0.185]\n",
      "8.6e-06 9210.0 [0.1906122448979592, 0.196]\n",
      "8.6e-06 9310.0 [0.1986326530612245, 0.217]\n",
      "8.6e-06 9410.0 [0.22140816326530613, 0.233]\n",
      "8.6e-06 9510.0 [0.23181632653061224, 0.226]\n",
      "8.6e-06 9610.0 [0.18559183673469387, 0.176]\n",
      "8.6e-06 9710.0 [0.2339387755102041, 0.242]\n",
      "8.6e-06 9810.0 [0.22716326530612244, 0.235]\n",
      "8.6e-06 9910.0 [0.18146938775510205, 0.18]\n",
      "9.100000000000001e-06 10.0 [0.3525510204081633, 0.352]\n",
      "9.100000000000001e-06 110.0 [0.3373673469387755, 0.348]\n",
      "9.100000000000001e-06 210.0 [0.3463469387755102, 0.342]\n",
      "9.100000000000001e-06 310.0 [0.3059387755102041, 0.325]\n",
      "9.100000000000001e-06 410.0 [0.3210408163265306, 0.323]\n",
      "9.100000000000001e-06 510.0 [0.2753673469387755, 0.283]\n",
      "9.100000000000001e-06 610.0 [0.3173877551020408, 0.343]\n",
      "9.100000000000001e-06 710.0 [0.2765102040816326, 0.289]\n",
      "9.100000000000001e-06 810.0 [0.2879387755102041, 0.283]\n",
      "9.100000000000001e-06 910.0 [0.25912244897959186, 0.268]\n",
      "9.100000000000001e-06 1010.0 [0.2758163265306122, 0.275]\n",
      "9.100000000000001e-06 1110.0 [0.2539387755102041, 0.25]\n",
      "9.100000000000001e-06 1210.0 [0.30753061224489797, 0.307]\n",
      "9.100000000000001e-06 1310.0 [0.27944897959183673, 0.281]\n",
      "9.100000000000001e-06 1410.0 [0.25673469387755105, 0.264]\n",
      "9.100000000000001e-06 1510.0 [0.251530612244898, 0.256]\n",
      "9.100000000000001e-06 1610.0 [0.26302040816326533, 0.253]\n",
      "9.100000000000001e-06 1710.0 [0.23451020408163264, 0.242]\n",
      "9.100000000000001e-06 1810.0 [0.2985510204081633, 0.299]\n",
      "9.100000000000001e-06 1910.0 [0.2709591836734694, 0.256]\n",
      "9.100000000000001e-06 2010.0 [0.3253061224489796, 0.332]\n",
      "9.100000000000001e-06 2110.0 [0.29312244897959183, 0.286]\n",
      "9.100000000000001e-06 2210.0 [0.2630408163265306, 0.279]\n",
      "9.100000000000001e-06 2310.0 [0.2430408163265306, 0.244]\n",
      "9.100000000000001e-06 2410.0 [0.2866734693877551, 0.293]\n",
      "9.100000000000001e-06 2510.0 [0.23353061224489796, 0.258]\n",
      "9.100000000000001e-06 2610.0 [0.27118367346938776, 0.282]\n",
      "9.100000000000001e-06 2710.0 [0.2711224489795918, 0.256]\n",
      "9.100000000000001e-06 2810.0 [0.2536734693877551, 0.249]\n",
      "9.100000000000001e-06 2910.0 [0.20838775510204083, 0.223]\n",
      "9.100000000000001e-06 3010.0 [0.26387755102040816, 0.262]\n",
      "9.100000000000001e-06 3110.0 [0.22912244897959183, 0.208]\n",
      "9.100000000000001e-06 3210.0 [0.27948979591836737, 0.269]\n",
      "9.100000000000001e-06 3310.0 [0.24257142857142858, 0.235]\n",
      "9.100000000000001e-06 3410.0 [0.2183061224489796, 0.204]\n",
      "9.100000000000001e-06 3510.0 [0.3096734693877551, 0.316]\n",
      "9.100000000000001e-06 3610.0 [0.2396734693877551, 0.225]\n",
      "9.100000000000001e-06 3710.0 [0.19616326530612244, 0.188]\n",
      "9.100000000000001e-06 3810.0 [0.27810204081632656, 0.272]\n",
      "9.100000000000001e-06 3910.0 [0.26202040816326533, 0.256]\n",
      "9.100000000000001e-06 4010.0 [0.2543877551020408, 0.289]\n",
      "9.100000000000001e-06 4110.0 [0.21824489795918367, 0.217]\n",
      "9.100000000000001e-06 4210.0 [0.27414285714285713, 0.28]\n",
      "9.100000000000001e-06 4310.0 [0.25781632653061226, 0.254]\n",
      "9.100000000000001e-06 4410.0 [0.22824489795918368, 0.243]\n",
      "9.100000000000001e-06 4510.0 [0.25542857142857145, 0.28]\n",
      "9.100000000000001e-06 4610.0 [0.24948979591836734, 0.253]\n",
      "9.100000000000001e-06 4710.0 [0.20716326530612245, 0.211]\n",
      "9.100000000000001e-06 4810.0 [0.2323673469387755, 0.23]\n",
      "9.100000000000001e-06 4910.0 [0.21585714285714286, 0.215]\n",
      "9.100000000000001e-06 5010.0 [0.26242857142857146, 0.277]\n",
      "9.100000000000001e-06 5110.0 [0.2213469387755102, 0.225]\n",
      "9.100000000000001e-06 5210.0 [0.2153061224489796, 0.235]\n",
      "9.100000000000001e-06 5310.0 [0.2413673469387755, 0.252]\n",
      "9.100000000000001e-06 5410.0 [0.2433061224489796, 0.26]\n",
      "9.100000000000001e-06 5510.0 [0.2546938775510204, 0.231]\n",
      "9.100000000000001e-06 5610.0 [0.22220408163265307, 0.225]\n",
      "9.100000000000001e-06 5710.0 [0.22318367346938775, 0.212]\n",
      "9.100000000000001e-06 5810.0 [0.25916326530612244, 0.275]\n",
      "9.100000000000001e-06 5910.0 [0.2396734693877551, 0.239]\n",
      "9.100000000000001e-06 6010.0 [0.2818163265306122, 0.283]\n",
      "9.100000000000001e-06 6110.0 [0.20408163265306123, 0.204]\n",
      "9.100000000000001e-06 6210.0 [0.2369387755102041, 0.239]\n",
      "9.100000000000001e-06 6310.0 [0.25014285714285717, 0.272]\n",
      "9.100000000000001e-06 6410.0 [0.22163265306122448, 0.231]\n",
      "9.100000000000001e-06 6510.0 [0.24420408163265306, 0.252]\n",
      "9.100000000000001e-06 6610.0 [0.23542857142857143, 0.234]\n",
      "9.100000000000001e-06 6710.0 [0.18720408163265306, 0.2]\n",
      "9.100000000000001e-06 6810.0 [0.24712244897959185, 0.258]\n",
      "9.100000000000001e-06 6910.0 [0.27383673469387754, 0.275]\n",
      "9.100000000000001e-06 7010.0 [0.263734693877551, 0.281]\n",
      "9.100000000000001e-06 7110.0 [0.2755102040816326, 0.276]\n",
      "9.100000000000001e-06 7210.0 [0.22463265306122449, 0.242]\n",
      "9.100000000000001e-06 7310.0 [0.22316326530612246, 0.227]\n",
      "9.100000000000001e-06 7410.0 [0.24897959183673468, 0.239]\n",
      "9.100000000000001e-06 7510.0 [0.20016326530612244, 0.221]\n",
      "9.100000000000001e-06 7610.0 [0.17008163265306123, 0.179]\n",
      "9.100000000000001e-06 7710.0 [0.21779591836734694, 0.217]\n",
      "9.100000000000001e-06 7810.0 [0.2353673469387755, 0.246]\n",
      "9.100000000000001e-06 7910.0 [0.22773469387755102, 0.213]\n",
      "9.100000000000001e-06 8010.0 [0.1963265306122449, 0.199]\n",
      "9.100000000000001e-06 8110.0 [0.2502448979591837, 0.279]\n",
      "9.100000000000001e-06 8210.0 [0.24957142857142858, 0.256]\n",
      "9.100000000000001e-06 8310.0 [0.1676326530612245, 0.167]\n",
      "9.100000000000001e-06 8410.0 [0.18385714285714286, 0.198]\n",
      "9.100000000000001e-06 8510.0 [0.2299795918367347, 0.235]\n",
      "9.100000000000001e-06 8610.0 [0.23430612244897958, 0.253]\n",
      "9.100000000000001e-06 8710.0 [0.23161224489795917, 0.26]\n",
      "9.100000000000001e-06 8810.0 [0.22344897959183674, 0.255]\n",
      "9.100000000000001e-06 8910.0 [0.15987755102040815, 0.178]\n",
      "9.100000000000001e-06 9010.0 [0.1456326530612245, 0.155]\n",
      "9.100000000000001e-06 9110.0 [0.18785714285714286, 0.203]\n",
      "9.100000000000001e-06 9210.0 [0.2620612244897959, 0.264]\n",
      "9.100000000000001e-06 9310.0 [0.19459183673469388, 0.205]\n",
      "9.100000000000001e-06 9410.0 [0.20971428571428571, 0.21]\n",
      "9.100000000000001e-06 9510.0 [0.20022448979591836, 0.213]\n",
      "9.100000000000001e-06 9610.0 [0.16446938775510203, 0.173]\n",
      "9.100000000000001e-06 9710.0 [0.21906122448979592, 0.217]\n",
      "9.100000000000001e-06 9810.0 [0.22838775510204082, 0.24]\n",
      "9.100000000000001e-06 9910.0 [0.27710204081632656, 0.28]\n",
      "9.6e-06 10.0 [0.32212244897959186, 0.335]\n",
      "9.6e-06 110.0 [0.3380408163265306, 0.323]\n",
      "9.6e-06 210.0 [0.30414285714285716, 0.294]\n",
      "9.6e-06 310.0 [0.25446938775510203, 0.262]\n",
      "9.6e-06 410.0 [0.3529387755102041, 0.328]\n",
      "9.6e-06 510.0 [0.3059183673469388, 0.333]\n",
      "9.6e-06 610.0 [0.2469795918367347, 0.266]\n",
      "9.6e-06 710.0 [0.3132448979591837, 0.304]\n",
      "9.6e-06 810.0 [0.2607551020408163, 0.253]\n",
      "9.6e-06 910.0 [0.26763265306122447, 0.275]\n",
      "9.6e-06 1010.0 [0.24689795918367347, 0.258]\n",
      "9.6e-06 1110.0 [0.29646938775510207, 0.305]\n",
      "9.6e-06 1210.0 [0.26879591836734695, 0.272]\n",
      "9.6e-06 1310.0 [0.25440816326530613, 0.237]\n",
      "9.6e-06 1410.0 [0.21124489795918366, 0.219]\n",
      "9.6e-06 1510.0 [0.2703673469387755, 0.281]\n",
      "9.6e-06 1610.0 [0.24589795918367346, 0.265]\n",
      "9.6e-06 1710.0 [0.298265306122449, 0.322]\n",
      "9.6e-06 1810.0 [0.2860204081632653, 0.28]\n",
      "9.6e-06 1910.0 [0.2753469387755102, 0.281]\n",
      "9.6e-06 2010.0 [0.2033673469387755, 0.211]\n",
      "9.6e-06 2110.0 [0.28383673469387755, 0.299]\n",
      "9.6e-06 2210.0 [0.23289795918367348, 0.229]\n",
      "9.6e-06 2310.0 [0.27846938775510205, 0.27]\n",
      "9.6e-06 2410.0 [0.27718367346938777, 0.31]\n",
      "9.6e-06 2510.0 [0.24514285714285713, 0.241]\n",
      "9.6e-06 2610.0 [0.22316326530612246, 0.246]\n",
      "9.6e-06 2710.0 [0.2216734693877551, 0.228]\n",
      "9.6e-06 2810.0 [0.24893877551020407, 0.253]\n",
      "9.6e-06 2910.0 [0.23857142857142857, 0.236]\n",
      "9.6e-06 3010.0 [0.2718163265306122, 0.305]\n",
      "9.6e-06 3110.0 [0.22144897959183674, 0.243]\n",
      "9.6e-06 3210.0 [0.2304081632653061, 0.229]\n",
      "9.6e-06 3310.0 [0.2153061224489796, 0.214]\n",
      "9.6e-06 3410.0 [0.254, 0.241]\n",
      "9.6e-06 3510.0 [0.2503061224489796, 0.253]\n",
      "9.6e-06 3610.0 [0.192, 0.205]\n",
      "9.6e-06 3710.0 [0.17716326530612245, 0.179]\n",
      "9.6e-06 3810.0 [0.2309795918367347, 0.237]\n",
      "9.6e-06 3910.0 [0.2600204081632653, 0.263]\n",
      "9.6e-06 4010.0 [0.2567755102040816, 0.271]\n",
      "9.6e-06 4110.0 [0.22485714285714287, 0.22]\n",
      "9.6e-06 4210.0 [0.2617551020408163, 0.286]\n",
      "9.6e-06 4310.0 [0.2375918367346939, 0.229]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.6e-06 4410.0 [0.21553061224489795, 0.197]\n",
      "9.6e-06 4510.0 [0.2466122448979592, 0.231]\n",
      "9.6e-06 4610.0 [0.19087755102040815, 0.193]\n",
      "9.6e-06 4710.0 [0.27024489795918366, 0.268]\n",
      "9.6e-06 4810.0 [0.2143265306122449, 0.233]\n",
      "9.6e-06 4910.0 [0.23616326530612244, 0.236]\n",
      "9.6e-06 5010.0 [0.258530612244898, 0.263]\n",
      "9.6e-06 5110.0 [0.23873469387755103, 0.247]\n",
      "9.6e-06 5210.0 [0.26848979591836736, 0.254]\n",
      "9.6e-06 5310.0 [0.25114285714285717, 0.271]\n",
      "9.6e-06 5410.0 [0.24371428571428572, 0.232]\n",
      "9.6e-06 5510.0 [0.24997959183673468, 0.254]\n",
      "9.6e-06 5610.0 [0.285, 0.309]\n",
      "9.6e-06 5710.0 [0.23126530612244897, 0.222]\n",
      "9.6e-06 5810.0 [0.19420408163265307, 0.202]\n",
      "9.6e-06 5910.0 [0.24177551020408164, 0.246]\n",
      "9.6e-06 6010.0 [0.18191836734693878, 0.185]\n",
      "9.6e-06 6110.0 [0.1643469387755102, 0.155]\n",
      "9.6e-06 6210.0 [0.17708163265306123, 0.176]\n",
      "9.6e-06 6310.0 [0.21177551020408164, 0.233]\n",
      "9.6e-06 6410.0 [0.16428571428571428, 0.156]\n",
      "9.6e-06 6510.0 [0.1880408163265306, 0.203]\n",
      "9.6e-06 6610.0 [0.20557142857142857, 0.222]\n",
      "9.6e-06 6710.0 [0.20540816326530612, 0.222]\n",
      "9.6e-06 6810.0 [0.24255102040816326, 0.252]\n",
      "9.6e-06 6910.0 [0.26018367346938776, 0.275]\n",
      "9.6e-06 7010.0 [0.21785714285714286, 0.217]\n",
      "9.6e-06 7110.0 [0.25104081632653064, 0.267]\n",
      "9.6e-06 7210.0 [0.2420408163265306, 0.228]\n",
      "9.6e-06 7310.0 [0.17985714285714285, 0.154]\n",
      "9.6e-06 7410.0 [0.20704081632653062, 0.211]\n",
      "9.6e-06 7510.0 [0.2140408163265306, 0.226]\n",
      "9.6e-06 7610.0 [0.21936734693877552, 0.247]\n",
      "9.6e-06 7710.0 [0.21787755102040815, 0.231]\n",
      "9.6e-06 7810.0 [0.22387755102040816, 0.219]\n",
      "9.6e-06 7910.0 [0.16708163265306122, 0.174]\n",
      "9.6e-06 8010.0 [0.23424489795918368, 0.247]\n",
      "9.6e-06 8110.0 [0.22089795918367347, 0.22]\n",
      "9.6e-06 8210.0 [0.22544897959183674, 0.24]\n",
      "9.6e-06 8310.0 [0.21610204081632653, 0.23]\n",
      "9.6e-06 8410.0 [0.21771428571428572, 0.208]\n",
      "9.6e-06 8510.0 [0.21428571428571427, 0.224]\n",
      "9.6e-06 8610.0 [0.18987755102040815, 0.196]\n",
      "9.6e-06 8710.0 [0.21053061224489797, 0.207]\n",
      "9.6e-06 8810.0 [0.2259795918367347, 0.25]\n",
      "9.6e-06 8910.0 [0.1966734693877551, 0.221]\n",
      "9.6e-06 9010.0 [0.23653061224489796, 0.256]\n",
      "9.6e-06 9110.0 [0.19891836734693877, 0.201]\n",
      "9.6e-06 9210.0 [0.1796734693877551, 0.174]\n",
      "9.6e-06 9310.0 [0.21053061224489797, 0.218]\n",
      "9.6e-06 9410.0 [0.19046938775510205, 0.19]\n",
      "9.6e-06 9510.0 [0.20824489795918366, 0.217]\n",
      "9.6e-06 9610.0 [0.17295918367346938, 0.193]\n",
      "9.6e-06 9710.0 [0.21657142857142858, 0.217]\n",
      "9.6e-06 9810.0 [0.21975510204081633, 0.228]\n",
      "9.6e-06 9910.0 [0.2555918367346939, 0.244]\n",
      "lr 1.000000e-07 reg 1.000000e+01 train accuracy: 0.233592 val accuracy: 0.231000\n",
      "lr 1.000000e-07 reg 1.100000e+02 train accuracy: 0.229408 val accuracy: 0.242000\n",
      "lr 1.000000e-07 reg 2.100000e+02 train accuracy: 0.237061 val accuracy: 0.233000\n",
      "lr 1.000000e-07 reg 3.100000e+02 train accuracy: 0.229714 val accuracy: 0.237000\n",
      "lr 1.000000e-07 reg 4.100000e+02 train accuracy: 0.229571 val accuracy: 0.225000\n",
      "lr 1.000000e-07 reg 5.100000e+02 train accuracy: 0.236796 val accuracy: 0.244000\n",
      "lr 1.000000e-07 reg 6.100000e+02 train accuracy: 0.238327 val accuracy: 0.253000\n",
      "lr 1.000000e-07 reg 7.100000e+02 train accuracy: 0.229204 val accuracy: 0.233000\n",
      "lr 1.000000e-07 reg 8.100000e+02 train accuracy: 0.239939 val accuracy: 0.239000\n",
      "lr 1.000000e-07 reg 9.100000e+02 train accuracy: 0.240204 val accuracy: 0.259000\n",
      "lr 1.000000e-07 reg 1.010000e+03 train accuracy: 0.219143 val accuracy: 0.214000\n",
      "lr 1.000000e-07 reg 1.110000e+03 train accuracy: 0.235510 val accuracy: 0.227000\n",
      "lr 1.000000e-07 reg 1.210000e+03 train accuracy: 0.226714 val accuracy: 0.225000\n",
      "lr 1.000000e-07 reg 1.310000e+03 train accuracy: 0.242673 val accuracy: 0.234000\n",
      "lr 1.000000e-07 reg 1.410000e+03 train accuracy: 0.239490 val accuracy: 0.255000\n",
      "lr 1.000000e-07 reg 1.510000e+03 train accuracy: 0.229959 val accuracy: 0.239000\n",
      "lr 1.000000e-07 reg 1.610000e+03 train accuracy: 0.231755 val accuracy: 0.240000\n",
      "lr 1.000000e-07 reg 1.710000e+03 train accuracy: 0.243857 val accuracy: 0.249000\n",
      "lr 1.000000e-07 reg 1.810000e+03 train accuracy: 0.234857 val accuracy: 0.206000\n",
      "lr 1.000000e-07 reg 1.910000e+03 train accuracy: 0.236041 val accuracy: 0.272000\n",
      "lr 1.000000e-07 reg 2.010000e+03 train accuracy: 0.232816 val accuracy: 0.240000\n",
      "lr 1.000000e-07 reg 2.110000e+03 train accuracy: 0.247286 val accuracy: 0.255000\n",
      "lr 1.000000e-07 reg 2.210000e+03 train accuracy: 0.242878 val accuracy: 0.245000\n",
      "lr 1.000000e-07 reg 2.310000e+03 train accuracy: 0.243143 val accuracy: 0.247000\n",
      "lr 1.000000e-07 reg 2.410000e+03 train accuracy: 0.244714 val accuracy: 0.241000\n",
      "lr 1.000000e-07 reg 2.510000e+03 train accuracy: 0.245082 val accuracy: 0.255000\n",
      "lr 1.000000e-07 reg 2.610000e+03 train accuracy: 0.236857 val accuracy: 0.257000\n",
      "lr 1.000000e-07 reg 2.710000e+03 train accuracy: 0.242898 val accuracy: 0.249000\n",
      "lr 1.000000e-07 reg 2.810000e+03 train accuracy: 0.245551 val accuracy: 0.240000\n",
      "lr 1.000000e-07 reg 2.910000e+03 train accuracy: 0.239184 val accuracy: 0.228000\n",
      "lr 1.000000e-07 reg 3.010000e+03 train accuracy: 0.237857 val accuracy: 0.250000\n",
      "lr 1.000000e-07 reg 3.110000e+03 train accuracy: 0.244143 val accuracy: 0.249000\n",
      "lr 1.000000e-07 reg 3.210000e+03 train accuracy: 0.236776 val accuracy: 0.228000\n",
      "lr 1.000000e-07 reg 3.310000e+03 train accuracy: 0.242510 val accuracy: 0.250000\n",
      "lr 1.000000e-07 reg 3.410000e+03 train accuracy: 0.252551 val accuracy: 0.264000\n",
      "lr 1.000000e-07 reg 3.510000e+03 train accuracy: 0.249510 val accuracy: 0.264000\n",
      "lr 1.000000e-07 reg 3.610000e+03 train accuracy: 0.249122 val accuracy: 0.270000\n",
      "lr 1.000000e-07 reg 3.710000e+03 train accuracy: 0.251082 val accuracy: 0.254000\n",
      "lr 1.000000e-07 reg 3.810000e+03 train accuracy: 0.252959 val accuracy: 0.258000\n",
      "lr 1.000000e-07 reg 3.910000e+03 train accuracy: 0.244531 val accuracy: 0.248000\n",
      "lr 1.000000e-07 reg 4.010000e+03 train accuracy: 0.250714 val accuracy: 0.283000\n",
      "lr 1.000000e-07 reg 4.110000e+03 train accuracy: 0.246082 val accuracy: 0.236000\n",
      "lr 1.000000e-07 reg 4.210000e+03 train accuracy: 0.260776 val accuracy: 0.270000\n",
      "lr 1.000000e-07 reg 4.310000e+03 train accuracy: 0.250184 val accuracy: 0.250000\n",
      "lr 1.000000e-07 reg 4.410000e+03 train accuracy: 0.248755 val accuracy: 0.244000\n",
      "lr 1.000000e-07 reg 4.510000e+03 train accuracy: 0.255163 val accuracy: 0.259000\n",
      "lr 1.000000e-07 reg 4.610000e+03 train accuracy: 0.242408 val accuracy: 0.225000\n",
      "lr 1.000000e-07 reg 4.710000e+03 train accuracy: 0.260429 val accuracy: 0.262000\n",
      "lr 1.000000e-07 reg 4.810000e+03 train accuracy: 0.253184 val accuracy: 0.245000\n",
      "lr 1.000000e-07 reg 4.910000e+03 train accuracy: 0.248939 val accuracy: 0.260000\n",
      "lr 1.000000e-07 reg 5.010000e+03 train accuracy: 0.254306 val accuracy: 0.286000\n",
      "lr 1.000000e-07 reg 5.110000e+03 train accuracy: 0.265163 val accuracy: 0.268000\n",
      "lr 1.000000e-07 reg 5.210000e+03 train accuracy: 0.261551 val accuracy: 0.277000\n",
      "lr 1.000000e-07 reg 5.310000e+03 train accuracy: 0.260816 val accuracy: 0.256000\n",
      "lr 1.000000e-07 reg 5.410000e+03 train accuracy: 0.258306 val accuracy: 0.270000\n",
      "lr 1.000000e-07 reg 5.510000e+03 train accuracy: 0.264429 val accuracy: 0.261000\n",
      "lr 1.000000e-07 reg 5.610000e+03 train accuracy: 0.259510 val accuracy: 0.256000\n",
      "lr 1.000000e-07 reg 5.710000e+03 train accuracy: 0.260408 val accuracy: 0.265000\n",
      "lr 1.000000e-07 reg 5.810000e+03 train accuracy: 0.258735 val accuracy: 0.239000\n",
      "lr 1.000000e-07 reg 5.910000e+03 train accuracy: 0.269673 val accuracy: 0.285000\n",
      "lr 1.000000e-07 reg 6.010000e+03 train accuracy: 0.261408 val accuracy: 0.249000\n",
      "lr 1.000000e-07 reg 6.110000e+03 train accuracy: 0.261735 val accuracy: 0.248000\n",
      "lr 1.000000e-07 reg 6.210000e+03 train accuracy: 0.268327 val accuracy: 0.270000\n",
      "lr 1.000000e-07 reg 6.310000e+03 train accuracy: 0.265714 val accuracy: 0.276000\n",
      "lr 1.000000e-07 reg 6.410000e+03 train accuracy: 0.263918 val accuracy: 0.257000\n",
      "lr 1.000000e-07 reg 6.510000e+03 train accuracy: 0.259184 val accuracy: 0.263000\n",
      "lr 1.000000e-07 reg 6.610000e+03 train accuracy: 0.264041 val accuracy: 0.261000\n",
      "lr 1.000000e-07 reg 6.710000e+03 train accuracy: 0.273694 val accuracy: 0.273000\n",
      "lr 1.000000e-07 reg 6.810000e+03 train accuracy: 0.262531 val accuracy: 0.275000\n",
      "lr 1.000000e-07 reg 6.910000e+03 train accuracy: 0.264939 val accuracy: 0.258000\n",
      "lr 1.000000e-07 reg 7.010000e+03 train accuracy: 0.273980 val accuracy: 0.303000\n",
      "lr 1.000000e-07 reg 7.110000e+03 train accuracy: 0.260143 val accuracy: 0.276000\n",
      "lr 1.000000e-07 reg 7.210000e+03 train accuracy: 0.271224 val accuracy: 0.283000\n",
      "lr 1.000000e-07 reg 7.310000e+03 train accuracy: 0.265102 val accuracy: 0.265000\n",
      "lr 1.000000e-07 reg 7.410000e+03 train accuracy: 0.265633 val accuracy: 0.273000\n",
      "lr 1.000000e-07 reg 7.510000e+03 train accuracy: 0.269265 val accuracy: 0.267000\n",
      "lr 1.000000e-07 reg 7.610000e+03 train accuracy: 0.271898 val accuracy: 0.283000\n",
      "lr 1.000000e-07 reg 7.710000e+03 train accuracy: 0.266551 val accuracy: 0.275000\n",
      "lr 1.000000e-07 reg 7.810000e+03 train accuracy: 0.279571 val accuracy: 0.264000\n",
      "lr 1.000000e-07 reg 7.910000e+03 train accuracy: 0.282531 val accuracy: 0.273000\n",
      "lr 1.000000e-07 reg 8.010000e+03 train accuracy: 0.275000 val accuracy: 0.271000\n",
      "lr 1.000000e-07 reg 8.110000e+03 train accuracy: 0.271510 val accuracy: 0.276000\n",
      "lr 1.000000e-07 reg 8.210000e+03 train accuracy: 0.282837 val accuracy: 0.270000\n",
      "lr 1.000000e-07 reg 8.310000e+03 train accuracy: 0.267531 val accuracy: 0.277000\n",
      "lr 1.000000e-07 reg 8.410000e+03 train accuracy: 0.269714 val accuracy: 0.289000\n",
      "lr 1.000000e-07 reg 8.510000e+03 train accuracy: 0.275122 val accuracy: 0.289000\n",
      "lr 1.000000e-07 reg 8.610000e+03 train accuracy: 0.275980 val accuracy: 0.274000\n",
      "lr 1.000000e-07 reg 8.710000e+03 train accuracy: 0.277367 val accuracy: 0.273000\n",
      "lr 1.000000e-07 reg 8.810000e+03 train accuracy: 0.281918 val accuracy: 0.278000\n",
      "lr 1.000000e-07 reg 8.910000e+03 train accuracy: 0.278082 val accuracy: 0.269000\n",
      "lr 1.000000e-07 reg 9.010000e+03 train accuracy: 0.276367 val accuracy: 0.286000\n",
      "lr 1.000000e-07 reg 9.110000e+03 train accuracy: 0.283061 val accuracy: 0.279000\n",
      "lr 1.000000e-07 reg 9.210000e+03 train accuracy: 0.284388 val accuracy: 0.300000\n",
      "lr 1.000000e-07 reg 9.310000e+03 train accuracy: 0.291857 val accuracy: 0.283000\n",
      "lr 1.000000e-07 reg 9.410000e+03 train accuracy: 0.280776 val accuracy: 0.255000\n",
      "lr 1.000000e-07 reg 9.510000e+03 train accuracy: 0.286367 val accuracy: 0.306000\n",
      "lr 1.000000e-07 reg 9.610000e+03 train accuracy: 0.282469 val accuracy: 0.302000\n",
      "lr 1.000000e-07 reg 9.710000e+03 train accuracy: 0.284612 val accuracy: 0.310000\n",
      "lr 1.000000e-07 reg 9.810000e+03 train accuracy: 0.291388 val accuracy: 0.273000\n",
      "lr 1.000000e-07 reg 9.910000e+03 train accuracy: 0.286286 val accuracy: 0.308000\n",
      "lr 6.000000e-07 reg 1.000000e+01 train accuracy: 0.308000 val accuracy: 0.317000\n",
      "lr 6.000000e-07 reg 1.100000e+02 train accuracy: 0.312000 val accuracy: 0.312000\n",
      "lr 6.000000e-07 reg 2.100000e+02 train accuracy: 0.317490 val accuracy: 0.303000\n",
      "lr 6.000000e-07 reg 3.100000e+02 train accuracy: 0.320224 val accuracy: 0.328000\n",
      "lr 6.000000e-07 reg 4.100000e+02 train accuracy: 0.321592 val accuracy: 0.305000\n",
      "lr 6.000000e-07 reg 5.100000e+02 train accuracy: 0.322592 val accuracy: 0.330000\n",
      "lr 6.000000e-07 reg 6.100000e+02 train accuracy: 0.332388 val accuracy: 0.321000\n",
      "lr 6.000000e-07 reg 7.100000e+02 train accuracy: 0.333245 val accuracy: 0.320000\n",
      "lr 6.000000e-07 reg 8.100000e+02 train accuracy: 0.338490 val accuracy: 0.349000\n",
      "lr 6.000000e-07 reg 9.100000e+02 train accuracy: 0.344449 val accuracy: 0.358000\n",
      "lr 6.000000e-07 reg 1.010000e+03 train accuracy: 0.344184 val accuracy: 0.338000\n",
      "lr 6.000000e-07 reg 1.110000e+03 train accuracy: 0.347306 val accuracy: 0.345000\n",
      "lr 6.000000e-07 reg 1.210000e+03 train accuracy: 0.351531 val accuracy: 0.343000\n",
      "lr 6.000000e-07 reg 1.310000e+03 train accuracy: 0.356776 val accuracy: 0.369000\n",
      "lr 6.000000e-07 reg 1.410000e+03 train accuracy: 0.359837 val accuracy: 0.375000\n",
      "lr 6.000000e-07 reg 1.510000e+03 train accuracy: 0.363061 val accuracy: 0.375000\n",
      "lr 6.000000e-07 reg 1.610000e+03 train accuracy: 0.363061 val accuracy: 0.361000\n",
      "lr 6.000000e-07 reg 1.710000e+03 train accuracy: 0.363857 val accuracy: 0.374000\n",
      "lr 6.000000e-07 reg 1.810000e+03 train accuracy: 0.369714 val accuracy: 0.364000\n",
      "lr 6.000000e-07 reg 1.910000e+03 train accuracy: 0.370306 val accuracy: 0.375000\n",
      "lr 6.000000e-07 reg 2.010000e+03 train accuracy: 0.377714 val accuracy: 0.369000\n",
      "lr 6.000000e-07 reg 2.110000e+03 train accuracy: 0.374959 val accuracy: 0.388000\n",
      "lr 6.000000e-07 reg 2.210000e+03 train accuracy: 0.378327 val accuracy: 0.399000\n",
      "lr 6.000000e-07 reg 2.310000e+03 train accuracy: 0.377143 val accuracy: 0.382000\n",
      "lr 6.000000e-07 reg 2.410000e+03 train accuracy: 0.380347 val accuracy: 0.377000\n",
      "lr 6.000000e-07 reg 2.510000e+03 train accuracy: 0.383408 val accuracy: 0.379000\n",
      "lr 6.000000e-07 reg 2.610000e+03 train accuracy: 0.382959 val accuracy: 0.391000\n",
      "lr 6.000000e-07 reg 2.710000e+03 train accuracy: 0.383612 val accuracy: 0.388000\n",
      "lr 6.000000e-07 reg 2.810000e+03 train accuracy: 0.383918 val accuracy: 0.380000\n",
      "lr 6.000000e-07 reg 2.910000e+03 train accuracy: 0.381735 val accuracy: 0.389000\n",
      "lr 6.000000e-07 reg 3.010000e+03 train accuracy: 0.383939 val accuracy: 0.391000\n",
      "lr 6.000000e-07 reg 3.110000e+03 train accuracy: 0.382286 val accuracy: 0.396000\n",
      "lr 6.000000e-07 reg 3.210000e+03 train accuracy: 0.387776 val accuracy: 0.402000\n",
      "lr 6.000000e-07 reg 3.310000e+03 train accuracy: 0.387837 val accuracy: 0.383000\n",
      "lr 6.000000e-07 reg 3.410000e+03 train accuracy: 0.386551 val accuracy: 0.379000\n",
      "lr 6.000000e-07 reg 3.510000e+03 train accuracy: 0.385531 val accuracy: 0.370000\n",
      "lr 6.000000e-07 reg 3.610000e+03 train accuracy: 0.388163 val accuracy: 0.403000\n",
      "lr 6.000000e-07 reg 3.710000e+03 train accuracy: 0.388959 val accuracy: 0.392000\n",
      "lr 6.000000e-07 reg 3.810000e+03 train accuracy: 0.384286 val accuracy: 0.403000\n",
      "lr 6.000000e-07 reg 3.910000e+03 train accuracy: 0.386918 val accuracy: 0.391000\n",
      "lr 6.000000e-07 reg 4.010000e+03 train accuracy: 0.386776 val accuracy: 0.403000\n",
      "lr 6.000000e-07 reg 4.110000e+03 train accuracy: 0.385633 val accuracy: 0.401000\n",
      "lr 6.000000e-07 reg 4.210000e+03 train accuracy: 0.387000 val accuracy: 0.398000\n",
      "lr 6.000000e-07 reg 4.310000e+03 train accuracy: 0.386163 val accuracy: 0.397000\n",
      "lr 6.000000e-07 reg 4.410000e+03 train accuracy: 0.386816 val accuracy: 0.396000\n",
      "lr 6.000000e-07 reg 4.510000e+03 train accuracy: 0.388000 val accuracy: 0.392000\n",
      "lr 6.000000e-07 reg 4.610000e+03 train accuracy: 0.385061 val accuracy: 0.395000\n",
      "lr 6.000000e-07 reg 4.710000e+03 train accuracy: 0.385633 val accuracy: 0.388000\n",
      "lr 6.000000e-07 reg 4.810000e+03 train accuracy: 0.384980 val accuracy: 0.401000\n",
      "lr 6.000000e-07 reg 4.910000e+03 train accuracy: 0.381837 val accuracy: 0.396000\n",
      "lr 6.000000e-07 reg 5.010000e+03 train accuracy: 0.386571 val accuracy: 0.403000\n",
      "lr 6.000000e-07 reg 5.110000e+03 train accuracy: 0.385082 val accuracy: 0.396000\n",
      "lr 6.000000e-07 reg 5.210000e+03 train accuracy: 0.386694 val accuracy: 0.384000\n",
      "lr 6.000000e-07 reg 5.310000e+03 train accuracy: 0.380857 val accuracy: 0.389000\n",
      "lr 6.000000e-07 reg 5.410000e+03 train accuracy: 0.379204 val accuracy: 0.389000\n",
      "lr 6.000000e-07 reg 5.510000e+03 train accuracy: 0.388286 val accuracy: 0.389000\n",
      "lr 6.000000e-07 reg 5.610000e+03 train accuracy: 0.383898 val accuracy: 0.390000\n",
      "lr 6.000000e-07 reg 5.710000e+03 train accuracy: 0.382735 val accuracy: 0.397000\n",
      "lr 6.000000e-07 reg 5.810000e+03 train accuracy: 0.385327 val accuracy: 0.396000\n",
      "lr 6.000000e-07 reg 5.910000e+03 train accuracy: 0.380102 val accuracy: 0.379000\n",
      "lr 6.000000e-07 reg 6.010000e+03 train accuracy: 0.380816 val accuracy: 0.380000\n",
      "lr 6.000000e-07 reg 6.110000e+03 train accuracy: 0.378469 val accuracy: 0.386000\n",
      "lr 6.000000e-07 reg 6.210000e+03 train accuracy: 0.381102 val accuracy: 0.393000\n",
      "lr 6.000000e-07 reg 6.310000e+03 train accuracy: 0.381245 val accuracy: 0.391000\n",
      "lr 6.000000e-07 reg 6.410000e+03 train accuracy: 0.379959 val accuracy: 0.388000\n",
      "lr 6.000000e-07 reg 6.510000e+03 train accuracy: 0.380143 val accuracy: 0.391000\n",
      "lr 6.000000e-07 reg 6.610000e+03 train accuracy: 0.380857 val accuracy: 0.377000\n",
      "lr 6.000000e-07 reg 6.710000e+03 train accuracy: 0.382122 val accuracy: 0.382000\n",
      "lr 6.000000e-07 reg 6.810000e+03 train accuracy: 0.379837 val accuracy: 0.391000\n",
      "lr 6.000000e-07 reg 6.910000e+03 train accuracy: 0.375408 val accuracy: 0.398000\n",
      "lr 6.000000e-07 reg 7.010000e+03 train accuracy: 0.378694 val accuracy: 0.401000\n",
      "lr 6.000000e-07 reg 7.110000e+03 train accuracy: 0.379265 val accuracy: 0.393000\n",
      "lr 6.000000e-07 reg 7.210000e+03 train accuracy: 0.376939 val accuracy: 0.388000\n",
      "lr 6.000000e-07 reg 7.310000e+03 train accuracy: 0.379204 val accuracy: 0.384000\n",
      "lr 6.000000e-07 reg 7.410000e+03 train accuracy: 0.379020 val accuracy: 0.394000\n",
      "lr 6.000000e-07 reg 7.510000e+03 train accuracy: 0.373245 val accuracy: 0.374000\n",
      "lr 6.000000e-07 reg 7.610000e+03 train accuracy: 0.377265 val accuracy: 0.376000\n",
      "lr 6.000000e-07 reg 7.710000e+03 train accuracy: 0.375204 val accuracy: 0.391000\n",
      "lr 6.000000e-07 reg 7.810000e+03 train accuracy: 0.376204 val accuracy: 0.388000\n",
      "lr 6.000000e-07 reg 7.910000e+03 train accuracy: 0.376367 val accuracy: 0.382000\n",
      "lr 6.000000e-07 reg 8.010000e+03 train accuracy: 0.380184 val accuracy: 0.378000\n",
      "lr 6.000000e-07 reg 8.110000e+03 train accuracy: 0.373816 val accuracy: 0.380000\n",
      "lr 6.000000e-07 reg 8.210000e+03 train accuracy: 0.373898 val accuracy: 0.400000\n",
      "lr 6.000000e-07 reg 8.310000e+03 train accuracy: 0.374857 val accuracy: 0.375000\n",
      "lr 6.000000e-07 reg 8.410000e+03 train accuracy: 0.373449 val accuracy: 0.390000\n",
      "lr 6.000000e-07 reg 8.510000e+03 train accuracy: 0.371816 val accuracy: 0.387000\n",
      "lr 6.000000e-07 reg 8.610000e+03 train accuracy: 0.373020 val accuracy: 0.389000\n",
      "lr 6.000000e-07 reg 8.710000e+03 train accuracy: 0.376020 val accuracy: 0.386000\n",
      "lr 6.000000e-07 reg 8.810000e+03 train accuracy: 0.368857 val accuracy: 0.374000\n",
      "lr 6.000000e-07 reg 8.910000e+03 train accuracy: 0.368918 val accuracy: 0.379000\n",
      "lr 6.000000e-07 reg 9.010000e+03 train accuracy: 0.374204 val accuracy: 0.389000\n",
      "lr 6.000000e-07 reg 9.110000e+03 train accuracy: 0.375000 val accuracy: 0.381000\n",
      "lr 6.000000e-07 reg 9.210000e+03 train accuracy: 0.370980 val accuracy: 0.378000\n",
      "lr 6.000000e-07 reg 9.310000e+03 train accuracy: 0.370184 val accuracy: 0.385000\n",
      "lr 6.000000e-07 reg 9.410000e+03 train accuracy: 0.370878 val accuracy: 0.383000\n",
      "lr 6.000000e-07 reg 9.510000e+03 train accuracy: 0.374184 val accuracy: 0.387000\n",
      "lr 6.000000e-07 reg 9.610000e+03 train accuracy: 0.370102 val accuracy: 0.380000\n",
      "lr 6.000000e-07 reg 9.710000e+03 train accuracy: 0.373612 val accuracy: 0.388000\n",
      "lr 6.000000e-07 reg 9.810000e+03 train accuracy: 0.374714 val accuracy: 0.391000\n",
      "lr 6.000000e-07 reg 9.910000e+03 train accuracy: 0.369939 val accuracy: 0.376000\n",
      "lr 1.100000e-06 reg 1.000000e+01 train accuracy: 0.331857 val accuracy: 0.319000\n",
      "lr 1.100000e-06 reg 1.100000e+02 train accuracy: 0.340327 val accuracy: 0.355000\n",
      "lr 1.100000e-06 reg 2.100000e+02 train accuracy: 0.347571 val accuracy: 0.343000\n",
      "lr 1.100000e-06 reg 3.100000e+02 train accuracy: 0.359143 val accuracy: 0.343000\n",
      "lr 1.100000e-06 reg 4.100000e+02 train accuracy: 0.361041 val accuracy: 0.366000\n",
      "lr 1.100000e-06 reg 5.100000e+02 train accuracy: 0.368673 val accuracy: 0.367000\n",
      "lr 1.100000e-06 reg 6.100000e+02 train accuracy: 0.371510 val accuracy: 0.362000\n",
      "lr 1.100000e-06 reg 7.100000e+02 train accuracy: 0.381673 val accuracy: 0.373000\n",
      "lr 1.100000e-06 reg 8.100000e+02 train accuracy: 0.381388 val accuracy: 0.383000\n",
      "lr 1.100000e-06 reg 9.100000e+02 train accuracy: 0.382592 val accuracy: 0.386000\n",
      "lr 1.100000e-06 reg 1.010000e+03 train accuracy: 0.388224 val accuracy: 0.401000\n",
      "lr 1.100000e-06 reg 1.110000e+03 train accuracy: 0.391204 val accuracy: 0.387000\n",
      "lr 1.100000e-06 reg 1.210000e+03 train accuracy: 0.389429 val accuracy: 0.382000\n",
      "lr 1.100000e-06 reg 1.310000e+03 train accuracy: 0.393061 val accuracy: 0.393000\n",
      "lr 1.100000e-06 reg 1.410000e+03 train accuracy: 0.392286 val accuracy: 0.397000\n",
      "lr 1.100000e-06 reg 1.510000e+03 train accuracy: 0.392367 val accuracy: 0.388000\n",
      "lr 1.100000e-06 reg 1.610000e+03 train accuracy: 0.395143 val accuracy: 0.396000\n",
      "lr 1.100000e-06 reg 1.710000e+03 train accuracy: 0.394857 val accuracy: 0.385000\n",
      "lr 1.100000e-06 reg 1.810000e+03 train accuracy: 0.395776 val accuracy: 0.385000\n",
      "lr 1.100000e-06 reg 1.910000e+03 train accuracy: 0.398735 val accuracy: 0.400000\n",
      "lr 1.100000e-06 reg 2.010000e+03 train accuracy: 0.395490 val accuracy: 0.395000\n",
      "lr 1.100000e-06 reg 2.110000e+03 train accuracy: 0.396959 val accuracy: 0.398000\n",
      "lr 1.100000e-06 reg 2.210000e+03 train accuracy: 0.397020 val accuracy: 0.398000\n",
      "lr 1.100000e-06 reg 2.310000e+03 train accuracy: 0.396878 val accuracy: 0.391000\n",
      "lr 1.100000e-06 reg 2.410000e+03 train accuracy: 0.396327 val accuracy: 0.398000\n",
      "lr 1.100000e-06 reg 2.510000e+03 train accuracy: 0.393714 val accuracy: 0.400000\n",
      "lr 1.100000e-06 reg 2.610000e+03 train accuracy: 0.394204 val accuracy: 0.392000\n",
      "lr 1.100000e-06 reg 2.710000e+03 train accuracy: 0.393347 val accuracy: 0.385000\n",
      "lr 1.100000e-06 reg 2.810000e+03 train accuracy: 0.387653 val accuracy: 0.399000\n",
      "lr 1.100000e-06 reg 2.910000e+03 train accuracy: 0.394898 val accuracy: 0.391000\n",
      "lr 1.100000e-06 reg 3.010000e+03 train accuracy: 0.387816 val accuracy: 0.386000\n",
      "lr 1.100000e-06 reg 3.110000e+03 train accuracy: 0.386041 val accuracy: 0.407000\n",
      "lr 1.100000e-06 reg 3.210000e+03 train accuracy: 0.391449 val accuracy: 0.412000\n",
      "lr 1.100000e-06 reg 3.310000e+03 train accuracy: 0.391980 val accuracy: 0.374000\n",
      "lr 1.100000e-06 reg 3.410000e+03 train accuracy: 0.387857 val accuracy: 0.403000\n",
      "lr 1.100000e-06 reg 3.510000e+03 train accuracy: 0.388061 val accuracy: 0.398000\n",
      "lr 1.100000e-06 reg 3.610000e+03 train accuracy: 0.388571 val accuracy: 0.393000\n",
      "lr 1.100000e-06 reg 3.710000e+03 train accuracy: 0.387082 val accuracy: 0.391000\n",
      "lr 1.100000e-06 reg 3.810000e+03 train accuracy: 0.387510 val accuracy: 0.375000\n",
      "lr 1.100000e-06 reg 3.910000e+03 train accuracy: 0.389388 val accuracy: 0.392000\n",
      "lr 1.100000e-06 reg 4.010000e+03 train accuracy: 0.385918 val accuracy: 0.393000\n",
      "lr 1.100000e-06 reg 4.110000e+03 train accuracy: 0.382776 val accuracy: 0.387000\n",
      "lr 1.100000e-06 reg 4.210000e+03 train accuracy: 0.386102 val accuracy: 0.409000\n",
      "lr 1.100000e-06 reg 4.310000e+03 train accuracy: 0.389653 val accuracy: 0.391000\n",
      "lr 1.100000e-06 reg 4.410000e+03 train accuracy: 0.386898 val accuracy: 0.386000\n",
      "lr 1.100000e-06 reg 4.510000e+03 train accuracy: 0.382571 val accuracy: 0.399000\n",
      "lr 1.100000e-06 reg 4.610000e+03 train accuracy: 0.383571 val accuracy: 0.390000\n",
      "lr 1.100000e-06 reg 4.710000e+03 train accuracy: 0.382102 val accuracy: 0.400000\n",
      "lr 1.100000e-06 reg 4.810000e+03 train accuracy: 0.381122 val accuracy: 0.395000\n",
      "lr 1.100000e-06 reg 4.910000e+03 train accuracy: 0.386265 val accuracy: 0.381000\n",
      "lr 1.100000e-06 reg 5.010000e+03 train accuracy: 0.381612 val accuracy: 0.393000\n",
      "lr 1.100000e-06 reg 5.110000e+03 train accuracy: 0.379857 val accuracy: 0.381000\n",
      "lr 1.100000e-06 reg 5.210000e+03 train accuracy: 0.381286 val accuracy: 0.382000\n",
      "lr 1.100000e-06 reg 5.310000e+03 train accuracy: 0.382980 val accuracy: 0.398000\n",
      "lr 1.100000e-06 reg 5.410000e+03 train accuracy: 0.378673 val accuracy: 0.376000\n",
      "lr 1.100000e-06 reg 5.510000e+03 train accuracy: 0.380755 val accuracy: 0.386000\n",
      "lr 1.100000e-06 reg 5.610000e+03 train accuracy: 0.379755 val accuracy: 0.372000\n",
      "lr 1.100000e-06 reg 5.710000e+03 train accuracy: 0.377143 val accuracy: 0.393000\n",
      "lr 1.100000e-06 reg 5.810000e+03 train accuracy: 0.376898 val accuracy: 0.393000\n",
      "lr 1.100000e-06 reg 5.910000e+03 train accuracy: 0.372837 val accuracy: 0.364000\n",
      "lr 1.100000e-06 reg 6.010000e+03 train accuracy: 0.370816 val accuracy: 0.382000\n",
      "lr 1.100000e-06 reg 6.110000e+03 train accuracy: 0.371796 val accuracy: 0.387000\n",
      "lr 1.100000e-06 reg 6.210000e+03 train accuracy: 0.377694 val accuracy: 0.376000\n",
      "lr 1.100000e-06 reg 6.310000e+03 train accuracy: 0.369122 val accuracy: 0.370000\n",
      "lr 1.100000e-06 reg 6.410000e+03 train accuracy: 0.374041 val accuracy: 0.381000\n",
      "lr 1.100000e-06 reg 6.510000e+03 train accuracy: 0.376327 val accuracy: 0.386000\n",
      "lr 1.100000e-06 reg 6.610000e+03 train accuracy: 0.372959 val accuracy: 0.375000\n",
      "lr 1.100000e-06 reg 6.710000e+03 train accuracy: 0.375837 val accuracy: 0.390000\n",
      "lr 1.100000e-06 reg 6.810000e+03 train accuracy: 0.374510 val accuracy: 0.388000\n",
      "lr 1.100000e-06 reg 6.910000e+03 train accuracy: 0.370163 val accuracy: 0.369000\n",
      "lr 1.100000e-06 reg 7.010000e+03 train accuracy: 0.377122 val accuracy: 0.390000\n",
      "lr 1.100000e-06 reg 7.110000e+03 train accuracy: 0.367306 val accuracy: 0.373000\n",
      "lr 1.100000e-06 reg 7.210000e+03 train accuracy: 0.376612 val accuracy: 0.390000\n",
      "lr 1.100000e-06 reg 7.310000e+03 train accuracy: 0.377612 val accuracy: 0.392000\n",
      "lr 1.100000e-06 reg 7.410000e+03 train accuracy: 0.373653 val accuracy: 0.378000\n",
      "lr 1.100000e-06 reg 7.510000e+03 train accuracy: 0.372857 val accuracy: 0.381000\n",
      "lr 1.100000e-06 reg 7.610000e+03 train accuracy: 0.370347 val accuracy: 0.385000\n",
      "lr 1.100000e-06 reg 7.710000e+03 train accuracy: 0.375082 val accuracy: 0.391000\n",
      "lr 1.100000e-06 reg 7.810000e+03 train accuracy: 0.375204 val accuracy: 0.382000\n",
      "lr 1.100000e-06 reg 7.910000e+03 train accuracy: 0.358592 val accuracy: 0.369000\n",
      "lr 1.100000e-06 reg 8.010000e+03 train accuracy: 0.369184 val accuracy: 0.372000\n",
      "lr 1.100000e-06 reg 8.110000e+03 train accuracy: 0.368224 val accuracy: 0.373000\n",
      "lr 1.100000e-06 reg 8.210000e+03 train accuracy: 0.366878 val accuracy: 0.369000\n",
      "lr 1.100000e-06 reg 8.310000e+03 train accuracy: 0.373980 val accuracy: 0.392000\n",
      "lr 1.100000e-06 reg 8.410000e+03 train accuracy: 0.368633 val accuracy: 0.379000\n",
      "lr 1.100000e-06 reg 8.510000e+03 train accuracy: 0.371735 val accuracy: 0.377000\n",
      "lr 1.100000e-06 reg 8.610000e+03 train accuracy: 0.373143 val accuracy: 0.381000\n",
      "lr 1.100000e-06 reg 8.710000e+03 train accuracy: 0.373061 val accuracy: 0.388000\n",
      "lr 1.100000e-06 reg 8.810000e+03 train accuracy: 0.368959 val accuracy: 0.380000\n",
      "lr 1.100000e-06 reg 8.910000e+03 train accuracy: 0.366245 val accuracy: 0.362000\n",
      "lr 1.100000e-06 reg 9.010000e+03 train accuracy: 0.365388 val accuracy: 0.372000\n",
      "lr 1.100000e-06 reg 9.110000e+03 train accuracy: 0.372265 val accuracy: 0.392000\n",
      "lr 1.100000e-06 reg 9.210000e+03 train accuracy: 0.365633 val accuracy: 0.378000\n",
      "lr 1.100000e-06 reg 9.310000e+03 train accuracy: 0.371286 val accuracy: 0.364000\n",
      "lr 1.100000e-06 reg 9.410000e+03 train accuracy: 0.369571 val accuracy: 0.381000\n",
      "lr 1.100000e-06 reg 9.510000e+03 train accuracy: 0.366388 val accuracy: 0.382000\n",
      "lr 1.100000e-06 reg 9.610000e+03 train accuracy: 0.366061 val accuracy: 0.381000\n",
      "lr 1.100000e-06 reg 9.710000e+03 train accuracy: 0.362898 val accuracy: 0.361000\n",
      "lr 1.100000e-06 reg 9.810000e+03 train accuracy: 0.370878 val accuracy: 0.388000\n",
      "lr 1.100000e-06 reg 9.910000e+03 train accuracy: 0.371735 val accuracy: 0.380000\n",
      "lr 1.600000e-06 reg 1.000000e+01 train accuracy: 0.340286 val accuracy: 0.337000\n",
      "lr 1.600000e-06 reg 1.100000e+02 train accuracy: 0.363878 val accuracy: 0.364000\n",
      "lr 1.600000e-06 reg 2.100000e+02 train accuracy: 0.364653 val accuracy: 0.349000\n",
      "lr 1.600000e-06 reg 3.100000e+02 train accuracy: 0.375673 val accuracy: 0.350000\n",
      "lr 1.600000e-06 reg 4.100000e+02 train accuracy: 0.384694 val accuracy: 0.365000\n",
      "lr 1.600000e-06 reg 5.100000e+02 train accuracy: 0.385939 val accuracy: 0.382000\n",
      "lr 1.600000e-06 reg 6.100000e+02 train accuracy: 0.395959 val accuracy: 0.378000\n",
      "lr 1.600000e-06 reg 7.100000e+02 train accuracy: 0.393673 val accuracy: 0.380000\n",
      "lr 1.600000e-06 reg 8.100000e+02 train accuracy: 0.400347 val accuracy: 0.406000\n",
      "lr 1.600000e-06 reg 9.100000e+02 train accuracy: 0.398184 val accuracy: 0.393000\n",
      "lr 1.600000e-06 reg 1.010000e+03 train accuracy: 0.399143 val accuracy: 0.391000\n",
      "lr 1.600000e-06 reg 1.110000e+03 train accuracy: 0.395102 val accuracy: 0.404000\n",
      "lr 1.600000e-06 reg 1.210000e+03 train accuracy: 0.399755 val accuracy: 0.402000\n",
      "lr 1.600000e-06 reg 1.310000e+03 train accuracy: 0.405469 val accuracy: 0.405000\n",
      "lr 1.600000e-06 reg 1.410000e+03 train accuracy: 0.396204 val accuracy: 0.410000\n",
      "lr 1.600000e-06 reg 1.510000e+03 train accuracy: 0.399204 val accuracy: 0.405000\n",
      "lr 1.600000e-06 reg 1.610000e+03 train accuracy: 0.395898 val accuracy: 0.397000\n",
      "lr 1.600000e-06 reg 1.710000e+03 train accuracy: 0.396939 val accuracy: 0.398000\n",
      "lr 1.600000e-06 reg 1.810000e+03 train accuracy: 0.402694 val accuracy: 0.404000\n",
      "lr 1.600000e-06 reg 1.910000e+03 train accuracy: 0.402286 val accuracy: 0.415000\n",
      "lr 1.600000e-06 reg 2.010000e+03 train accuracy: 0.384918 val accuracy: 0.376000\n",
      "lr 1.600000e-06 reg 2.110000e+03 train accuracy: 0.393306 val accuracy: 0.383000\n",
      "lr 1.600000e-06 reg 2.210000e+03 train accuracy: 0.395673 val accuracy: 0.407000\n",
      "lr 1.600000e-06 reg 2.310000e+03 train accuracy: 0.388980 val accuracy: 0.393000\n",
      "lr 1.600000e-06 reg 2.410000e+03 train accuracy: 0.392571 val accuracy: 0.401000\n",
      "lr 1.600000e-06 reg 2.510000e+03 train accuracy: 0.394224 val accuracy: 0.389000\n",
      "lr 1.600000e-06 reg 2.610000e+03 train accuracy: 0.390184 val accuracy: 0.394000\n",
      "lr 1.600000e-06 reg 2.710000e+03 train accuracy: 0.391327 val accuracy: 0.393000\n",
      "lr 1.600000e-06 reg 2.810000e+03 train accuracy: 0.389776 val accuracy: 0.386000\n",
      "lr 1.600000e-06 reg 2.910000e+03 train accuracy: 0.386918 val accuracy: 0.388000\n",
      "lr 1.600000e-06 reg 3.010000e+03 train accuracy: 0.390816 val accuracy: 0.388000\n",
      "lr 1.600000e-06 reg 3.110000e+03 train accuracy: 0.390837 val accuracy: 0.387000\n",
      "lr 1.600000e-06 reg 3.210000e+03 train accuracy: 0.383041 val accuracy: 0.379000\n",
      "lr 1.600000e-06 reg 3.310000e+03 train accuracy: 0.389837 val accuracy: 0.400000\n",
      "lr 1.600000e-06 reg 3.410000e+03 train accuracy: 0.381041 val accuracy: 0.389000\n",
      "lr 1.600000e-06 reg 3.510000e+03 train accuracy: 0.384041 val accuracy: 0.376000\n",
      "lr 1.600000e-06 reg 3.610000e+03 train accuracy: 0.386224 val accuracy: 0.399000\n",
      "lr 1.600000e-06 reg 3.710000e+03 train accuracy: 0.388714 val accuracy: 0.385000\n",
      "lr 1.600000e-06 reg 3.810000e+03 train accuracy: 0.386224 val accuracy: 0.400000\n",
      "lr 1.600000e-06 reg 3.910000e+03 train accuracy: 0.382449 val accuracy: 0.387000\n",
      "lr 1.600000e-06 reg 4.010000e+03 train accuracy: 0.380837 val accuracy: 0.382000\n",
      "lr 1.600000e-06 reg 4.110000e+03 train accuracy: 0.384878 val accuracy: 0.390000\n",
      "lr 1.600000e-06 reg 4.210000e+03 train accuracy: 0.385408 val accuracy: 0.382000\n",
      "lr 1.600000e-06 reg 4.310000e+03 train accuracy: 0.379429 val accuracy: 0.382000\n",
      "lr 1.600000e-06 reg 4.410000e+03 train accuracy: 0.383449 val accuracy: 0.380000\n",
      "lr 1.600000e-06 reg 4.510000e+03 train accuracy: 0.385653 val accuracy: 0.393000\n",
      "lr 1.600000e-06 reg 4.610000e+03 train accuracy: 0.382102 val accuracy: 0.389000\n",
      "lr 1.600000e-06 reg 4.710000e+03 train accuracy: 0.371367 val accuracy: 0.389000\n",
      "lr 1.600000e-06 reg 4.810000e+03 train accuracy: 0.380612 val accuracy: 0.376000\n",
      "lr 1.600000e-06 reg 4.910000e+03 train accuracy: 0.383592 val accuracy: 0.400000\n",
      "lr 1.600000e-06 reg 5.010000e+03 train accuracy: 0.383735 val accuracy: 0.375000\n",
      "lr 1.600000e-06 reg 5.110000e+03 train accuracy: 0.373082 val accuracy: 0.380000\n",
      "lr 1.600000e-06 reg 5.210000e+03 train accuracy: 0.370082 val accuracy: 0.365000\n",
      "lr 1.600000e-06 reg 5.310000e+03 train accuracy: 0.377837 val accuracy: 0.392000\n",
      "lr 1.600000e-06 reg 5.410000e+03 train accuracy: 0.364755 val accuracy: 0.380000\n",
      "lr 1.600000e-06 reg 5.510000e+03 train accuracy: 0.372633 val accuracy: 0.378000\n",
      "lr 1.600000e-06 reg 5.610000e+03 train accuracy: 0.376020 val accuracy: 0.390000\n",
      "lr 1.600000e-06 reg 5.710000e+03 train accuracy: 0.370510 val accuracy: 0.372000\n",
      "lr 1.600000e-06 reg 5.810000e+03 train accuracy: 0.380082 val accuracy: 0.395000\n",
      "lr 1.600000e-06 reg 5.910000e+03 train accuracy: 0.376041 val accuracy: 0.380000\n",
      "lr 1.600000e-06 reg 6.010000e+03 train accuracy: 0.369837 val accuracy: 0.368000\n",
      "lr 1.600000e-06 reg 6.110000e+03 train accuracy: 0.371184 val accuracy: 0.372000\n",
      "lr 1.600000e-06 reg 6.210000e+03 train accuracy: 0.365714 val accuracy: 0.365000\n",
      "lr 1.600000e-06 reg 6.310000e+03 train accuracy: 0.376102 val accuracy: 0.391000\n",
      "lr 1.600000e-06 reg 6.410000e+03 train accuracy: 0.374714 val accuracy: 0.393000\n",
      "lr 1.600000e-06 reg 6.510000e+03 train accuracy: 0.378306 val accuracy: 0.402000\n",
      "lr 1.600000e-06 reg 6.610000e+03 train accuracy: 0.367571 val accuracy: 0.347000\n",
      "lr 1.600000e-06 reg 6.710000e+03 train accuracy: 0.371612 val accuracy: 0.376000\n",
      "lr 1.600000e-06 reg 6.810000e+03 train accuracy: 0.362837 val accuracy: 0.370000\n",
      "lr 1.600000e-06 reg 6.910000e+03 train accuracy: 0.368898 val accuracy: 0.376000\n",
      "lr 1.600000e-06 reg 7.010000e+03 train accuracy: 0.364000 val accuracy: 0.377000\n",
      "lr 1.600000e-06 reg 7.110000e+03 train accuracy: 0.373796 val accuracy: 0.370000\n",
      "lr 1.600000e-06 reg 7.210000e+03 train accuracy: 0.369694 val accuracy: 0.370000\n",
      "lr 1.600000e-06 reg 7.310000e+03 train accuracy: 0.360673 val accuracy: 0.355000\n",
      "lr 1.600000e-06 reg 7.410000e+03 train accuracy: 0.367633 val accuracy: 0.379000\n",
      "lr 1.600000e-06 reg 7.510000e+03 train accuracy: 0.373102 val accuracy: 0.363000\n",
      "lr 1.600000e-06 reg 7.610000e+03 train accuracy: 0.370327 val accuracy: 0.378000\n",
      "lr 1.600000e-06 reg 7.710000e+03 train accuracy: 0.370735 val accuracy: 0.373000\n",
      "lr 1.600000e-06 reg 7.810000e+03 train accuracy: 0.372367 val accuracy: 0.377000\n",
      "lr 1.600000e-06 reg 7.910000e+03 train accuracy: 0.364510 val accuracy: 0.347000\n",
      "lr 1.600000e-06 reg 8.010000e+03 train accuracy: 0.366327 val accuracy: 0.370000\n",
      "lr 1.600000e-06 reg 8.110000e+03 train accuracy: 0.375531 val accuracy: 0.373000\n",
      "lr 1.600000e-06 reg 8.210000e+03 train accuracy: 0.371000 val accuracy: 0.368000\n",
      "lr 1.600000e-06 reg 8.310000e+03 train accuracy: 0.360939 val accuracy: 0.359000\n",
      "lr 1.600000e-06 reg 8.410000e+03 train accuracy: 0.368878 val accuracy: 0.358000\n",
      "lr 1.600000e-06 reg 8.510000e+03 train accuracy: 0.369673 val accuracy: 0.357000\n",
      "lr 1.600000e-06 reg 8.610000e+03 train accuracy: 0.362571 val accuracy: 0.370000\n",
      "lr 1.600000e-06 reg 8.710000e+03 train accuracy: 0.367347 val accuracy: 0.379000\n",
      "lr 1.600000e-06 reg 8.810000e+03 train accuracy: 0.356265 val accuracy: 0.371000\n",
      "lr 1.600000e-06 reg 8.910000e+03 train accuracy: 0.365163 val accuracy: 0.378000\n",
      "lr 1.600000e-06 reg 9.010000e+03 train accuracy: 0.363612 val accuracy: 0.373000\n",
      "lr 1.600000e-06 reg 9.110000e+03 train accuracy: 0.363469 val accuracy: 0.354000\n",
      "lr 1.600000e-06 reg 9.210000e+03 train accuracy: 0.363388 val accuracy: 0.368000\n",
      "lr 1.600000e-06 reg 9.310000e+03 train accuracy: 0.357673 val accuracy: 0.374000\n",
      "lr 1.600000e-06 reg 9.410000e+03 train accuracy: 0.365653 val accuracy: 0.375000\n",
      "lr 1.600000e-06 reg 9.510000e+03 train accuracy: 0.355714 val accuracy: 0.371000\n",
      "lr 1.600000e-06 reg 9.610000e+03 train accuracy: 0.364327 val accuracy: 0.379000\n",
      "lr 1.600000e-06 reg 9.710000e+03 train accuracy: 0.357224 val accuracy: 0.361000\n",
      "lr 1.600000e-06 reg 9.810000e+03 train accuracy: 0.368612 val accuracy: 0.371000\n",
      "lr 1.600000e-06 reg 9.910000e+03 train accuracy: 0.341959 val accuracy: 0.336000\n",
      "lr 2.100000e-06 reg 1.000000e+01 train accuracy: 0.357000 val accuracy: 0.334000\n",
      "lr 2.100000e-06 reg 1.100000e+02 train accuracy: 0.375449 val accuracy: 0.367000\n",
      "lr 2.100000e-06 reg 2.100000e+02 train accuracy: 0.380898 val accuracy: 0.383000\n",
      "lr 2.100000e-06 reg 3.100000e+02 train accuracy: 0.386939 val accuracy: 0.384000\n",
      "lr 2.100000e-06 reg 4.100000e+02 train accuracy: 0.397898 val accuracy: 0.394000\n",
      "lr 2.100000e-06 reg 5.100000e+02 train accuracy: 0.392102 val accuracy: 0.386000\n",
      "lr 2.100000e-06 reg 6.100000e+02 train accuracy: 0.401224 val accuracy: 0.395000\n",
      "lr 2.100000e-06 reg 7.100000e+02 train accuracy: 0.405612 val accuracy: 0.393000\n",
      "lr 2.100000e-06 reg 8.100000e+02 train accuracy: 0.386878 val accuracy: 0.372000\n",
      "lr 2.100000e-06 reg 9.100000e+02 train accuracy: 0.402122 val accuracy: 0.393000\n",
      "lr 2.100000e-06 reg 1.010000e+03 train accuracy: 0.378286 val accuracy: 0.370000\n",
      "lr 2.100000e-06 reg 1.110000e+03 train accuracy: 0.397551 val accuracy: 0.400000\n",
      "lr 2.100000e-06 reg 1.210000e+03 train accuracy: 0.391551 val accuracy: 0.405000\n",
      "lr 2.100000e-06 reg 1.310000e+03 train accuracy: 0.391918 val accuracy: 0.393000\n",
      "lr 2.100000e-06 reg 1.410000e+03 train accuracy: 0.402612 val accuracy: 0.399000\n",
      "lr 2.100000e-06 reg 1.510000e+03 train accuracy: 0.396592 val accuracy: 0.404000\n",
      "lr 2.100000e-06 reg 1.610000e+03 train accuracy: 0.396265 val accuracy: 0.376000\n",
      "lr 2.100000e-06 reg 1.710000e+03 train accuracy: 0.395898 val accuracy: 0.408000\n",
      "lr 2.100000e-06 reg 1.810000e+03 train accuracy: 0.392429 val accuracy: 0.398000\n",
      "lr 2.100000e-06 reg 1.910000e+03 train accuracy: 0.391612 val accuracy: 0.407000\n",
      "lr 2.100000e-06 reg 2.010000e+03 train accuracy: 0.386061 val accuracy: 0.385000\n",
      "lr 2.100000e-06 reg 2.110000e+03 train accuracy: 0.393204 val accuracy: 0.385000\n",
      "lr 2.100000e-06 reg 2.210000e+03 train accuracy: 0.393469 val accuracy: 0.404000\n",
      "lr 2.100000e-06 reg 2.310000e+03 train accuracy: 0.389816 val accuracy: 0.389000\n",
      "lr 2.100000e-06 reg 2.410000e+03 train accuracy: 0.382837 val accuracy: 0.374000\n",
      "lr 2.100000e-06 reg 2.510000e+03 train accuracy: 0.383898 val accuracy: 0.382000\n",
      "lr 2.100000e-06 reg 2.610000e+03 train accuracy: 0.394367 val accuracy: 0.404000\n",
      "lr 2.100000e-06 reg 2.710000e+03 train accuracy: 0.386694 val accuracy: 0.401000\n",
      "lr 2.100000e-06 reg 2.810000e+03 train accuracy: 0.373082 val accuracy: 0.373000\n",
      "lr 2.100000e-06 reg 2.910000e+03 train accuracy: 0.388327 val accuracy: 0.395000\n",
      "lr 2.100000e-06 reg 3.010000e+03 train accuracy: 0.386429 val accuracy: 0.396000\n",
      "lr 2.100000e-06 reg 3.110000e+03 train accuracy: 0.377102 val accuracy: 0.383000\n",
      "lr 2.100000e-06 reg 3.210000e+03 train accuracy: 0.373265 val accuracy: 0.385000\n",
      "lr 2.100000e-06 reg 3.310000e+03 train accuracy: 0.383469 val accuracy: 0.396000\n",
      "lr 2.100000e-06 reg 3.410000e+03 train accuracy: 0.377939 val accuracy: 0.382000\n",
      "lr 2.100000e-06 reg 3.510000e+03 train accuracy: 0.373184 val accuracy: 0.378000\n",
      "lr 2.100000e-06 reg 3.610000e+03 train accuracy: 0.384061 val accuracy: 0.382000\n",
      "lr 2.100000e-06 reg 3.710000e+03 train accuracy: 0.368388 val accuracy: 0.376000\n",
      "lr 2.100000e-06 reg 3.810000e+03 train accuracy: 0.376959 val accuracy: 0.379000\n",
      "lr 2.100000e-06 reg 3.910000e+03 train accuracy: 0.383061 val accuracy: 0.379000\n",
      "lr 2.100000e-06 reg 4.010000e+03 train accuracy: 0.378531 val accuracy: 0.392000\n",
      "lr 2.100000e-06 reg 4.110000e+03 train accuracy: 0.385000 val accuracy: 0.393000\n",
      "lr 2.100000e-06 reg 4.210000e+03 train accuracy: 0.374061 val accuracy: 0.358000\n",
      "lr 2.100000e-06 reg 4.310000e+03 train accuracy: 0.381143 val accuracy: 0.385000\n",
      "lr 2.100000e-06 reg 4.410000e+03 train accuracy: 0.377551 val accuracy: 0.388000\n",
      "lr 2.100000e-06 reg 4.510000e+03 train accuracy: 0.366612 val accuracy: 0.359000\n",
      "lr 2.100000e-06 reg 4.610000e+03 train accuracy: 0.365469 val accuracy: 0.353000\n",
      "lr 2.100000e-06 reg 4.710000e+03 train accuracy: 0.376469 val accuracy: 0.373000\n",
      "lr 2.100000e-06 reg 4.810000e+03 train accuracy: 0.377061 val accuracy: 0.377000\n",
      "lr 2.100000e-06 reg 4.910000e+03 train accuracy: 0.371673 val accuracy: 0.391000\n",
      "lr 2.100000e-06 reg 5.010000e+03 train accuracy: 0.380469 val accuracy: 0.387000\n",
      "lr 2.100000e-06 reg 5.110000e+03 train accuracy: 0.367061 val accuracy: 0.381000\n",
      "lr 2.100000e-06 reg 5.210000e+03 train accuracy: 0.372612 val accuracy: 0.376000\n",
      "lr 2.100000e-06 reg 5.310000e+03 train accuracy: 0.380714 val accuracy: 0.398000\n",
      "lr 2.100000e-06 reg 5.410000e+03 train accuracy: 0.373796 val accuracy: 0.392000\n",
      "lr 2.100000e-06 reg 5.510000e+03 train accuracy: 0.367816 val accuracy: 0.372000\n",
      "lr 2.100000e-06 reg 5.610000e+03 train accuracy: 0.369816 val accuracy: 0.378000\n",
      "lr 2.100000e-06 reg 5.710000e+03 train accuracy: 0.369531 val accuracy: 0.373000\n",
      "lr 2.100000e-06 reg 5.810000e+03 train accuracy: 0.370082 val accuracy: 0.369000\n",
      "lr 2.100000e-06 reg 5.910000e+03 train accuracy: 0.364041 val accuracy: 0.365000\n",
      "lr 2.100000e-06 reg 6.010000e+03 train accuracy: 0.358510 val accuracy: 0.366000\n",
      "lr 2.100000e-06 reg 6.110000e+03 train accuracy: 0.366082 val accuracy: 0.382000\n",
      "lr 2.100000e-06 reg 6.210000e+03 train accuracy: 0.368755 val accuracy: 0.379000\n",
      "lr 2.100000e-06 reg 6.310000e+03 train accuracy: 0.369388 val accuracy: 0.367000\n",
      "lr 2.100000e-06 reg 6.410000e+03 train accuracy: 0.370612 val accuracy: 0.360000\n",
      "lr 2.100000e-06 reg 6.510000e+03 train accuracy: 0.364898 val accuracy: 0.358000\n",
      "lr 2.100000e-06 reg 6.610000e+03 train accuracy: 0.365551 val accuracy: 0.366000\n",
      "lr 2.100000e-06 reg 6.710000e+03 train accuracy: 0.361735 val accuracy: 0.357000\n",
      "lr 2.100000e-06 reg 6.810000e+03 train accuracy: 0.367633 val accuracy: 0.381000\n",
      "lr 2.100000e-06 reg 6.910000e+03 train accuracy: 0.366673 val accuracy: 0.379000\n",
      "lr 2.100000e-06 reg 7.010000e+03 train accuracy: 0.361286 val accuracy: 0.362000\n",
      "lr 2.100000e-06 reg 7.110000e+03 train accuracy: 0.364673 val accuracy: 0.378000\n",
      "lr 2.100000e-06 reg 7.210000e+03 train accuracy: 0.372102 val accuracy: 0.374000\n",
      "lr 2.100000e-06 reg 7.310000e+03 train accuracy: 0.364265 val accuracy: 0.354000\n",
      "lr 2.100000e-06 reg 7.410000e+03 train accuracy: 0.366612 val accuracy: 0.379000\n",
      "lr 2.100000e-06 reg 7.510000e+03 train accuracy: 0.349184 val accuracy: 0.370000\n",
      "lr 2.100000e-06 reg 7.610000e+03 train accuracy: 0.353918 val accuracy: 0.351000\n",
      "lr 2.100000e-06 reg 7.710000e+03 train accuracy: 0.359143 val accuracy: 0.355000\n",
      "lr 2.100000e-06 reg 7.810000e+03 train accuracy: 0.368857 val accuracy: 0.381000\n",
      "lr 2.100000e-06 reg 7.910000e+03 train accuracy: 0.343837 val accuracy: 0.355000\n",
      "lr 2.100000e-06 reg 8.010000e+03 train accuracy: 0.359143 val accuracy: 0.350000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 2.100000e-06 reg 8.110000e+03 train accuracy: 0.346163 val accuracy: 0.357000\n",
      "lr 2.100000e-06 reg 8.210000e+03 train accuracy: 0.361898 val accuracy: 0.375000\n",
      "lr 2.100000e-06 reg 8.310000e+03 train accuracy: 0.360367 val accuracy: 0.359000\n",
      "lr 2.100000e-06 reg 8.410000e+03 train accuracy: 0.358469 val accuracy: 0.357000\n",
      "lr 2.100000e-06 reg 8.510000e+03 train accuracy: 0.365388 val accuracy: 0.363000\n",
      "lr 2.100000e-06 reg 8.610000e+03 train accuracy: 0.356469 val accuracy: 0.357000\n",
      "lr 2.100000e-06 reg 8.710000e+03 train accuracy: 0.358673 val accuracy: 0.363000\n",
      "lr 2.100000e-06 reg 8.810000e+03 train accuracy: 0.347490 val accuracy: 0.338000\n",
      "lr 2.100000e-06 reg 8.910000e+03 train accuracy: 0.352265 val accuracy: 0.350000\n",
      "lr 2.100000e-06 reg 9.010000e+03 train accuracy: 0.362020 val accuracy: 0.387000\n",
      "lr 2.100000e-06 reg 9.110000e+03 train accuracy: 0.360061 val accuracy: 0.371000\n",
      "lr 2.100000e-06 reg 9.210000e+03 train accuracy: 0.355286 val accuracy: 0.359000\n",
      "lr 2.100000e-06 reg 9.310000e+03 train accuracy: 0.355939 val accuracy: 0.344000\n",
      "lr 2.100000e-06 reg 9.410000e+03 train accuracy: 0.354796 val accuracy: 0.369000\n",
      "lr 2.100000e-06 reg 9.510000e+03 train accuracy: 0.352347 val accuracy: 0.356000\n",
      "lr 2.100000e-06 reg 9.610000e+03 train accuracy: 0.362041 val accuracy: 0.359000\n",
      "lr 2.100000e-06 reg 9.710000e+03 train accuracy: 0.349163 val accuracy: 0.359000\n",
      "lr 2.100000e-06 reg 9.810000e+03 train accuracy: 0.362286 val accuracy: 0.367000\n",
      "lr 2.100000e-06 reg 9.910000e+03 train accuracy: 0.346102 val accuracy: 0.355000\n",
      "lr 2.600000e-06 reg 1.000000e+01 train accuracy: 0.365061 val accuracy: 0.373000\n",
      "lr 2.600000e-06 reg 1.100000e+02 train accuracy: 0.380939 val accuracy: 0.362000\n",
      "lr 2.600000e-06 reg 2.100000e+02 train accuracy: 0.383816 val accuracy: 0.360000\n",
      "lr 2.600000e-06 reg 3.100000e+02 train accuracy: 0.393265 val accuracy: 0.398000\n",
      "lr 2.600000e-06 reg 4.100000e+02 train accuracy: 0.405837 val accuracy: 0.380000\n",
      "lr 2.600000e-06 reg 5.100000e+02 train accuracy: 0.393388 val accuracy: 0.391000\n",
      "lr 2.600000e-06 reg 6.100000e+02 train accuracy: 0.400714 val accuracy: 0.388000\n",
      "lr 2.600000e-06 reg 7.100000e+02 train accuracy: 0.385735 val accuracy: 0.387000\n",
      "lr 2.600000e-06 reg 8.100000e+02 train accuracy: 0.405714 val accuracy: 0.409000\n",
      "lr 2.600000e-06 reg 9.100000e+02 train accuracy: 0.403245 val accuracy: 0.401000\n",
      "lr 2.600000e-06 reg 1.010000e+03 train accuracy: 0.395939 val accuracy: 0.387000\n",
      "lr 2.600000e-06 reg 1.110000e+03 train accuracy: 0.386531 val accuracy: 0.391000\n",
      "lr 2.600000e-06 reg 1.210000e+03 train accuracy: 0.402102 val accuracy: 0.398000\n",
      "lr 2.600000e-06 reg 1.310000e+03 train accuracy: 0.394082 val accuracy: 0.387000\n",
      "lr 2.600000e-06 reg 1.410000e+03 train accuracy: 0.395020 val accuracy: 0.400000\n",
      "lr 2.600000e-06 reg 1.510000e+03 train accuracy: 0.397796 val accuracy: 0.389000\n",
      "lr 2.600000e-06 reg 1.610000e+03 train accuracy: 0.370776 val accuracy: 0.362000\n",
      "lr 2.600000e-06 reg 1.710000e+03 train accuracy: 0.389224 val accuracy: 0.375000\n",
      "lr 2.600000e-06 reg 1.810000e+03 train accuracy: 0.369490 val accuracy: 0.366000\n",
      "lr 2.600000e-06 reg 1.910000e+03 train accuracy: 0.376776 val accuracy: 0.377000\n",
      "lr 2.600000e-06 reg 2.010000e+03 train accuracy: 0.393469 val accuracy: 0.407000\n",
      "lr 2.600000e-06 reg 2.110000e+03 train accuracy: 0.389612 val accuracy: 0.382000\n",
      "lr 2.600000e-06 reg 2.210000e+03 train accuracy: 0.389347 val accuracy: 0.387000\n",
      "lr 2.600000e-06 reg 2.310000e+03 train accuracy: 0.372776 val accuracy: 0.384000\n",
      "lr 2.600000e-06 reg 2.410000e+03 train accuracy: 0.381408 val accuracy: 0.377000\n",
      "lr 2.600000e-06 reg 2.510000e+03 train accuracy: 0.362204 val accuracy: 0.357000\n",
      "lr 2.600000e-06 reg 2.610000e+03 train accuracy: 0.375755 val accuracy: 0.382000\n",
      "lr 2.600000e-06 reg 2.710000e+03 train accuracy: 0.375490 val accuracy: 0.392000\n",
      "lr 2.600000e-06 reg 2.810000e+03 train accuracy: 0.376122 val accuracy: 0.373000\n",
      "lr 2.600000e-06 reg 2.910000e+03 train accuracy: 0.373061 val accuracy: 0.370000\n",
      "lr 2.600000e-06 reg 3.010000e+03 train accuracy: 0.381143 val accuracy: 0.385000\n",
      "lr 2.600000e-06 reg 3.110000e+03 train accuracy: 0.375571 val accuracy: 0.379000\n",
      "lr 2.600000e-06 reg 3.210000e+03 train accuracy: 0.386122 val accuracy: 0.397000\n",
      "lr 2.600000e-06 reg 3.310000e+03 train accuracy: 0.352898 val accuracy: 0.362000\n",
      "lr 2.600000e-06 reg 3.410000e+03 train accuracy: 0.356082 val accuracy: 0.373000\n",
      "lr 2.600000e-06 reg 3.510000e+03 train accuracy: 0.374204 val accuracy: 0.375000\n",
      "lr 2.600000e-06 reg 3.610000e+03 train accuracy: 0.380918 val accuracy: 0.397000\n",
      "lr 2.600000e-06 reg 3.710000e+03 train accuracy: 0.371041 val accuracy: 0.376000\n",
      "lr 2.600000e-06 reg 3.810000e+03 train accuracy: 0.375000 val accuracy: 0.384000\n",
      "lr 2.600000e-06 reg 3.910000e+03 train accuracy: 0.376000 val accuracy: 0.380000\n",
      "lr 2.600000e-06 reg 4.010000e+03 train accuracy: 0.376000 val accuracy: 0.378000\n",
      "lr 2.600000e-06 reg 4.110000e+03 train accuracy: 0.369878 val accuracy: 0.360000\n",
      "lr 2.600000e-06 reg 4.210000e+03 train accuracy: 0.366531 val accuracy: 0.375000\n",
      "lr 2.600000e-06 reg 4.310000e+03 train accuracy: 0.376265 val accuracy: 0.375000\n",
      "lr 2.600000e-06 reg 4.410000e+03 train accuracy: 0.363551 val accuracy: 0.376000\n",
      "lr 2.600000e-06 reg 4.510000e+03 train accuracy: 0.363592 val accuracy: 0.364000\n",
      "lr 2.600000e-06 reg 4.610000e+03 train accuracy: 0.358714 val accuracy: 0.365000\n",
      "lr 2.600000e-06 reg 4.710000e+03 train accuracy: 0.361612 val accuracy: 0.358000\n",
      "lr 2.600000e-06 reg 4.810000e+03 train accuracy: 0.366694 val accuracy: 0.368000\n",
      "lr 2.600000e-06 reg 4.910000e+03 train accuracy: 0.375327 val accuracy: 0.361000\n",
      "lr 2.600000e-06 reg 5.010000e+03 train accuracy: 0.362796 val accuracy: 0.375000\n",
      "lr 2.600000e-06 reg 5.110000e+03 train accuracy: 0.355000 val accuracy: 0.351000\n",
      "lr 2.600000e-06 reg 5.210000e+03 train accuracy: 0.365816 val accuracy: 0.370000\n",
      "lr 2.600000e-06 reg 5.310000e+03 train accuracy: 0.369980 val accuracy: 0.380000\n",
      "lr 2.600000e-06 reg 5.410000e+03 train accuracy: 0.375980 val accuracy: 0.382000\n",
      "lr 2.600000e-06 reg 5.510000e+03 train accuracy: 0.367184 val accuracy: 0.386000\n",
      "lr 2.600000e-06 reg 5.610000e+03 train accuracy: 0.347408 val accuracy: 0.353000\n",
      "lr 2.600000e-06 reg 5.710000e+03 train accuracy: 0.363837 val accuracy: 0.353000\n",
      "lr 2.600000e-06 reg 5.810000e+03 train accuracy: 0.364245 val accuracy: 0.375000\n",
      "lr 2.600000e-06 reg 5.910000e+03 train accuracy: 0.363347 val accuracy: 0.365000\n",
      "lr 2.600000e-06 reg 6.010000e+03 train accuracy: 0.366347 val accuracy: 0.372000\n",
      "lr 2.600000e-06 reg 6.110000e+03 train accuracy: 0.362653 val accuracy: 0.366000\n",
      "lr 2.600000e-06 reg 6.210000e+03 train accuracy: 0.373857 val accuracy: 0.374000\n",
      "lr 2.600000e-06 reg 6.310000e+03 train accuracy: 0.368286 val accuracy: 0.373000\n",
      "lr 2.600000e-06 reg 6.410000e+03 train accuracy: 0.358408 val accuracy: 0.367000\n",
      "lr 2.600000e-06 reg 6.510000e+03 train accuracy: 0.360102 val accuracy: 0.375000\n",
      "lr 2.600000e-06 reg 6.610000e+03 train accuracy: 0.368653 val accuracy: 0.376000\n",
      "lr 2.600000e-06 reg 6.710000e+03 train accuracy: 0.362939 val accuracy: 0.366000\n",
      "lr 2.600000e-06 reg 6.810000e+03 train accuracy: 0.356000 val accuracy: 0.362000\n",
      "lr 2.600000e-06 reg 6.910000e+03 train accuracy: 0.359469 val accuracy: 0.367000\n",
      "lr 2.600000e-06 reg 7.010000e+03 train accuracy: 0.354388 val accuracy: 0.362000\n",
      "lr 2.600000e-06 reg 7.110000e+03 train accuracy: 0.348429 val accuracy: 0.363000\n",
      "lr 2.600000e-06 reg 7.210000e+03 train accuracy: 0.357939 val accuracy: 0.363000\n",
      "lr 2.600000e-06 reg 7.310000e+03 train accuracy: 0.352939 val accuracy: 0.353000\n",
      "lr 2.600000e-06 reg 7.410000e+03 train accuracy: 0.356061 val accuracy: 0.366000\n",
      "lr 2.600000e-06 reg 7.510000e+03 train accuracy: 0.334449 val accuracy: 0.332000\n",
      "lr 2.600000e-06 reg 7.610000e+03 train accuracy: 0.341918 val accuracy: 0.343000\n",
      "lr 2.600000e-06 reg 7.710000e+03 train accuracy: 0.357735 val accuracy: 0.375000\n",
      "lr 2.600000e-06 reg 7.810000e+03 train accuracy: 0.342408 val accuracy: 0.363000\n",
      "lr 2.600000e-06 reg 7.910000e+03 train accuracy: 0.363531 val accuracy: 0.362000\n",
      "lr 2.600000e-06 reg 8.010000e+03 train accuracy: 0.356816 val accuracy: 0.354000\n",
      "lr 2.600000e-06 reg 8.110000e+03 train accuracy: 0.349633 val accuracy: 0.348000\n",
      "lr 2.600000e-06 reg 8.210000e+03 train accuracy: 0.365265 val accuracy: 0.375000\n",
      "lr 2.600000e-06 reg 8.310000e+03 train accuracy: 0.360878 val accuracy: 0.364000\n",
      "lr 2.600000e-06 reg 8.410000e+03 train accuracy: 0.358571 val accuracy: 0.350000\n",
      "lr 2.600000e-06 reg 8.510000e+03 train accuracy: 0.361000 val accuracy: 0.367000\n",
      "lr 2.600000e-06 reg 8.610000e+03 train accuracy: 0.345286 val accuracy: 0.358000\n",
      "lr 2.600000e-06 reg 8.710000e+03 train accuracy: 0.349000 val accuracy: 0.360000\n",
      "lr 2.600000e-06 reg 8.810000e+03 train accuracy: 0.350673 val accuracy: 0.353000\n",
      "lr 2.600000e-06 reg 8.910000e+03 train accuracy: 0.364306 val accuracy: 0.368000\n",
      "lr 2.600000e-06 reg 9.010000e+03 train accuracy: 0.358612 val accuracy: 0.365000\n",
      "lr 2.600000e-06 reg 9.110000e+03 train accuracy: 0.341327 val accuracy: 0.339000\n",
      "lr 2.600000e-06 reg 9.210000e+03 train accuracy: 0.350980 val accuracy: 0.371000\n",
      "lr 2.600000e-06 reg 9.310000e+03 train accuracy: 0.350306 val accuracy: 0.350000\n",
      "lr 2.600000e-06 reg 9.410000e+03 train accuracy: 0.350143 val accuracy: 0.361000\n",
      "lr 2.600000e-06 reg 9.510000e+03 train accuracy: 0.324367 val accuracy: 0.328000\n",
      "lr 2.600000e-06 reg 9.610000e+03 train accuracy: 0.354163 val accuracy: 0.357000\n",
      "lr 2.600000e-06 reg 9.710000e+03 train accuracy: 0.347245 val accuracy: 0.362000\n",
      "lr 2.600000e-06 reg 9.810000e+03 train accuracy: 0.339980 val accuracy: 0.342000\n",
      "lr 2.600000e-06 reg 9.910000e+03 train accuracy: 0.344469 val accuracy: 0.356000\n",
      "lr 3.100000e-06 reg 1.000000e+01 train accuracy: 0.373306 val accuracy: 0.339000\n",
      "lr 3.100000e-06 reg 1.100000e+02 train accuracy: 0.383653 val accuracy: 0.347000\n",
      "lr 3.100000e-06 reg 2.100000e+02 train accuracy: 0.391000 val accuracy: 0.379000\n",
      "lr 3.100000e-06 reg 3.100000e+02 train accuracy: 0.394694 val accuracy: 0.394000\n",
      "lr 3.100000e-06 reg 4.100000e+02 train accuracy: 0.401857 val accuracy: 0.393000\n",
      "lr 3.100000e-06 reg 5.100000e+02 train accuracy: 0.403408 val accuracy: 0.392000\n",
      "lr 3.100000e-06 reg 6.100000e+02 train accuracy: 0.401939 val accuracy: 0.389000\n",
      "lr 3.100000e-06 reg 7.100000e+02 train accuracy: 0.399898 val accuracy: 0.392000\n",
      "lr 3.100000e-06 reg 8.100000e+02 train accuracy: 0.403408 val accuracy: 0.413000\n",
      "lr 3.100000e-06 reg 9.100000e+02 train accuracy: 0.399408 val accuracy: 0.401000\n",
      "lr 3.100000e-06 reg 1.010000e+03 train accuracy: 0.398020 val accuracy: 0.413000\n",
      "lr 3.100000e-06 reg 1.110000e+03 train accuracy: 0.391694 val accuracy: 0.389000\n",
      "lr 3.100000e-06 reg 1.210000e+03 train accuracy: 0.380388 val accuracy: 0.391000\n",
      "lr 3.100000e-06 reg 1.310000e+03 train accuracy: 0.392490 val accuracy: 0.396000\n",
      "lr 3.100000e-06 reg 1.410000e+03 train accuracy: 0.384898 val accuracy: 0.370000\n",
      "lr 3.100000e-06 reg 1.510000e+03 train accuracy: 0.392429 val accuracy: 0.387000\n",
      "lr 3.100000e-06 reg 1.610000e+03 train accuracy: 0.382102 val accuracy: 0.377000\n",
      "lr 3.100000e-06 reg 1.710000e+03 train accuracy: 0.379673 val accuracy: 0.362000\n",
      "lr 3.100000e-06 reg 1.810000e+03 train accuracy: 0.394939 val accuracy: 0.394000\n",
      "lr 3.100000e-06 reg 1.910000e+03 train accuracy: 0.383918 val accuracy: 0.395000\n",
      "lr 3.100000e-06 reg 2.010000e+03 train accuracy: 0.381510 val accuracy: 0.368000\n",
      "lr 3.100000e-06 reg 2.110000e+03 train accuracy: 0.381388 val accuracy: 0.390000\n",
      "lr 3.100000e-06 reg 2.210000e+03 train accuracy: 0.380959 val accuracy: 0.367000\n",
      "lr 3.100000e-06 reg 2.310000e+03 train accuracy: 0.389551 val accuracy: 0.398000\n",
      "lr 3.100000e-06 reg 2.410000e+03 train accuracy: 0.368612 val accuracy: 0.362000\n",
      "lr 3.100000e-06 reg 2.510000e+03 train accuracy: 0.378000 val accuracy: 0.382000\n",
      "lr 3.100000e-06 reg 2.610000e+03 train accuracy: 0.383837 val accuracy: 0.397000\n",
      "lr 3.100000e-06 reg 2.710000e+03 train accuracy: 0.375224 val accuracy: 0.373000\n",
      "lr 3.100000e-06 reg 2.810000e+03 train accuracy: 0.370490 val accuracy: 0.359000\n",
      "lr 3.100000e-06 reg 2.910000e+03 train accuracy: 0.372449 val accuracy: 0.369000\n",
      "lr 3.100000e-06 reg 3.010000e+03 train accuracy: 0.361776 val accuracy: 0.358000\n",
      "lr 3.100000e-06 reg 3.110000e+03 train accuracy: 0.380612 val accuracy: 0.369000\n",
      "lr 3.100000e-06 reg 3.210000e+03 train accuracy: 0.366367 val accuracy: 0.370000\n",
      "lr 3.100000e-06 reg 3.310000e+03 train accuracy: 0.372388 val accuracy: 0.365000\n",
      "lr 3.100000e-06 reg 3.410000e+03 train accuracy: 0.364776 val accuracy: 0.372000\n",
      "lr 3.100000e-06 reg 3.510000e+03 train accuracy: 0.358306 val accuracy: 0.358000\n",
      "lr 3.100000e-06 reg 3.610000e+03 train accuracy: 0.362204 val accuracy: 0.370000\n",
      "lr 3.100000e-06 reg 3.710000e+03 train accuracy: 0.365265 val accuracy: 0.361000\n",
      "lr 3.100000e-06 reg 3.810000e+03 train accuracy: 0.349061 val accuracy: 0.342000\n",
      "lr 3.100000e-06 reg 3.910000e+03 train accuracy: 0.365224 val accuracy: 0.371000\n",
      "lr 3.100000e-06 reg 4.010000e+03 train accuracy: 0.367857 val accuracy: 0.359000\n",
      "lr 3.100000e-06 reg 4.110000e+03 train accuracy: 0.361490 val accuracy: 0.375000\n",
      "lr 3.100000e-06 reg 4.210000e+03 train accuracy: 0.356776 val accuracy: 0.357000\n",
      "lr 3.100000e-06 reg 4.310000e+03 train accuracy: 0.362286 val accuracy: 0.371000\n",
      "lr 3.100000e-06 reg 4.410000e+03 train accuracy: 0.373939 val accuracy: 0.395000\n",
      "lr 3.100000e-06 reg 4.510000e+03 train accuracy: 0.359816 val accuracy: 0.353000\n",
      "lr 3.100000e-06 reg 4.610000e+03 train accuracy: 0.361449 val accuracy: 0.358000\n",
      "lr 3.100000e-06 reg 4.710000e+03 train accuracy: 0.365061 val accuracy: 0.353000\n",
      "lr 3.100000e-06 reg 4.810000e+03 train accuracy: 0.361959 val accuracy: 0.366000\n",
      "lr 3.100000e-06 reg 4.910000e+03 train accuracy: 0.359061 val accuracy: 0.352000\n",
      "lr 3.100000e-06 reg 5.010000e+03 train accuracy: 0.353286 val accuracy: 0.367000\n",
      "lr 3.100000e-06 reg 5.110000e+03 train accuracy: 0.337776 val accuracy: 0.340000\n",
      "lr 3.100000e-06 reg 5.210000e+03 train accuracy: 0.352061 val accuracy: 0.346000\n",
      "lr 3.100000e-06 reg 5.310000e+03 train accuracy: 0.348469 val accuracy: 0.347000\n",
      "lr 3.100000e-06 reg 5.410000e+03 train accuracy: 0.343204 val accuracy: 0.343000\n",
      "lr 3.100000e-06 reg 5.510000e+03 train accuracy: 0.352694 val accuracy: 0.354000\n",
      "lr 3.100000e-06 reg 5.610000e+03 train accuracy: 0.359592 val accuracy: 0.369000\n",
      "lr 3.100000e-06 reg 5.710000e+03 train accuracy: 0.360102 val accuracy: 0.346000\n",
      "lr 3.100000e-06 reg 5.810000e+03 train accuracy: 0.366469 val accuracy: 0.382000\n",
      "lr 3.100000e-06 reg 5.910000e+03 train accuracy: 0.356633 val accuracy: 0.353000\n",
      "lr 3.100000e-06 reg 6.010000e+03 train accuracy: 0.354510 val accuracy: 0.347000\n",
      "lr 3.100000e-06 reg 6.110000e+03 train accuracy: 0.356490 val accuracy: 0.363000\n",
      "lr 3.100000e-06 reg 6.210000e+03 train accuracy: 0.357939 val accuracy: 0.362000\n",
      "lr 3.100000e-06 reg 6.310000e+03 train accuracy: 0.339510 val accuracy: 0.357000\n",
      "lr 3.100000e-06 reg 6.410000e+03 train accuracy: 0.360878 val accuracy: 0.364000\n",
      "lr 3.100000e-06 reg 6.510000e+03 train accuracy: 0.345959 val accuracy: 0.357000\n",
      "lr 3.100000e-06 reg 6.610000e+03 train accuracy: 0.360102 val accuracy: 0.373000\n",
      "lr 3.100000e-06 reg 6.710000e+03 train accuracy: 0.359469 val accuracy: 0.368000\n",
      "lr 3.100000e-06 reg 6.810000e+03 train accuracy: 0.344367 val accuracy: 0.343000\n",
      "lr 3.100000e-06 reg 6.910000e+03 train accuracy: 0.348020 val accuracy: 0.353000\n",
      "lr 3.100000e-06 reg 7.010000e+03 train accuracy: 0.360286 val accuracy: 0.357000\n",
      "lr 3.100000e-06 reg 7.110000e+03 train accuracy: 0.347755 val accuracy: 0.367000\n",
      "lr 3.100000e-06 reg 7.210000e+03 train accuracy: 0.365265 val accuracy: 0.380000\n",
      "lr 3.100000e-06 reg 7.310000e+03 train accuracy: 0.351408 val accuracy: 0.349000\n",
      "lr 3.100000e-06 reg 7.410000e+03 train accuracy: 0.360510 val accuracy: 0.365000\n",
      "lr 3.100000e-06 reg 7.510000e+03 train accuracy: 0.358796 val accuracy: 0.368000\n",
      "lr 3.100000e-06 reg 7.610000e+03 train accuracy: 0.345449 val accuracy: 0.356000\n",
      "lr 3.100000e-06 reg 7.710000e+03 train accuracy: 0.354653 val accuracy: 0.370000\n",
      "lr 3.100000e-06 reg 7.810000e+03 train accuracy: 0.338633 val accuracy: 0.322000\n",
      "lr 3.100000e-06 reg 7.910000e+03 train accuracy: 0.355306 val accuracy: 0.362000\n",
      "lr 3.100000e-06 reg 8.010000e+03 train accuracy: 0.341959 val accuracy: 0.365000\n",
      "lr 3.100000e-06 reg 8.110000e+03 train accuracy: 0.310633 val accuracy: 0.333000\n",
      "lr 3.100000e-06 reg 8.210000e+03 train accuracy: 0.343592 val accuracy: 0.353000\n",
      "lr 3.100000e-06 reg 8.310000e+03 train accuracy: 0.343857 val accuracy: 0.359000\n",
      "lr 3.100000e-06 reg 8.410000e+03 train accuracy: 0.353694 val accuracy: 0.378000\n",
      "lr 3.100000e-06 reg 8.510000e+03 train accuracy: 0.338714 val accuracy: 0.342000\n",
      "lr 3.100000e-06 reg 8.610000e+03 train accuracy: 0.344612 val accuracy: 0.346000\n",
      "lr 3.100000e-06 reg 8.710000e+03 train accuracy: 0.338980 val accuracy: 0.369000\n",
      "lr 3.100000e-06 reg 8.810000e+03 train accuracy: 0.346755 val accuracy: 0.346000\n",
      "lr 3.100000e-06 reg 8.910000e+03 train accuracy: 0.344531 val accuracy: 0.346000\n",
      "lr 3.100000e-06 reg 9.010000e+03 train accuracy: 0.335612 val accuracy: 0.350000\n",
      "lr 3.100000e-06 reg 9.110000e+03 train accuracy: 0.335633 val accuracy: 0.363000\n",
      "lr 3.100000e-06 reg 9.210000e+03 train accuracy: 0.354327 val accuracy: 0.367000\n",
      "lr 3.100000e-06 reg 9.310000e+03 train accuracy: 0.344306 val accuracy: 0.352000\n",
      "lr 3.100000e-06 reg 9.410000e+03 train accuracy: 0.346388 val accuracy: 0.339000\n",
      "lr 3.100000e-06 reg 9.510000e+03 train accuracy: 0.348000 val accuracy: 0.352000\n",
      "lr 3.100000e-06 reg 9.610000e+03 train accuracy: 0.352673 val accuracy: 0.354000\n",
      "lr 3.100000e-06 reg 9.710000e+03 train accuracy: 0.342612 val accuracy: 0.347000\n",
      "lr 3.100000e-06 reg 9.810000e+03 train accuracy: 0.357429 val accuracy: 0.367000\n",
      "lr 3.100000e-06 reg 9.910000e+03 train accuracy: 0.332469 val accuracy: 0.346000\n",
      "lr 3.600000e-06 reg 1.000000e+01 train accuracy: 0.378408 val accuracy: 0.360000\n",
      "lr 3.600000e-06 reg 1.100000e+02 train accuracy: 0.384776 val accuracy: 0.376000\n",
      "lr 3.600000e-06 reg 2.100000e+02 train accuracy: 0.390939 val accuracy: 0.381000\n",
      "lr 3.600000e-06 reg 3.100000e+02 train accuracy: 0.392755 val accuracy: 0.372000\n",
      "lr 3.600000e-06 reg 4.100000e+02 train accuracy: 0.402408 val accuracy: 0.384000\n",
      "lr 3.600000e-06 reg 5.100000e+02 train accuracy: 0.401306 val accuracy: 0.401000\n",
      "lr 3.600000e-06 reg 6.100000e+02 train accuracy: 0.390163 val accuracy: 0.376000\n",
      "lr 3.600000e-06 reg 7.100000e+02 train accuracy: 0.401143 val accuracy: 0.399000\n",
      "lr 3.600000e-06 reg 8.100000e+02 train accuracy: 0.391082 val accuracy: 0.387000\n",
      "lr 3.600000e-06 reg 9.100000e+02 train accuracy: 0.385571 val accuracy: 0.381000\n",
      "lr 3.600000e-06 reg 1.010000e+03 train accuracy: 0.385449 val accuracy: 0.373000\n",
      "lr 3.600000e-06 reg 1.110000e+03 train accuracy: 0.393224 val accuracy: 0.376000\n",
      "lr 3.600000e-06 reg 1.210000e+03 train accuracy: 0.384184 val accuracy: 0.379000\n",
      "lr 3.600000e-06 reg 1.310000e+03 train accuracy: 0.373959 val accuracy: 0.359000\n",
      "lr 3.600000e-06 reg 1.410000e+03 train accuracy: 0.388612 val accuracy: 0.392000\n",
      "lr 3.600000e-06 reg 1.510000e+03 train accuracy: 0.375918 val accuracy: 0.377000\n",
      "lr 3.600000e-06 reg 1.610000e+03 train accuracy: 0.382102 val accuracy: 0.384000\n",
      "lr 3.600000e-06 reg 1.710000e+03 train accuracy: 0.384143 val accuracy: 0.380000\n",
      "lr 3.600000e-06 reg 1.810000e+03 train accuracy: 0.387020 val accuracy: 0.375000\n",
      "lr 3.600000e-06 reg 1.910000e+03 train accuracy: 0.371306 val accuracy: 0.373000\n",
      "lr 3.600000e-06 reg 2.010000e+03 train accuracy: 0.364041 val accuracy: 0.358000\n",
      "lr 3.600000e-06 reg 2.110000e+03 train accuracy: 0.377837 val accuracy: 0.388000\n",
      "lr 3.600000e-06 reg 2.210000e+03 train accuracy: 0.362653 val accuracy: 0.354000\n",
      "lr 3.600000e-06 reg 2.310000e+03 train accuracy: 0.361122 val accuracy: 0.364000\n",
      "lr 3.600000e-06 reg 2.410000e+03 train accuracy: 0.380143 val accuracy: 0.385000\n",
      "lr 3.600000e-06 reg 2.510000e+03 train accuracy: 0.371653 val accuracy: 0.364000\n",
      "lr 3.600000e-06 reg 2.610000e+03 train accuracy: 0.369816 val accuracy: 0.366000\n",
      "lr 3.600000e-06 reg 2.710000e+03 train accuracy: 0.363041 val accuracy: 0.356000\n",
      "lr 3.600000e-06 reg 2.810000e+03 train accuracy: 0.368776 val accuracy: 0.372000\n",
      "lr 3.600000e-06 reg 2.910000e+03 train accuracy: 0.373490 val accuracy: 0.380000\n",
      "lr 3.600000e-06 reg 3.010000e+03 train accuracy: 0.374449 val accuracy: 0.373000\n",
      "lr 3.600000e-06 reg 3.110000e+03 train accuracy: 0.365163 val accuracy: 0.388000\n",
      "lr 3.600000e-06 reg 3.210000e+03 train accuracy: 0.365469 val accuracy: 0.366000\n",
      "lr 3.600000e-06 reg 3.310000e+03 train accuracy: 0.367551 val accuracy: 0.374000\n",
      "lr 3.600000e-06 reg 3.410000e+03 train accuracy: 0.358531 val accuracy: 0.338000\n",
      "lr 3.600000e-06 reg 3.510000e+03 train accuracy: 0.363449 val accuracy: 0.350000\n",
      "lr 3.600000e-06 reg 3.610000e+03 train accuracy: 0.383510 val accuracy: 0.384000\n",
      "lr 3.600000e-06 reg 3.710000e+03 train accuracy: 0.359816 val accuracy: 0.362000\n",
      "lr 3.600000e-06 reg 3.810000e+03 train accuracy: 0.364265 val accuracy: 0.367000\n",
      "lr 3.600000e-06 reg 3.910000e+03 train accuracy: 0.343673 val accuracy: 0.355000\n",
      "lr 3.600000e-06 reg 4.010000e+03 train accuracy: 0.366143 val accuracy: 0.388000\n",
      "lr 3.600000e-06 reg 4.110000e+03 train accuracy: 0.356939 val accuracy: 0.377000\n",
      "lr 3.600000e-06 reg 4.210000e+03 train accuracy: 0.368449 val accuracy: 0.371000\n",
      "lr 3.600000e-06 reg 4.310000e+03 train accuracy: 0.350388 val accuracy: 0.346000\n",
      "lr 3.600000e-06 reg 4.410000e+03 train accuracy: 0.336918 val accuracy: 0.342000\n",
      "lr 3.600000e-06 reg 4.510000e+03 train accuracy: 0.362061 val accuracy: 0.379000\n",
      "lr 3.600000e-06 reg 4.610000e+03 train accuracy: 0.363694 val accuracy: 0.356000\n",
      "lr 3.600000e-06 reg 4.710000e+03 train accuracy: 0.357735 val accuracy: 0.358000\n",
      "lr 3.600000e-06 reg 4.810000e+03 train accuracy: 0.365184 val accuracy: 0.361000\n",
      "lr 3.600000e-06 reg 4.910000e+03 train accuracy: 0.350510 val accuracy: 0.347000\n",
      "lr 3.600000e-06 reg 5.010000e+03 train accuracy: 0.362204 val accuracy: 0.380000\n",
      "lr 3.600000e-06 reg 5.110000e+03 train accuracy: 0.354449 val accuracy: 0.367000\n",
      "lr 3.600000e-06 reg 5.210000e+03 train accuracy: 0.354857 val accuracy: 0.373000\n",
      "lr 3.600000e-06 reg 5.310000e+03 train accuracy: 0.361102 val accuracy: 0.382000\n",
      "lr 3.600000e-06 reg 5.410000e+03 train accuracy: 0.348592 val accuracy: 0.378000\n",
      "lr 3.600000e-06 reg 5.510000e+03 train accuracy: 0.339959 val accuracy: 0.345000\n",
      "lr 3.600000e-06 reg 5.610000e+03 train accuracy: 0.351000 val accuracy: 0.347000\n",
      "lr 3.600000e-06 reg 5.710000e+03 train accuracy: 0.350918 val accuracy: 0.365000\n",
      "lr 3.600000e-06 reg 5.810000e+03 train accuracy: 0.345755 val accuracy: 0.354000\n",
      "lr 3.600000e-06 reg 5.910000e+03 train accuracy: 0.371592 val accuracy: 0.362000\n",
      "lr 3.600000e-06 reg 6.010000e+03 train accuracy: 0.361082 val accuracy: 0.367000\n",
      "lr 3.600000e-06 reg 6.110000e+03 train accuracy: 0.346510 val accuracy: 0.341000\n",
      "lr 3.600000e-06 reg 6.210000e+03 train accuracy: 0.338388 val accuracy: 0.345000\n",
      "lr 3.600000e-06 reg 6.310000e+03 train accuracy: 0.318388 val accuracy: 0.337000\n",
      "lr 3.600000e-06 reg 6.410000e+03 train accuracy: 0.322612 val accuracy: 0.337000\n",
      "lr 3.600000e-06 reg 6.510000e+03 train accuracy: 0.333694 val accuracy: 0.358000\n",
      "lr 3.600000e-06 reg 6.610000e+03 train accuracy: 0.339735 val accuracy: 0.350000\n",
      "lr 3.600000e-06 reg 6.710000e+03 train accuracy: 0.326776 val accuracy: 0.326000\n",
      "lr 3.600000e-06 reg 6.810000e+03 train accuracy: 0.352816 val accuracy: 0.357000\n",
      "lr 3.600000e-06 reg 6.910000e+03 train accuracy: 0.357286 val accuracy: 0.364000\n",
      "lr 3.600000e-06 reg 7.010000e+03 train accuracy: 0.346898 val accuracy: 0.341000\n",
      "lr 3.600000e-06 reg 7.110000e+03 train accuracy: 0.333510 val accuracy: 0.317000\n",
      "lr 3.600000e-06 reg 7.210000e+03 train accuracy: 0.330204 val accuracy: 0.331000\n",
      "lr 3.600000e-06 reg 7.310000e+03 train accuracy: 0.321551 val accuracy: 0.321000\n",
      "lr 3.600000e-06 reg 7.410000e+03 train accuracy: 0.356776 val accuracy: 0.380000\n",
      "lr 3.600000e-06 reg 7.510000e+03 train accuracy: 0.343796 val accuracy: 0.346000\n",
      "lr 3.600000e-06 reg 7.610000e+03 train accuracy: 0.334898 val accuracy: 0.341000\n",
      "lr 3.600000e-06 reg 7.710000e+03 train accuracy: 0.341469 val accuracy: 0.345000\n",
      "lr 3.600000e-06 reg 7.810000e+03 train accuracy: 0.343878 val accuracy: 0.351000\n",
      "lr 3.600000e-06 reg 7.910000e+03 train accuracy: 0.355857 val accuracy: 0.357000\n",
      "lr 3.600000e-06 reg 8.010000e+03 train accuracy: 0.346347 val accuracy: 0.326000\n",
      "lr 3.600000e-06 reg 8.110000e+03 train accuracy: 0.350673 val accuracy: 0.356000\n",
      "lr 3.600000e-06 reg 8.210000e+03 train accuracy: 0.340653 val accuracy: 0.352000\n",
      "lr 3.600000e-06 reg 8.310000e+03 train accuracy: 0.346653 val accuracy: 0.359000\n",
      "lr 3.600000e-06 reg 8.410000e+03 train accuracy: 0.343571 val accuracy: 0.360000\n",
      "lr 3.600000e-06 reg 8.510000e+03 train accuracy: 0.348082 val accuracy: 0.369000\n",
      "lr 3.600000e-06 reg 8.610000e+03 train accuracy: 0.351612 val accuracy: 0.352000\n",
      "lr 3.600000e-06 reg 8.710000e+03 train accuracy: 0.336327 val accuracy: 0.325000\n",
      "lr 3.600000e-06 reg 8.810000e+03 train accuracy: 0.360551 val accuracy: 0.363000\n",
      "lr 3.600000e-06 reg 8.910000e+03 train accuracy: 0.333551 val accuracy: 0.354000\n",
      "lr 3.600000e-06 reg 9.010000e+03 train accuracy: 0.337510 val accuracy: 0.342000\n",
      "lr 3.600000e-06 reg 9.110000e+03 train accuracy: 0.333918 val accuracy: 0.326000\n",
      "lr 3.600000e-06 reg 9.210000e+03 train accuracy: 0.315000 val accuracy: 0.311000\n",
      "lr 3.600000e-06 reg 9.310000e+03 train accuracy: 0.336612 val accuracy: 0.333000\n",
      "lr 3.600000e-06 reg 9.410000e+03 train accuracy: 0.326306 val accuracy: 0.341000\n",
      "lr 3.600000e-06 reg 9.510000e+03 train accuracy: 0.321735 val accuracy: 0.332000\n",
      "lr 3.600000e-06 reg 9.610000e+03 train accuracy: 0.309714 val accuracy: 0.312000\n",
      "lr 3.600000e-06 reg 9.710000e+03 train accuracy: 0.316918 val accuracy: 0.302000\n",
      "lr 3.600000e-06 reg 9.810000e+03 train accuracy: 0.324388 val accuracy: 0.339000\n",
      "lr 3.600000e-06 reg 9.910000e+03 train accuracy: 0.332367 val accuracy: 0.337000\n",
      "lr 4.100000e-06 reg 1.000000e+01 train accuracy: 0.359551 val accuracy: 0.340000\n",
      "lr 4.100000e-06 reg 1.100000e+02 train accuracy: 0.374633 val accuracy: 0.348000\n",
      "lr 4.100000e-06 reg 2.100000e+02 train accuracy: 0.396102 val accuracy: 0.388000\n",
      "lr 4.100000e-06 reg 3.100000e+02 train accuracy: 0.389449 val accuracy: 0.370000\n",
      "lr 4.100000e-06 reg 4.100000e+02 train accuracy: 0.376041 val accuracy: 0.358000\n",
      "lr 4.100000e-06 reg 5.100000e+02 train accuracy: 0.393551 val accuracy: 0.398000\n",
      "lr 4.100000e-06 reg 6.100000e+02 train accuracy: 0.379571 val accuracy: 0.364000\n",
      "lr 4.100000e-06 reg 7.100000e+02 train accuracy: 0.400102 val accuracy: 0.385000\n",
      "lr 4.100000e-06 reg 8.100000e+02 train accuracy: 0.380939 val accuracy: 0.368000\n",
      "lr 4.100000e-06 reg 9.100000e+02 train accuracy: 0.376816 val accuracy: 0.386000\n",
      "lr 4.100000e-06 reg 1.010000e+03 train accuracy: 0.384327 val accuracy: 0.378000\n",
      "lr 4.100000e-06 reg 1.110000e+03 train accuracy: 0.389449 val accuracy: 0.385000\n",
      "lr 4.100000e-06 reg 1.210000e+03 train accuracy: 0.375000 val accuracy: 0.372000\n",
      "lr 4.100000e-06 reg 1.310000e+03 train accuracy: 0.394265 val accuracy: 0.392000\n",
      "lr 4.100000e-06 reg 1.410000e+03 train accuracy: 0.371122 val accuracy: 0.371000\n",
      "lr 4.100000e-06 reg 1.510000e+03 train accuracy: 0.375102 val accuracy: 0.388000\n",
      "lr 4.100000e-06 reg 1.610000e+03 train accuracy: 0.375469 val accuracy: 0.387000\n",
      "lr 4.100000e-06 reg 1.710000e+03 train accuracy: 0.357714 val accuracy: 0.345000\n",
      "lr 4.100000e-06 reg 1.810000e+03 train accuracy: 0.345939 val accuracy: 0.345000\n",
      "lr 4.100000e-06 reg 1.910000e+03 train accuracy: 0.371408 val accuracy: 0.366000\n",
      "lr 4.100000e-06 reg 2.010000e+03 train accuracy: 0.376388 val accuracy: 0.378000\n",
      "lr 4.100000e-06 reg 2.110000e+03 train accuracy: 0.368163 val accuracy: 0.405000\n",
      "lr 4.100000e-06 reg 2.210000e+03 train accuracy: 0.370918 val accuracy: 0.369000\n",
      "lr 4.100000e-06 reg 2.310000e+03 train accuracy: 0.379184 val accuracy: 0.382000\n",
      "lr 4.100000e-06 reg 2.410000e+03 train accuracy: 0.352653 val accuracy: 0.330000\n",
      "lr 4.100000e-06 reg 2.510000e+03 train accuracy: 0.353939 val accuracy: 0.346000\n",
      "lr 4.100000e-06 reg 2.610000e+03 train accuracy: 0.376796 val accuracy: 0.386000\n",
      "lr 4.100000e-06 reg 2.710000e+03 train accuracy: 0.374755 val accuracy: 0.379000\n",
      "lr 4.100000e-06 reg 2.810000e+03 train accuracy: 0.371592 val accuracy: 0.375000\n",
      "lr 4.100000e-06 reg 2.910000e+03 train accuracy: 0.363796 val accuracy: 0.372000\n",
      "lr 4.100000e-06 reg 3.010000e+03 train accuracy: 0.356939 val accuracy: 0.362000\n",
      "lr 4.100000e-06 reg 3.110000e+03 train accuracy: 0.313388 val accuracy: 0.324000\n",
      "lr 4.100000e-06 reg 3.210000e+03 train accuracy: 0.349020 val accuracy: 0.365000\n",
      "lr 4.100000e-06 reg 3.310000e+03 train accuracy: 0.348143 val accuracy: 0.356000\n",
      "lr 4.100000e-06 reg 3.410000e+03 train accuracy: 0.371571 val accuracy: 0.383000\n",
      "lr 4.100000e-06 reg 3.510000e+03 train accuracy: 0.367327 val accuracy: 0.365000\n",
      "lr 4.100000e-06 reg 3.610000e+03 train accuracy: 0.357408 val accuracy: 0.380000\n",
      "lr 4.100000e-06 reg 3.710000e+03 train accuracy: 0.346816 val accuracy: 0.342000\n",
      "lr 4.100000e-06 reg 3.810000e+03 train accuracy: 0.332673 val accuracy: 0.317000\n",
      "lr 4.100000e-06 reg 3.910000e+03 train accuracy: 0.362429 val accuracy: 0.376000\n",
      "lr 4.100000e-06 reg 4.010000e+03 train accuracy: 0.347633 val accuracy: 0.362000\n",
      "lr 4.100000e-06 reg 4.110000e+03 train accuracy: 0.352980 val accuracy: 0.358000\n",
      "lr 4.100000e-06 reg 4.210000e+03 train accuracy: 0.346653 val accuracy: 0.352000\n",
      "lr 4.100000e-06 reg 4.310000e+03 train accuracy: 0.370755 val accuracy: 0.363000\n",
      "lr 4.100000e-06 reg 4.410000e+03 train accuracy: 0.342367 val accuracy: 0.345000\n",
      "lr 4.100000e-06 reg 4.510000e+03 train accuracy: 0.365327 val accuracy: 0.374000\n",
      "lr 4.100000e-06 reg 4.610000e+03 train accuracy: 0.322163 val accuracy: 0.329000\n",
      "lr 4.100000e-06 reg 4.710000e+03 train accuracy: 0.335571 val accuracy: 0.326000\n",
      "lr 4.100000e-06 reg 4.810000e+03 train accuracy: 0.344816 val accuracy: 0.351000\n",
      "lr 4.100000e-06 reg 4.910000e+03 train accuracy: 0.341510 val accuracy: 0.348000\n",
      "lr 4.100000e-06 reg 5.010000e+03 train accuracy: 0.321755 val accuracy: 0.312000\n",
      "lr 4.100000e-06 reg 5.110000e+03 train accuracy: 0.331000 val accuracy: 0.331000\n",
      "lr 4.100000e-06 reg 5.210000e+03 train accuracy: 0.349551 val accuracy: 0.356000\n",
      "lr 4.100000e-06 reg 5.310000e+03 train accuracy: 0.364653 val accuracy: 0.368000\n",
      "lr 4.100000e-06 reg 5.410000e+03 train accuracy: 0.343653 val accuracy: 0.357000\n",
      "lr 4.100000e-06 reg 5.510000e+03 train accuracy: 0.348837 val accuracy: 0.363000\n",
      "lr 4.100000e-06 reg 5.610000e+03 train accuracy: 0.339612 val accuracy: 0.360000\n",
      "lr 4.100000e-06 reg 5.710000e+03 train accuracy: 0.349163 val accuracy: 0.365000\n",
      "lr 4.100000e-06 reg 5.810000e+03 train accuracy: 0.354082 val accuracy: 0.346000\n",
      "lr 4.100000e-06 reg 5.910000e+03 train accuracy: 0.349388 val accuracy: 0.361000\n",
      "lr 4.100000e-06 reg 6.010000e+03 train accuracy: 0.360306 val accuracy: 0.349000\n",
      "lr 4.100000e-06 reg 6.110000e+03 train accuracy: 0.341551 val accuracy: 0.361000\n",
      "lr 4.100000e-06 reg 6.210000e+03 train accuracy: 0.329510 val accuracy: 0.341000\n",
      "lr 4.100000e-06 reg 6.310000e+03 train accuracy: 0.340469 val accuracy: 0.346000\n",
      "lr 4.100000e-06 reg 6.410000e+03 train accuracy: 0.331776 val accuracy: 0.352000\n",
      "lr 4.100000e-06 reg 6.510000e+03 train accuracy: 0.350286 val accuracy: 0.354000\n",
      "lr 4.100000e-06 reg 6.610000e+03 train accuracy: 0.331469 val accuracy: 0.343000\n",
      "lr 4.100000e-06 reg 6.710000e+03 train accuracy: 0.337388 val accuracy: 0.351000\n",
      "lr 4.100000e-06 reg 6.810000e+03 train accuracy: 0.315347 val accuracy: 0.330000\n",
      "lr 4.100000e-06 reg 6.910000e+03 train accuracy: 0.330061 val accuracy: 0.332000\n",
      "lr 4.100000e-06 reg 7.010000e+03 train accuracy: 0.331531 val accuracy: 0.341000\n",
      "lr 4.100000e-06 reg 7.110000e+03 train accuracy: 0.345041 val accuracy: 0.363000\n",
      "lr 4.100000e-06 reg 7.210000e+03 train accuracy: 0.329082 val accuracy: 0.333000\n",
      "lr 4.100000e-06 reg 7.310000e+03 train accuracy: 0.299245 val accuracy: 0.332000\n",
      "lr 4.100000e-06 reg 7.410000e+03 train accuracy: 0.332592 val accuracy: 0.341000\n",
      "lr 4.100000e-06 reg 7.510000e+03 train accuracy: 0.339959 val accuracy: 0.341000\n",
      "lr 4.100000e-06 reg 7.610000e+03 train accuracy: 0.346755 val accuracy: 0.346000\n",
      "lr 4.100000e-06 reg 7.710000e+03 train accuracy: 0.304041 val accuracy: 0.308000\n",
      "lr 4.100000e-06 reg 7.810000e+03 train accuracy: 0.317429 val accuracy: 0.319000\n",
      "lr 4.100000e-06 reg 7.910000e+03 train accuracy: 0.346469 val accuracy: 0.345000\n",
      "lr 4.100000e-06 reg 8.010000e+03 train accuracy: 0.337327 val accuracy: 0.327000\n",
      "lr 4.100000e-06 reg 8.110000e+03 train accuracy: 0.341776 val accuracy: 0.353000\n",
      "lr 4.100000e-06 reg 8.210000e+03 train accuracy: 0.355265 val accuracy: 0.354000\n",
      "lr 4.100000e-06 reg 8.310000e+03 train accuracy: 0.341694 val accuracy: 0.317000\n",
      "lr 4.100000e-06 reg 8.410000e+03 train accuracy: 0.336143 val accuracy: 0.324000\n",
      "lr 4.100000e-06 reg 8.510000e+03 train accuracy: 0.336898 val accuracy: 0.345000\n",
      "lr 4.100000e-06 reg 8.610000e+03 train accuracy: 0.331510 val accuracy: 0.345000\n",
      "lr 4.100000e-06 reg 8.710000e+03 train accuracy: 0.345265 val accuracy: 0.365000\n",
      "lr 4.100000e-06 reg 8.810000e+03 train accuracy: 0.322469 val accuracy: 0.329000\n",
      "lr 4.100000e-06 reg 8.910000e+03 train accuracy: 0.328490 val accuracy: 0.341000\n",
      "lr 4.100000e-06 reg 9.010000e+03 train accuracy: 0.336469 val accuracy: 0.345000\n",
      "lr 4.100000e-06 reg 9.110000e+03 train accuracy: 0.327694 val accuracy: 0.345000\n",
      "lr 4.100000e-06 reg 9.210000e+03 train accuracy: 0.330449 val accuracy: 0.326000\n",
      "lr 4.100000e-06 reg 9.310000e+03 train accuracy: 0.339571 val accuracy: 0.346000\n",
      "lr 4.100000e-06 reg 9.410000e+03 train accuracy: 0.340143 val accuracy: 0.356000\n",
      "lr 4.100000e-06 reg 9.510000e+03 train accuracy: 0.327102 val accuracy: 0.330000\n",
      "lr 4.100000e-06 reg 9.610000e+03 train accuracy: 0.296939 val accuracy: 0.301000\n",
      "lr 4.100000e-06 reg 9.710000e+03 train accuracy: 0.325531 val accuracy: 0.326000\n",
      "lr 4.100000e-06 reg 9.810000e+03 train accuracy: 0.337102 val accuracy: 0.349000\n",
      "lr 4.100000e-06 reg 9.910000e+03 train accuracy: 0.306816 val accuracy: 0.316000\n",
      "lr 4.600000e-06 reg 1.000000e+01 train accuracy: 0.379429 val accuracy: 0.355000\n",
      "lr 4.600000e-06 reg 1.100000e+02 train accuracy: 0.385694 val accuracy: 0.364000\n",
      "lr 4.600000e-06 reg 2.100000e+02 train accuracy: 0.393980 val accuracy: 0.395000\n",
      "lr 4.600000e-06 reg 3.100000e+02 train accuracy: 0.388531 val accuracy: 0.380000\n",
      "lr 4.600000e-06 reg 4.100000e+02 train accuracy: 0.372980 val accuracy: 0.365000\n",
      "lr 4.600000e-06 reg 5.100000e+02 train accuracy: 0.394367 val accuracy: 0.374000\n",
      "lr 4.600000e-06 reg 6.100000e+02 train accuracy: 0.388878 val accuracy: 0.385000\n",
      "lr 4.600000e-06 reg 7.100000e+02 train accuracy: 0.364490 val accuracy: 0.356000\n",
      "lr 4.600000e-06 reg 8.100000e+02 train accuracy: 0.392449 val accuracy: 0.387000\n",
      "lr 4.600000e-06 reg 9.100000e+02 train accuracy: 0.361796 val accuracy: 0.351000\n",
      "lr 4.600000e-06 reg 1.010000e+03 train accuracy: 0.362633 val accuracy: 0.366000\n",
      "lr 4.600000e-06 reg 1.110000e+03 train accuracy: 0.361776 val accuracy: 0.352000\n",
      "lr 4.600000e-06 reg 1.210000e+03 train accuracy: 0.385469 val accuracy: 0.395000\n",
      "lr 4.600000e-06 reg 1.310000e+03 train accuracy: 0.376816 val accuracy: 0.388000\n",
      "lr 4.600000e-06 reg 1.410000e+03 train accuracy: 0.377469 val accuracy: 0.376000\n",
      "lr 4.600000e-06 reg 1.510000e+03 train accuracy: 0.370265 val accuracy: 0.377000\n",
      "lr 4.600000e-06 reg 1.610000e+03 train accuracy: 0.357918 val accuracy: 0.358000\n",
      "lr 4.600000e-06 reg 1.710000e+03 train accuracy: 0.358000 val accuracy: 0.341000\n",
      "lr 4.600000e-06 reg 1.810000e+03 train accuracy: 0.353469 val accuracy: 0.344000\n",
      "lr 4.600000e-06 reg 1.910000e+03 train accuracy: 0.350000 val accuracy: 0.331000\n",
      "lr 4.600000e-06 reg 2.010000e+03 train accuracy: 0.339204 val accuracy: 0.335000\n",
      "lr 4.600000e-06 reg 2.110000e+03 train accuracy: 0.358612 val accuracy: 0.367000\n",
      "lr 4.600000e-06 reg 2.210000e+03 train accuracy: 0.339551 val accuracy: 0.337000\n",
      "lr 4.600000e-06 reg 2.310000e+03 train accuracy: 0.347653 val accuracy: 0.338000\n",
      "lr 4.600000e-06 reg 2.410000e+03 train accuracy: 0.355612 val accuracy: 0.343000\n",
      "lr 4.600000e-06 reg 2.510000e+03 train accuracy: 0.346959 val accuracy: 0.352000\n",
      "lr 4.600000e-06 reg 2.610000e+03 train accuracy: 0.370082 val accuracy: 0.347000\n",
      "lr 4.600000e-06 reg 2.710000e+03 train accuracy: 0.365184 val accuracy: 0.352000\n",
      "lr 4.600000e-06 reg 2.810000e+03 train accuracy: 0.332102 val accuracy: 0.349000\n",
      "lr 4.600000e-06 reg 2.910000e+03 train accuracy: 0.331327 val accuracy: 0.340000\n",
      "lr 4.600000e-06 reg 3.010000e+03 train accuracy: 0.340408 val accuracy: 0.344000\n",
      "lr 4.600000e-06 reg 3.110000e+03 train accuracy: 0.360898 val accuracy: 0.363000\n",
      "lr 4.600000e-06 reg 3.210000e+03 train accuracy: 0.361041 val accuracy: 0.385000\n",
      "lr 4.600000e-06 reg 3.310000e+03 train accuracy: 0.352388 val accuracy: 0.358000\n",
      "lr 4.600000e-06 reg 3.410000e+03 train accuracy: 0.345184 val accuracy: 0.358000\n",
      "lr 4.600000e-06 reg 3.510000e+03 train accuracy: 0.367102 val accuracy: 0.374000\n",
      "lr 4.600000e-06 reg 3.610000e+03 train accuracy: 0.334449 val accuracy: 0.320000\n",
      "lr 4.600000e-06 reg 3.710000e+03 train accuracy: 0.334796 val accuracy: 0.340000\n",
      "lr 4.600000e-06 reg 3.810000e+03 train accuracy: 0.332714 val accuracy: 0.348000\n",
      "lr 4.600000e-06 reg 3.910000e+03 train accuracy: 0.349000 val accuracy: 0.356000\n",
      "lr 4.600000e-06 reg 4.010000e+03 train accuracy: 0.338959 val accuracy: 0.337000\n",
      "lr 4.600000e-06 reg 4.110000e+03 train accuracy: 0.335755 val accuracy: 0.340000\n",
      "lr 4.600000e-06 reg 4.210000e+03 train accuracy: 0.302633 val accuracy: 0.308000\n",
      "lr 4.600000e-06 reg 4.310000e+03 train accuracy: 0.345286 val accuracy: 0.339000\n",
      "lr 4.600000e-06 reg 4.410000e+03 train accuracy: 0.340857 val accuracy: 0.362000\n",
      "lr 4.600000e-06 reg 4.510000e+03 train accuracy: 0.331163 val accuracy: 0.322000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 4.600000e-06 reg 4.610000e+03 train accuracy: 0.303673 val accuracy: 0.311000\n",
      "lr 4.600000e-06 reg 4.710000e+03 train accuracy: 0.343531 val accuracy: 0.346000\n",
      "lr 4.600000e-06 reg 4.810000e+03 train accuracy: 0.344796 val accuracy: 0.353000\n",
      "lr 4.600000e-06 reg 4.910000e+03 train accuracy: 0.309408 val accuracy: 0.321000\n",
      "lr 4.600000e-06 reg 5.010000e+03 train accuracy: 0.350776 val accuracy: 0.339000\n",
      "lr 4.600000e-06 reg 5.110000e+03 train accuracy: 0.340633 val accuracy: 0.372000\n",
      "lr 4.600000e-06 reg 5.210000e+03 train accuracy: 0.317796 val accuracy: 0.318000\n",
      "lr 4.600000e-06 reg 5.310000e+03 train accuracy: 0.344694 val accuracy: 0.351000\n",
      "lr 4.600000e-06 reg 5.410000e+03 train accuracy: 0.320857 val accuracy: 0.334000\n",
      "lr 4.600000e-06 reg 5.510000e+03 train accuracy: 0.311571 val accuracy: 0.309000\n",
      "lr 4.600000e-06 reg 5.610000e+03 train accuracy: 0.322204 val accuracy: 0.326000\n",
      "lr 4.600000e-06 reg 5.710000e+03 train accuracy: 0.316490 val accuracy: 0.330000\n",
      "lr 4.600000e-06 reg 5.810000e+03 train accuracy: 0.335327 val accuracy: 0.343000\n",
      "lr 4.600000e-06 reg 5.910000e+03 train accuracy: 0.338816 val accuracy: 0.358000\n",
      "lr 4.600000e-06 reg 6.010000e+03 train accuracy: 0.325082 val accuracy: 0.332000\n",
      "lr 4.600000e-06 reg 6.110000e+03 train accuracy: 0.333020 val accuracy: 0.352000\n",
      "lr 4.600000e-06 reg 6.210000e+03 train accuracy: 0.315837 val accuracy: 0.324000\n",
      "lr 4.600000e-06 reg 6.310000e+03 train accuracy: 0.317000 val accuracy: 0.335000\n",
      "lr 4.600000e-06 reg 6.410000e+03 train accuracy: 0.301939 val accuracy: 0.320000\n",
      "lr 4.600000e-06 reg 6.510000e+03 train accuracy: 0.310571 val accuracy: 0.320000\n",
      "lr 4.600000e-06 reg 6.610000e+03 train accuracy: 0.335776 val accuracy: 0.330000\n",
      "lr 4.600000e-06 reg 6.710000e+03 train accuracy: 0.303061 val accuracy: 0.328000\n",
      "lr 4.600000e-06 reg 6.810000e+03 train accuracy: 0.341959 val accuracy: 0.351000\n",
      "lr 4.600000e-06 reg 6.910000e+03 train accuracy: 0.341980 val accuracy: 0.360000\n",
      "lr 4.600000e-06 reg 7.010000e+03 train accuracy: 0.312204 val accuracy: 0.336000\n",
      "lr 4.600000e-06 reg 7.110000e+03 train accuracy: 0.322918 val accuracy: 0.320000\n",
      "lr 4.600000e-06 reg 7.210000e+03 train accuracy: 0.325490 val accuracy: 0.307000\n",
      "lr 4.600000e-06 reg 7.310000e+03 train accuracy: 0.337776 val accuracy: 0.360000\n",
      "lr 4.600000e-06 reg 7.410000e+03 train accuracy: 0.306571 val accuracy: 0.322000\n",
      "lr 4.600000e-06 reg 7.510000e+03 train accuracy: 0.319959 val accuracy: 0.337000\n",
      "lr 4.600000e-06 reg 7.610000e+03 train accuracy: 0.340531 val accuracy: 0.344000\n",
      "lr 4.600000e-06 reg 7.710000e+03 train accuracy: 0.313490 val accuracy: 0.326000\n",
      "lr 4.600000e-06 reg 7.810000e+03 train accuracy: 0.332776 val accuracy: 0.339000\n",
      "lr 4.600000e-06 reg 7.910000e+03 train accuracy: 0.326122 val accuracy: 0.337000\n",
      "lr 4.600000e-06 reg 8.010000e+03 train accuracy: 0.307980 val accuracy: 0.317000\n",
      "lr 4.600000e-06 reg 8.110000e+03 train accuracy: 0.304653 val accuracy: 0.309000\n",
      "lr 4.600000e-06 reg 8.210000e+03 train accuracy: 0.302816 val accuracy: 0.317000\n",
      "lr 4.600000e-06 reg 8.310000e+03 train accuracy: 0.342551 val accuracy: 0.370000\n",
      "lr 4.600000e-06 reg 8.410000e+03 train accuracy: 0.305041 val accuracy: 0.296000\n",
      "lr 4.600000e-06 reg 8.510000e+03 train accuracy: 0.317673 val accuracy: 0.309000\n",
      "lr 4.600000e-06 reg 8.610000e+03 train accuracy: 0.334102 val accuracy: 0.341000\n",
      "lr 4.600000e-06 reg 8.710000e+03 train accuracy: 0.313510 val accuracy: 0.324000\n",
      "lr 4.600000e-06 reg 8.810000e+03 train accuracy: 0.330980 val accuracy: 0.342000\n",
      "lr 4.600000e-06 reg 8.910000e+03 train accuracy: 0.322245 val accuracy: 0.297000\n",
      "lr 4.600000e-06 reg 9.010000e+03 train accuracy: 0.310408 val accuracy: 0.328000\n",
      "lr 4.600000e-06 reg 9.110000e+03 train accuracy: 0.335980 val accuracy: 0.349000\n",
      "lr 4.600000e-06 reg 9.210000e+03 train accuracy: 0.326061 val accuracy: 0.333000\n",
      "lr 4.600000e-06 reg 9.310000e+03 train accuracy: 0.296837 val accuracy: 0.300000\n",
      "lr 4.600000e-06 reg 9.410000e+03 train accuracy: 0.274245 val accuracy: 0.287000\n",
      "lr 4.600000e-06 reg 9.510000e+03 train accuracy: 0.300327 val accuracy: 0.301000\n",
      "lr 4.600000e-06 reg 9.610000e+03 train accuracy: 0.312000 val accuracy: 0.307000\n",
      "lr 4.600000e-06 reg 9.710000e+03 train accuracy: 0.321224 val accuracy: 0.330000\n",
      "lr 4.600000e-06 reg 9.810000e+03 train accuracy: 0.321531 val accuracy: 0.319000\n",
      "lr 4.600000e-06 reg 9.910000e+03 train accuracy: 0.275531 val accuracy: 0.294000\n",
      "lr 5.100000e-06 reg 1.000000e+01 train accuracy: 0.366633 val accuracy: 0.334000\n",
      "lr 5.100000e-06 reg 1.100000e+02 train accuracy: 0.388306 val accuracy: 0.382000\n",
      "lr 5.100000e-06 reg 2.100000e+02 train accuracy: 0.383204 val accuracy: 0.390000\n",
      "lr 5.100000e-06 reg 3.100000e+02 train accuracy: 0.383020 val accuracy: 0.367000\n",
      "lr 5.100000e-06 reg 4.100000e+02 train accuracy: 0.395980 val accuracy: 0.391000\n",
      "lr 5.100000e-06 reg 5.100000e+02 train accuracy: 0.386061 val accuracy: 0.385000\n",
      "lr 5.100000e-06 reg 6.100000e+02 train accuracy: 0.372082 val accuracy: 0.376000\n",
      "lr 5.100000e-06 reg 7.100000e+02 train accuracy: 0.367388 val accuracy: 0.369000\n",
      "lr 5.100000e-06 reg 8.100000e+02 train accuracy: 0.354367 val accuracy: 0.355000\n",
      "lr 5.100000e-06 reg 9.100000e+02 train accuracy: 0.363388 val accuracy: 0.348000\n",
      "lr 5.100000e-06 reg 1.010000e+03 train accuracy: 0.357490 val accuracy: 0.369000\n",
      "lr 5.100000e-06 reg 1.110000e+03 train accuracy: 0.359245 val accuracy: 0.358000\n",
      "lr 5.100000e-06 reg 1.210000e+03 train accuracy: 0.359388 val accuracy: 0.347000\n",
      "lr 5.100000e-06 reg 1.310000e+03 train accuracy: 0.358020 val accuracy: 0.345000\n",
      "lr 5.100000e-06 reg 1.410000e+03 train accuracy: 0.351816 val accuracy: 0.353000\n",
      "lr 5.100000e-06 reg 1.510000e+03 train accuracy: 0.352122 val accuracy: 0.339000\n",
      "lr 5.100000e-06 reg 1.610000e+03 train accuracy: 0.359224 val accuracy: 0.361000\n",
      "lr 5.100000e-06 reg 1.710000e+03 train accuracy: 0.345735 val accuracy: 0.340000\n",
      "lr 5.100000e-06 reg 1.810000e+03 train accuracy: 0.364531 val accuracy: 0.375000\n",
      "lr 5.100000e-06 reg 1.910000e+03 train accuracy: 0.367490 val accuracy: 0.367000\n",
      "lr 5.100000e-06 reg 2.010000e+03 train accuracy: 0.343102 val accuracy: 0.346000\n",
      "lr 5.100000e-06 reg 2.110000e+03 train accuracy: 0.343224 val accuracy: 0.345000\n",
      "lr 5.100000e-06 reg 2.210000e+03 train accuracy: 0.330327 val accuracy: 0.320000\n",
      "lr 5.100000e-06 reg 2.310000e+03 train accuracy: 0.309469 val accuracy: 0.298000\n",
      "lr 5.100000e-06 reg 2.410000e+03 train accuracy: 0.356265 val accuracy: 0.377000\n",
      "lr 5.100000e-06 reg 2.510000e+03 train accuracy: 0.352000 val accuracy: 0.377000\n",
      "lr 5.100000e-06 reg 2.610000e+03 train accuracy: 0.349959 val accuracy: 0.346000\n",
      "lr 5.100000e-06 reg 2.710000e+03 train accuracy: 0.335122 val accuracy: 0.344000\n",
      "lr 5.100000e-06 reg 2.810000e+03 train accuracy: 0.311184 val accuracy: 0.322000\n",
      "lr 5.100000e-06 reg 2.910000e+03 train accuracy: 0.340531 val accuracy: 0.322000\n",
      "lr 5.100000e-06 reg 3.010000e+03 train accuracy: 0.362918 val accuracy: 0.366000\n",
      "lr 5.100000e-06 reg 3.110000e+03 train accuracy: 0.329224 val accuracy: 0.313000\n",
      "lr 5.100000e-06 reg 3.210000e+03 train accuracy: 0.350143 val accuracy: 0.362000\n",
      "lr 5.100000e-06 reg 3.310000e+03 train accuracy: 0.341612 val accuracy: 0.338000\n",
      "lr 5.100000e-06 reg 3.410000e+03 train accuracy: 0.323245 val accuracy: 0.344000\n",
      "lr 5.100000e-06 reg 3.510000e+03 train accuracy: 0.328898 val accuracy: 0.313000\n",
      "lr 5.100000e-06 reg 3.610000e+03 train accuracy: 0.342531 val accuracy: 0.345000\n",
      "lr 5.100000e-06 reg 3.710000e+03 train accuracy: 0.349673 val accuracy: 0.354000\n",
      "lr 5.100000e-06 reg 3.810000e+03 train accuracy: 0.356102 val accuracy: 0.374000\n",
      "lr 5.100000e-06 reg 3.910000e+03 train accuracy: 0.358633 val accuracy: 0.371000\n",
      "lr 5.100000e-06 reg 4.010000e+03 train accuracy: 0.287531 val accuracy: 0.306000\n",
      "lr 5.100000e-06 reg 4.110000e+03 train accuracy: 0.310306 val accuracy: 0.311000\n",
      "lr 5.100000e-06 reg 4.210000e+03 train accuracy: 0.274490 val accuracy: 0.273000\n",
      "lr 5.100000e-06 reg 4.310000e+03 train accuracy: 0.313714 val accuracy: 0.317000\n",
      "lr 5.100000e-06 reg 4.410000e+03 train accuracy: 0.346490 val accuracy: 0.345000\n",
      "lr 5.100000e-06 reg 4.510000e+03 train accuracy: 0.305735 val accuracy: 0.318000\n",
      "lr 5.100000e-06 reg 4.610000e+03 train accuracy: 0.333163 val accuracy: 0.333000\n",
      "lr 5.100000e-06 reg 4.710000e+03 train accuracy: 0.330510 val accuracy: 0.324000\n",
      "lr 5.100000e-06 reg 4.810000e+03 train accuracy: 0.331796 val accuracy: 0.363000\n",
      "lr 5.100000e-06 reg 4.910000e+03 train accuracy: 0.310204 val accuracy: 0.336000\n",
      "lr 5.100000e-06 reg 5.010000e+03 train accuracy: 0.297939 val accuracy: 0.287000\n",
      "lr 5.100000e-06 reg 5.110000e+03 train accuracy: 0.293980 val accuracy: 0.304000\n",
      "lr 5.100000e-06 reg 5.210000e+03 train accuracy: 0.335551 val accuracy: 0.322000\n",
      "lr 5.100000e-06 reg 5.310000e+03 train accuracy: 0.325429 val accuracy: 0.331000\n",
      "lr 5.100000e-06 reg 5.410000e+03 train accuracy: 0.333224 val accuracy: 0.341000\n",
      "lr 5.100000e-06 reg 5.510000e+03 train accuracy: 0.320531 val accuracy: 0.313000\n",
      "lr 5.100000e-06 reg 5.610000e+03 train accuracy: 0.356694 val accuracy: 0.373000\n",
      "lr 5.100000e-06 reg 5.710000e+03 train accuracy: 0.306020 val accuracy: 0.288000\n",
      "lr 5.100000e-06 reg 5.810000e+03 train accuracy: 0.315041 val accuracy: 0.318000\n",
      "lr 5.100000e-06 reg 5.910000e+03 train accuracy: 0.323020 val accuracy: 0.325000\n",
      "lr 5.100000e-06 reg 6.010000e+03 train accuracy: 0.333776 val accuracy: 0.349000\n",
      "lr 5.100000e-06 reg 6.110000e+03 train accuracy: 0.321122 val accuracy: 0.318000\n",
      "lr 5.100000e-06 reg 6.210000e+03 train accuracy: 0.295388 val accuracy: 0.290000\n",
      "lr 5.100000e-06 reg 6.310000e+03 train accuracy: 0.324531 val accuracy: 0.325000\n",
      "lr 5.100000e-06 reg 6.410000e+03 train accuracy: 0.236816 val accuracy: 0.252000\n",
      "lr 5.100000e-06 reg 6.510000e+03 train accuracy: 0.274816 val accuracy: 0.279000\n",
      "lr 5.100000e-06 reg 6.610000e+03 train accuracy: 0.303306 val accuracy: 0.316000\n",
      "lr 5.100000e-06 reg 6.710000e+03 train accuracy: 0.311327 val accuracy: 0.332000\n",
      "lr 5.100000e-06 reg 6.810000e+03 train accuracy: 0.298122 val accuracy: 0.313000\n",
      "lr 5.100000e-06 reg 6.910000e+03 train accuracy: 0.319143 val accuracy: 0.314000\n",
      "lr 5.100000e-06 reg 7.010000e+03 train accuracy: 0.290204 val accuracy: 0.312000\n",
      "lr 5.100000e-06 reg 7.110000e+03 train accuracy: 0.289347 val accuracy: 0.288000\n",
      "lr 5.100000e-06 reg 7.210000e+03 train accuracy: 0.291061 val accuracy: 0.302000\n",
      "lr 5.100000e-06 reg 7.310000e+03 train accuracy: 0.272041 val accuracy: 0.276000\n",
      "lr 5.100000e-06 reg 7.410000e+03 train accuracy: 0.299429 val accuracy: 0.307000\n",
      "lr 5.100000e-06 reg 7.510000e+03 train accuracy: 0.319510 val accuracy: 0.320000\n",
      "lr 5.100000e-06 reg 7.610000e+03 train accuracy: 0.318020 val accuracy: 0.329000\n",
      "lr 5.100000e-06 reg 7.710000e+03 train accuracy: 0.232061 val accuracy: 0.246000\n",
      "lr 5.100000e-06 reg 7.810000e+03 train accuracy: 0.327122 val accuracy: 0.328000\n",
      "lr 5.100000e-06 reg 7.910000e+03 train accuracy: 0.303367 val accuracy: 0.318000\n",
      "lr 5.100000e-06 reg 8.010000e+03 train accuracy: 0.298367 val accuracy: 0.318000\n",
      "lr 5.100000e-06 reg 8.110000e+03 train accuracy: 0.328020 val accuracy: 0.318000\n",
      "lr 5.100000e-06 reg 8.210000e+03 train accuracy: 0.264286 val accuracy: 0.288000\n",
      "lr 5.100000e-06 reg 8.310000e+03 train accuracy: 0.310122 val accuracy: 0.302000\n",
      "lr 5.100000e-06 reg 8.410000e+03 train accuracy: 0.310959 val accuracy: 0.317000\n",
      "lr 5.100000e-06 reg 8.510000e+03 train accuracy: 0.273776 val accuracy: 0.271000\n",
      "lr 5.100000e-06 reg 8.610000e+03 train accuracy: 0.313449 val accuracy: 0.315000\n",
      "lr 5.100000e-06 reg 8.710000e+03 train accuracy: 0.308143 val accuracy: 0.324000\n",
      "lr 5.100000e-06 reg 8.810000e+03 train accuracy: 0.312735 val accuracy: 0.312000\n",
      "lr 5.100000e-06 reg 8.910000e+03 train accuracy: 0.300102 val accuracy: 0.290000\n",
      "lr 5.100000e-06 reg 9.010000e+03 train accuracy: 0.334204 val accuracy: 0.340000\n",
      "lr 5.100000e-06 reg 9.110000e+03 train accuracy: 0.316224 val accuracy: 0.328000\n",
      "lr 5.100000e-06 reg 9.210000e+03 train accuracy: 0.300102 val accuracy: 0.312000\n",
      "lr 5.100000e-06 reg 9.310000e+03 train accuracy: 0.290816 val accuracy: 0.304000\n",
      "lr 5.100000e-06 reg 9.410000e+03 train accuracy: 0.299490 val accuracy: 0.320000\n",
      "lr 5.100000e-06 reg 9.510000e+03 train accuracy: 0.291857 val accuracy: 0.291000\n",
      "lr 5.100000e-06 reg 9.610000e+03 train accuracy: 0.257449 val accuracy: 0.274000\n",
      "lr 5.100000e-06 reg 9.710000e+03 train accuracy: 0.297327 val accuracy: 0.314000\n",
      "lr 5.100000e-06 reg 9.810000e+03 train accuracy: 0.305469 val accuracy: 0.311000\n",
      "lr 5.100000e-06 reg 9.910000e+03 train accuracy: 0.287102 val accuracy: 0.293000\n",
      "lr 5.600000e-06 reg 1.000000e+01 train accuracy: 0.367939 val accuracy: 0.359000\n",
      "lr 5.600000e-06 reg 1.100000e+02 train accuracy: 0.370612 val accuracy: 0.371000\n",
      "lr 5.600000e-06 reg 2.100000e+02 train accuracy: 0.395755 val accuracy: 0.375000\n",
      "lr 5.600000e-06 reg 3.100000e+02 train accuracy: 0.374816 val accuracy: 0.366000\n",
      "lr 5.600000e-06 reg 4.100000e+02 train accuracy: 0.390694 val accuracy: 0.378000\n",
      "lr 5.600000e-06 reg 5.100000e+02 train accuracy: 0.363776 val accuracy: 0.343000\n",
      "lr 5.600000e-06 reg 6.100000e+02 train accuracy: 0.383245 val accuracy: 0.380000\n",
      "lr 5.600000e-06 reg 7.100000e+02 train accuracy: 0.372020 val accuracy: 0.370000\n",
      "lr 5.600000e-06 reg 8.100000e+02 train accuracy: 0.358612 val accuracy: 0.353000\n",
      "lr 5.600000e-06 reg 9.100000e+02 train accuracy: 0.341857 val accuracy: 0.346000\n",
      "lr 5.600000e-06 reg 1.010000e+03 train accuracy: 0.356735 val accuracy: 0.352000\n",
      "lr 5.600000e-06 reg 1.110000e+03 train accuracy: 0.343122 val accuracy: 0.336000\n",
      "lr 5.600000e-06 reg 1.210000e+03 train accuracy: 0.357755 val accuracy: 0.367000\n",
      "lr 5.600000e-06 reg 1.310000e+03 train accuracy: 0.368980 val accuracy: 0.343000\n",
      "lr 5.600000e-06 reg 1.410000e+03 train accuracy: 0.338061 val accuracy: 0.351000\n",
      "lr 5.600000e-06 reg 1.510000e+03 train accuracy: 0.324816 val accuracy: 0.339000\n",
      "lr 5.600000e-06 reg 1.610000e+03 train accuracy: 0.324939 val accuracy: 0.318000\n",
      "lr 5.600000e-06 reg 1.710000e+03 train accuracy: 0.331837 val accuracy: 0.323000\n",
      "lr 5.600000e-06 reg 1.810000e+03 train accuracy: 0.362000 val accuracy: 0.359000\n",
      "lr 5.600000e-06 reg 1.910000e+03 train accuracy: 0.350612 val accuracy: 0.364000\n",
      "lr 5.600000e-06 reg 2.010000e+03 train accuracy: 0.354306 val accuracy: 0.363000\n",
      "lr 5.600000e-06 reg 2.110000e+03 train accuracy: 0.303714 val accuracy: 0.317000\n",
      "lr 5.600000e-06 reg 2.210000e+03 train accuracy: 0.329776 val accuracy: 0.328000\n",
      "lr 5.600000e-06 reg 2.310000e+03 train accuracy: 0.317796 val accuracy: 0.308000\n",
      "lr 5.600000e-06 reg 2.410000e+03 train accuracy: 0.324490 val accuracy: 0.310000\n",
      "lr 5.600000e-06 reg 2.510000e+03 train accuracy: 0.296898 val accuracy: 0.304000\n",
      "lr 5.600000e-06 reg 2.610000e+03 train accuracy: 0.334490 val accuracy: 0.349000\n",
      "lr 5.600000e-06 reg 2.710000e+03 train accuracy: 0.320020 val accuracy: 0.333000\n",
      "lr 5.600000e-06 reg 2.810000e+03 train accuracy: 0.311286 val accuracy: 0.330000\n",
      "lr 5.600000e-06 reg 2.910000e+03 train accuracy: 0.353653 val accuracy: 0.353000\n",
      "lr 5.600000e-06 reg 3.010000e+03 train accuracy: 0.308714 val accuracy: 0.318000\n",
      "lr 5.600000e-06 reg 3.110000e+03 train accuracy: 0.339061 val accuracy: 0.355000\n",
      "lr 5.600000e-06 reg 3.210000e+03 train accuracy: 0.338286 val accuracy: 0.339000\n",
      "lr 5.600000e-06 reg 3.310000e+03 train accuracy: 0.278633 val accuracy: 0.261000\n",
      "lr 5.600000e-06 reg 3.410000e+03 train accuracy: 0.298673 val accuracy: 0.280000\n",
      "lr 5.600000e-06 reg 3.510000e+03 train accuracy: 0.340857 val accuracy: 0.334000\n",
      "lr 5.600000e-06 reg 3.610000e+03 train accuracy: 0.347245 val accuracy: 0.358000\n",
      "lr 5.600000e-06 reg 3.710000e+03 train accuracy: 0.341939 val accuracy: 0.353000\n",
      "lr 5.600000e-06 reg 3.810000e+03 train accuracy: 0.263837 val accuracy: 0.277000\n",
      "lr 5.600000e-06 reg 3.910000e+03 train accuracy: 0.330367 val accuracy: 0.345000\n",
      "lr 5.600000e-06 reg 4.010000e+03 train accuracy: 0.297408 val accuracy: 0.306000\n",
      "lr 5.600000e-06 reg 4.110000e+03 train accuracy: 0.298531 val accuracy: 0.311000\n",
      "lr 5.600000e-06 reg 4.210000e+03 train accuracy: 0.325857 val accuracy: 0.338000\n",
      "lr 5.600000e-06 reg 4.310000e+03 train accuracy: 0.321612 val accuracy: 0.316000\n",
      "lr 5.600000e-06 reg 4.410000e+03 train accuracy: 0.299408 val accuracy: 0.301000\n",
      "lr 5.600000e-06 reg 4.510000e+03 train accuracy: 0.296898 val accuracy: 0.308000\n",
      "lr 5.600000e-06 reg 4.610000e+03 train accuracy: 0.329510 val accuracy: 0.354000\n",
      "lr 5.600000e-06 reg 4.710000e+03 train accuracy: 0.292327 val accuracy: 0.288000\n",
      "lr 5.600000e-06 reg 4.810000e+03 train accuracy: 0.333633 val accuracy: 0.335000\n",
      "lr 5.600000e-06 reg 4.910000e+03 train accuracy: 0.309000 val accuracy: 0.333000\n",
      "lr 5.600000e-06 reg 5.010000e+03 train accuracy: 0.295878 val accuracy: 0.312000\n",
      "lr 5.600000e-06 reg 5.110000e+03 train accuracy: 0.292163 val accuracy: 0.289000\n",
      "lr 5.600000e-06 reg 5.210000e+03 train accuracy: 0.320735 val accuracy: 0.328000\n",
      "lr 5.600000e-06 reg 5.310000e+03 train accuracy: 0.296469 val accuracy: 0.294000\n",
      "lr 5.600000e-06 reg 5.410000e+03 train accuracy: 0.335102 val accuracy: 0.332000\n",
      "lr 5.600000e-06 reg 5.510000e+03 train accuracy: 0.292633 val accuracy: 0.322000\n",
      "lr 5.600000e-06 reg 5.610000e+03 train accuracy: 0.330429 val accuracy: 0.337000\n",
      "lr 5.600000e-06 reg 5.710000e+03 train accuracy: 0.297531 val accuracy: 0.317000\n",
      "lr 5.600000e-06 reg 5.810000e+03 train accuracy: 0.341592 val accuracy: 0.347000\n",
      "lr 5.600000e-06 reg 5.910000e+03 train accuracy: 0.319306 val accuracy: 0.316000\n",
      "lr 5.600000e-06 reg 6.010000e+03 train accuracy: 0.290061 val accuracy: 0.287000\n",
      "lr 5.600000e-06 reg 6.110000e+03 train accuracy: 0.331551 val accuracy: 0.339000\n",
      "lr 5.600000e-06 reg 6.210000e+03 train accuracy: 0.310204 val accuracy: 0.303000\n",
      "lr 5.600000e-06 reg 6.310000e+03 train accuracy: 0.329265 val accuracy: 0.321000\n",
      "lr 5.600000e-06 reg 6.410000e+03 train accuracy: 0.302286 val accuracy: 0.310000\n",
      "lr 5.600000e-06 reg 6.510000e+03 train accuracy: 0.292980 val accuracy: 0.299000\n",
      "lr 5.600000e-06 reg 6.610000e+03 train accuracy: 0.265816 val accuracy: 0.314000\n",
      "lr 5.600000e-06 reg 6.710000e+03 train accuracy: 0.323286 val accuracy: 0.326000\n",
      "lr 5.600000e-06 reg 6.810000e+03 train accuracy: 0.295633 val accuracy: 0.286000\n",
      "lr 5.600000e-06 reg 6.910000e+03 train accuracy: 0.291714 val accuracy: 0.325000\n",
      "lr 5.600000e-06 reg 7.010000e+03 train accuracy: 0.278061 val accuracy: 0.300000\n",
      "lr 5.600000e-06 reg 7.110000e+03 train accuracy: 0.257347 val accuracy: 0.265000\n",
      "lr 5.600000e-06 reg 7.210000e+03 train accuracy: 0.324327 val accuracy: 0.336000\n",
      "lr 5.600000e-06 reg 7.310000e+03 train accuracy: 0.288653 val accuracy: 0.308000\n",
      "lr 5.600000e-06 reg 7.410000e+03 train accuracy: 0.273347 val accuracy: 0.273000\n",
      "lr 5.600000e-06 reg 7.510000e+03 train accuracy: 0.296673 val accuracy: 0.300000\n",
      "lr 5.600000e-06 reg 7.610000e+03 train accuracy: 0.274061 val accuracy: 0.273000\n",
      "lr 5.600000e-06 reg 7.710000e+03 train accuracy: 0.290469 val accuracy: 0.297000\n",
      "lr 5.600000e-06 reg 7.810000e+03 train accuracy: 0.278469 val accuracy: 0.285000\n",
      "lr 5.600000e-06 reg 7.910000e+03 train accuracy: 0.297347 val accuracy: 0.322000\n",
      "lr 5.600000e-06 reg 8.010000e+03 train accuracy: 0.339735 val accuracy: 0.358000\n",
      "lr 5.600000e-06 reg 8.110000e+03 train accuracy: 0.285857 val accuracy: 0.301000\n",
      "lr 5.600000e-06 reg 8.210000e+03 train accuracy: 0.298898 val accuracy: 0.298000\n",
      "lr 5.600000e-06 reg 8.310000e+03 train accuracy: 0.272367 val accuracy: 0.290000\n",
      "lr 5.600000e-06 reg 8.410000e+03 train accuracy: 0.313735 val accuracy: 0.326000\n",
      "lr 5.600000e-06 reg 8.510000e+03 train accuracy: 0.244204 val accuracy: 0.256000\n",
      "lr 5.600000e-06 reg 8.610000e+03 train accuracy: 0.299469 val accuracy: 0.294000\n",
      "lr 5.600000e-06 reg 8.710000e+03 train accuracy: 0.262939 val accuracy: 0.270000\n",
      "lr 5.600000e-06 reg 8.810000e+03 train accuracy: 0.224020 val accuracy: 0.234000\n",
      "lr 5.600000e-06 reg 8.910000e+03 train accuracy: 0.240367 val accuracy: 0.265000\n",
      "lr 5.600000e-06 reg 9.010000e+03 train accuracy: 0.291306 val accuracy: 0.291000\n",
      "lr 5.600000e-06 reg 9.110000e+03 train accuracy: 0.306347 val accuracy: 0.318000\n",
      "lr 5.600000e-06 reg 9.210000e+03 train accuracy: 0.303306 val accuracy: 0.339000\n",
      "lr 5.600000e-06 reg 9.310000e+03 train accuracy: 0.304041 val accuracy: 0.321000\n",
      "lr 5.600000e-06 reg 9.410000e+03 train accuracy: 0.287429 val accuracy: 0.286000\n",
      "lr 5.600000e-06 reg 9.510000e+03 train accuracy: 0.256184 val accuracy: 0.269000\n",
      "lr 5.600000e-06 reg 9.610000e+03 train accuracy: 0.258347 val accuracy: 0.262000\n",
      "lr 5.600000e-06 reg 9.710000e+03 train accuracy: 0.290857 val accuracy: 0.302000\n",
      "lr 5.600000e-06 reg 9.810000e+03 train accuracy: 0.289367 val accuracy: 0.287000\n",
      "lr 5.600000e-06 reg 9.910000e+03 train accuracy: 0.297939 val accuracy: 0.322000\n",
      "lr 6.100000e-06 reg 1.000000e+01 train accuracy: 0.358265 val accuracy: 0.364000\n",
      "lr 6.100000e-06 reg 1.100000e+02 train accuracy: 0.377020 val accuracy: 0.358000\n",
      "lr 6.100000e-06 reg 2.100000e+02 train accuracy: 0.369122 val accuracy: 0.352000\n",
      "lr 6.100000e-06 reg 3.100000e+02 train accuracy: 0.381408 val accuracy: 0.354000\n",
      "lr 6.100000e-06 reg 4.100000e+02 train accuracy: 0.348408 val accuracy: 0.372000\n",
      "lr 6.100000e-06 reg 5.100000e+02 train accuracy: 0.339796 val accuracy: 0.338000\n",
      "lr 6.100000e-06 reg 6.100000e+02 train accuracy: 0.365245 val accuracy: 0.363000\n",
      "lr 6.100000e-06 reg 7.100000e+02 train accuracy: 0.376306 val accuracy: 0.367000\n",
      "lr 6.100000e-06 reg 8.100000e+02 train accuracy: 0.325735 val accuracy: 0.329000\n",
      "lr 6.100000e-06 reg 9.100000e+02 train accuracy: 0.351020 val accuracy: 0.333000\n",
      "lr 6.100000e-06 reg 1.010000e+03 train accuracy: 0.321816 val accuracy: 0.334000\n",
      "lr 6.100000e-06 reg 1.110000e+03 train accuracy: 0.333082 val accuracy: 0.318000\n",
      "lr 6.100000e-06 reg 1.210000e+03 train accuracy: 0.331224 val accuracy: 0.334000\n",
      "lr 6.100000e-06 reg 1.310000e+03 train accuracy: 0.357898 val accuracy: 0.351000\n",
      "lr 6.100000e-06 reg 1.410000e+03 train accuracy: 0.309082 val accuracy: 0.311000\n",
      "lr 6.100000e-06 reg 1.510000e+03 train accuracy: 0.331551 val accuracy: 0.329000\n",
      "lr 6.100000e-06 reg 1.610000e+03 train accuracy: 0.337837 val accuracy: 0.328000\n",
      "lr 6.100000e-06 reg 1.710000e+03 train accuracy: 0.329041 val accuracy: 0.330000\n",
      "lr 6.100000e-06 reg 1.810000e+03 train accuracy: 0.323857 val accuracy: 0.329000\n",
      "lr 6.100000e-06 reg 1.910000e+03 train accuracy: 0.341204 val accuracy: 0.346000\n",
      "lr 6.100000e-06 reg 2.010000e+03 train accuracy: 0.334245 val accuracy: 0.336000\n",
      "lr 6.100000e-06 reg 2.110000e+03 train accuracy: 0.327878 val accuracy: 0.321000\n",
      "lr 6.100000e-06 reg 2.210000e+03 train accuracy: 0.310959 val accuracy: 0.314000\n",
      "lr 6.100000e-06 reg 2.310000e+03 train accuracy: 0.316510 val accuracy: 0.332000\n",
      "lr 6.100000e-06 reg 2.410000e+03 train accuracy: 0.315020 val accuracy: 0.332000\n",
      "lr 6.100000e-06 reg 2.510000e+03 train accuracy: 0.303816 val accuracy: 0.316000\n",
      "lr 6.100000e-06 reg 2.610000e+03 train accuracy: 0.323959 val accuracy: 0.297000\n",
      "lr 6.100000e-06 reg 2.710000e+03 train accuracy: 0.328020 val accuracy: 0.318000\n",
      "lr 6.100000e-06 reg 2.810000e+03 train accuracy: 0.305184 val accuracy: 0.296000\n",
      "lr 6.100000e-06 reg 2.910000e+03 train accuracy: 0.247673 val accuracy: 0.265000\n",
      "lr 6.100000e-06 reg 3.010000e+03 train accuracy: 0.333469 val accuracy: 0.338000\n",
      "lr 6.100000e-06 reg 3.110000e+03 train accuracy: 0.307796 val accuracy: 0.313000\n",
      "lr 6.100000e-06 reg 3.210000e+03 train accuracy: 0.347163 val accuracy: 0.355000\n",
      "lr 6.100000e-06 reg 3.310000e+03 train accuracy: 0.319694 val accuracy: 0.327000\n",
      "lr 6.100000e-06 reg 3.410000e+03 train accuracy: 0.301286 val accuracy: 0.292000\n",
      "lr 6.100000e-06 reg 3.510000e+03 train accuracy: 0.302204 val accuracy: 0.294000\n",
      "lr 6.100000e-06 reg 3.610000e+03 train accuracy: 0.319755 val accuracy: 0.311000\n",
      "lr 6.100000e-06 reg 3.710000e+03 train accuracy: 0.299041 val accuracy: 0.324000\n",
      "lr 6.100000e-06 reg 3.810000e+03 train accuracy: 0.267000 val accuracy: 0.260000\n",
      "lr 6.100000e-06 reg 3.910000e+03 train accuracy: 0.300878 val accuracy: 0.324000\n",
      "lr 6.100000e-06 reg 4.010000e+03 train accuracy: 0.302020 val accuracy: 0.299000\n",
      "lr 6.100000e-06 reg 4.110000e+03 train accuracy: 0.300041 val accuracy: 0.326000\n",
      "lr 6.100000e-06 reg 4.210000e+03 train accuracy: 0.304776 val accuracy: 0.323000\n",
      "lr 6.100000e-06 reg 4.310000e+03 train accuracy: 0.294796 val accuracy: 0.278000\n",
      "lr 6.100000e-06 reg 4.410000e+03 train accuracy: 0.298265 val accuracy: 0.302000\n",
      "lr 6.100000e-06 reg 4.510000e+03 train accuracy: 0.271837 val accuracy: 0.291000\n",
      "lr 6.100000e-06 reg 4.610000e+03 train accuracy: 0.297755 val accuracy: 0.319000\n",
      "lr 6.100000e-06 reg 4.710000e+03 train accuracy: 0.273245 val accuracy: 0.292000\n",
      "lr 6.100000e-06 reg 4.810000e+03 train accuracy: 0.272776 val accuracy: 0.273000\n",
      "lr 6.100000e-06 reg 4.910000e+03 train accuracy: 0.300367 val accuracy: 0.299000\n",
      "lr 6.100000e-06 reg 5.010000e+03 train accuracy: 0.303939 val accuracy: 0.313000\n",
      "lr 6.100000e-06 reg 5.110000e+03 train accuracy: 0.249327 val accuracy: 0.259000\n",
      "lr 6.100000e-06 reg 5.210000e+03 train accuracy: 0.297020 val accuracy: 0.299000\n",
      "lr 6.100000e-06 reg 5.310000e+03 train accuracy: 0.264939 val accuracy: 0.265000\n",
      "lr 6.100000e-06 reg 5.410000e+03 train accuracy: 0.318347 val accuracy: 0.346000\n",
      "lr 6.100000e-06 reg 5.510000e+03 train accuracy: 0.281286 val accuracy: 0.273000\n",
      "lr 6.100000e-06 reg 5.610000e+03 train accuracy: 0.254939 val accuracy: 0.264000\n",
      "lr 6.100000e-06 reg 5.710000e+03 train accuracy: 0.273816 val accuracy: 0.291000\n",
      "lr 6.100000e-06 reg 5.810000e+03 train accuracy: 0.306122 val accuracy: 0.318000\n",
      "lr 6.100000e-06 reg 5.910000e+03 train accuracy: 0.273286 val accuracy: 0.291000\n",
      "lr 6.100000e-06 reg 6.010000e+03 train accuracy: 0.298000 val accuracy: 0.303000\n",
      "lr 6.100000e-06 reg 6.110000e+03 train accuracy: 0.287469 val accuracy: 0.287000\n",
      "lr 6.100000e-06 reg 6.210000e+03 train accuracy: 0.263633 val accuracy: 0.273000\n",
      "lr 6.100000e-06 reg 6.310000e+03 train accuracy: 0.272796 val accuracy: 0.267000\n",
      "lr 6.100000e-06 reg 6.410000e+03 train accuracy: 0.306327 val accuracy: 0.304000\n",
      "lr 6.100000e-06 reg 6.510000e+03 train accuracy: 0.284408 val accuracy: 0.285000\n",
      "lr 6.100000e-06 reg 6.610000e+03 train accuracy: 0.211408 val accuracy: 0.213000\n",
      "lr 6.100000e-06 reg 6.710000e+03 train accuracy: 0.299020 val accuracy: 0.301000\n",
      "lr 6.100000e-06 reg 6.810000e+03 train accuracy: 0.244408 val accuracy: 0.253000\n",
      "lr 6.100000e-06 reg 6.910000e+03 train accuracy: 0.268286 val accuracy: 0.270000\n",
      "lr 6.100000e-06 reg 7.010000e+03 train accuracy: 0.284184 val accuracy: 0.285000\n",
      "lr 6.100000e-06 reg 7.110000e+03 train accuracy: 0.309816 val accuracy: 0.299000\n",
      "lr 6.100000e-06 reg 7.210000e+03 train accuracy: 0.280184 val accuracy: 0.270000\n",
      "lr 6.100000e-06 reg 7.310000e+03 train accuracy: 0.228000 val accuracy: 0.253000\n",
      "lr 6.100000e-06 reg 7.410000e+03 train accuracy: 0.284531 val accuracy: 0.274000\n",
      "lr 6.100000e-06 reg 7.510000e+03 train accuracy: 0.280245 val accuracy: 0.288000\n",
      "lr 6.100000e-06 reg 7.610000e+03 train accuracy: 0.279041 val accuracy: 0.292000\n",
      "lr 6.100000e-06 reg 7.710000e+03 train accuracy: 0.295531 val accuracy: 0.299000\n",
      "lr 6.100000e-06 reg 7.810000e+03 train accuracy: 0.278939 val accuracy: 0.302000\n",
      "lr 6.100000e-06 reg 7.910000e+03 train accuracy: 0.256571 val accuracy: 0.256000\n",
      "lr 6.100000e-06 reg 8.010000e+03 train accuracy: 0.291388 val accuracy: 0.281000\n",
      "lr 6.100000e-06 reg 8.110000e+03 train accuracy: 0.286204 val accuracy: 0.313000\n",
      "lr 6.100000e-06 reg 8.210000e+03 train accuracy: 0.284694 val accuracy: 0.279000\n",
      "lr 6.100000e-06 reg 8.310000e+03 train accuracy: 0.275898 val accuracy: 0.292000\n",
      "lr 6.100000e-06 reg 8.410000e+03 train accuracy: 0.206592 val accuracy: 0.192000\n",
      "lr 6.100000e-06 reg 8.510000e+03 train accuracy: 0.256714 val accuracy: 0.286000\n",
      "lr 6.100000e-06 reg 8.610000e+03 train accuracy: 0.244857 val accuracy: 0.266000\n",
      "lr 6.100000e-06 reg 8.710000e+03 train accuracy: 0.280286 val accuracy: 0.287000\n",
      "lr 6.100000e-06 reg 8.810000e+03 train accuracy: 0.290102 val accuracy: 0.311000\n",
      "lr 6.100000e-06 reg 8.910000e+03 train accuracy: 0.286959 val accuracy: 0.290000\n",
      "lr 6.100000e-06 reg 9.010000e+03 train accuracy: 0.274143 val accuracy: 0.287000\n",
      "lr 6.100000e-06 reg 9.110000e+03 train accuracy: 0.267265 val accuracy: 0.281000\n",
      "lr 6.100000e-06 reg 9.210000e+03 train accuracy: 0.305306 val accuracy: 0.307000\n",
      "lr 6.100000e-06 reg 9.310000e+03 train accuracy: 0.276510 val accuracy: 0.288000\n",
      "lr 6.100000e-06 reg 9.410000e+03 train accuracy: 0.299714 val accuracy: 0.322000\n",
      "lr 6.100000e-06 reg 9.510000e+03 train accuracy: 0.275796 val accuracy: 0.292000\n",
      "lr 6.100000e-06 reg 9.610000e+03 train accuracy: 0.262143 val accuracy: 0.270000\n",
      "lr 6.100000e-06 reg 9.710000e+03 train accuracy: 0.221592 val accuracy: 0.221000\n",
      "lr 6.100000e-06 reg 9.810000e+03 train accuracy: 0.237959 val accuracy: 0.244000\n",
      "lr 6.100000e-06 reg 9.910000e+03 train accuracy: 0.265878 val accuracy: 0.269000\n",
      "lr 6.600000e-06 reg 1.000000e+01 train accuracy: 0.321265 val accuracy: 0.319000\n",
      "lr 6.600000e-06 reg 1.100000e+02 train accuracy: 0.351143 val accuracy: 0.328000\n",
      "lr 6.600000e-06 reg 2.100000e+02 train accuracy: 0.356694 val accuracy: 0.318000\n",
      "lr 6.600000e-06 reg 3.100000e+02 train accuracy: 0.356571 val accuracy: 0.310000\n",
      "lr 6.600000e-06 reg 4.100000e+02 train accuracy: 0.329388 val accuracy: 0.342000\n",
      "lr 6.600000e-06 reg 5.100000e+02 train accuracy: 0.342347 val accuracy: 0.319000\n",
      "lr 6.600000e-06 reg 6.100000e+02 train accuracy: 0.348143 val accuracy: 0.349000\n",
      "lr 6.600000e-06 reg 7.100000e+02 train accuracy: 0.280327 val accuracy: 0.282000\n",
      "lr 6.600000e-06 reg 8.100000e+02 train accuracy: 0.341408 val accuracy: 0.326000\n",
      "lr 6.600000e-06 reg 9.100000e+02 train accuracy: 0.367918 val accuracy: 0.358000\n",
      "lr 6.600000e-06 reg 1.010000e+03 train accuracy: 0.326388 val accuracy: 0.311000\n",
      "lr 6.600000e-06 reg 1.110000e+03 train accuracy: 0.327449 val accuracy: 0.313000\n",
      "lr 6.600000e-06 reg 1.210000e+03 train accuracy: 0.319020 val accuracy: 0.316000\n",
      "lr 6.600000e-06 reg 1.310000e+03 train accuracy: 0.308939 val accuracy: 0.302000\n",
      "lr 6.600000e-06 reg 1.410000e+03 train accuracy: 0.293102 val accuracy: 0.295000\n",
      "lr 6.600000e-06 reg 1.510000e+03 train accuracy: 0.319551 val accuracy: 0.331000\n",
      "lr 6.600000e-06 reg 1.610000e+03 train accuracy: 0.338224 val accuracy: 0.348000\n",
      "lr 6.600000e-06 reg 1.710000e+03 train accuracy: 0.305776 val accuracy: 0.313000\n",
      "lr 6.600000e-06 reg 1.810000e+03 train accuracy: 0.284714 val accuracy: 0.291000\n",
      "lr 6.600000e-06 reg 1.910000e+03 train accuracy: 0.316918 val accuracy: 0.325000\n",
      "lr 6.600000e-06 reg 2.010000e+03 train accuracy: 0.273612 val accuracy: 0.279000\n",
      "lr 6.600000e-06 reg 2.110000e+03 train accuracy: 0.335939 val accuracy: 0.343000\n",
      "lr 6.600000e-06 reg 2.210000e+03 train accuracy: 0.309204 val accuracy: 0.295000\n",
      "lr 6.600000e-06 reg 2.310000e+03 train accuracy: 0.323796 val accuracy: 0.315000\n",
      "lr 6.600000e-06 reg 2.410000e+03 train accuracy: 0.311653 val accuracy: 0.327000\n",
      "lr 6.600000e-06 reg 2.510000e+03 train accuracy: 0.302980 val accuracy: 0.315000\n",
      "lr 6.600000e-06 reg 2.610000e+03 train accuracy: 0.299898 val accuracy: 0.330000\n",
      "lr 6.600000e-06 reg 2.710000e+03 train accuracy: 0.316122 val accuracy: 0.313000\n",
      "lr 6.600000e-06 reg 2.810000e+03 train accuracy: 0.314612 val accuracy: 0.332000\n",
      "lr 6.600000e-06 reg 2.910000e+03 train accuracy: 0.347082 val accuracy: 0.352000\n",
      "lr 6.600000e-06 reg 3.010000e+03 train accuracy: 0.300490 val accuracy: 0.290000\n",
      "lr 6.600000e-06 reg 3.110000e+03 train accuracy: 0.311837 val accuracy: 0.329000\n",
      "lr 6.600000e-06 reg 3.210000e+03 train accuracy: 0.297939 val accuracy: 0.309000\n",
      "lr 6.600000e-06 reg 3.310000e+03 train accuracy: 0.296776 val accuracy: 0.302000\n",
      "lr 6.600000e-06 reg 3.410000e+03 train accuracy: 0.295796 val accuracy: 0.315000\n",
      "lr 6.600000e-06 reg 3.510000e+03 train accuracy: 0.280653 val accuracy: 0.293000\n",
      "lr 6.600000e-06 reg 3.610000e+03 train accuracy: 0.322306 val accuracy: 0.314000\n",
      "lr 6.600000e-06 reg 3.710000e+03 train accuracy: 0.311653 val accuracy: 0.321000\n",
      "lr 6.600000e-06 reg 3.810000e+03 train accuracy: 0.287388 val accuracy: 0.292000\n",
      "lr 6.600000e-06 reg 3.910000e+03 train accuracy: 0.288122 val accuracy: 0.282000\n",
      "lr 6.600000e-06 reg 4.010000e+03 train accuracy: 0.340592 val accuracy: 0.348000\n",
      "lr 6.600000e-06 reg 4.110000e+03 train accuracy: 0.320388 val accuracy: 0.307000\n",
      "lr 6.600000e-06 reg 4.210000e+03 train accuracy: 0.313265 val accuracy: 0.317000\n",
      "lr 6.600000e-06 reg 4.310000e+03 train accuracy: 0.269714 val accuracy: 0.268000\n",
      "lr 6.600000e-06 reg 4.410000e+03 train accuracy: 0.229735 val accuracy: 0.253000\n",
      "lr 6.600000e-06 reg 4.510000e+03 train accuracy: 0.266490 val accuracy: 0.268000\n",
      "lr 6.600000e-06 reg 4.610000e+03 train accuracy: 0.315469 val accuracy: 0.331000\n",
      "lr 6.600000e-06 reg 4.710000e+03 train accuracy: 0.247163 val accuracy: 0.256000\n",
      "lr 6.600000e-06 reg 4.810000e+03 train accuracy: 0.294490 val accuracy: 0.305000\n",
      "lr 6.600000e-06 reg 4.910000e+03 train accuracy: 0.325837 val accuracy: 0.325000\n",
      "lr 6.600000e-06 reg 5.010000e+03 train accuracy: 0.297776 val accuracy: 0.305000\n",
      "lr 6.600000e-06 reg 5.110000e+03 train accuracy: 0.259714 val accuracy: 0.264000\n",
      "lr 6.600000e-06 reg 5.210000e+03 train accuracy: 0.251469 val accuracy: 0.257000\n",
      "lr 6.600000e-06 reg 5.310000e+03 train accuracy: 0.262612 val accuracy: 0.274000\n",
      "lr 6.600000e-06 reg 5.410000e+03 train accuracy: 0.296388 val accuracy: 0.318000\n",
      "lr 6.600000e-06 reg 5.510000e+03 train accuracy: 0.240245 val accuracy: 0.238000\n",
      "lr 6.600000e-06 reg 5.610000e+03 train accuracy: 0.258163 val accuracy: 0.262000\n",
      "lr 6.600000e-06 reg 5.710000e+03 train accuracy: 0.306367 val accuracy: 0.318000\n",
      "lr 6.600000e-06 reg 5.810000e+03 train accuracy: 0.251980 val accuracy: 0.257000\n",
      "lr 6.600000e-06 reg 5.910000e+03 train accuracy: 0.275592 val accuracy: 0.288000\n",
      "lr 6.600000e-06 reg 6.010000e+03 train accuracy: 0.281714 val accuracy: 0.294000\n",
      "lr 6.600000e-06 reg 6.110000e+03 train accuracy: 0.324857 val accuracy: 0.346000\n",
      "lr 6.600000e-06 reg 6.210000e+03 train accuracy: 0.279939 val accuracy: 0.296000\n",
      "lr 6.600000e-06 reg 6.310000e+03 train accuracy: 0.289449 val accuracy: 0.301000\n",
      "lr 6.600000e-06 reg 6.410000e+03 train accuracy: 0.241245 val accuracy: 0.242000\n",
      "lr 6.600000e-06 reg 6.510000e+03 train accuracy: 0.259102 val accuracy: 0.254000\n",
      "lr 6.600000e-06 reg 6.610000e+03 train accuracy: 0.267469 val accuracy: 0.281000\n",
      "lr 6.600000e-06 reg 6.710000e+03 train accuracy: 0.264265 val accuracy: 0.281000\n",
      "lr 6.600000e-06 reg 6.810000e+03 train accuracy: 0.277694 val accuracy: 0.275000\n",
      "lr 6.600000e-06 reg 6.910000e+03 train accuracy: 0.224367 val accuracy: 0.225000\n",
      "lr 6.600000e-06 reg 7.010000e+03 train accuracy: 0.274694 val accuracy: 0.275000\n",
      "lr 6.600000e-06 reg 7.110000e+03 train accuracy: 0.285592 val accuracy: 0.307000\n",
      "lr 6.600000e-06 reg 7.210000e+03 train accuracy: 0.215490 val accuracy: 0.220000\n",
      "lr 6.600000e-06 reg 7.310000e+03 train accuracy: 0.259776 val accuracy: 0.272000\n",
      "lr 6.600000e-06 reg 7.410000e+03 train accuracy: 0.229755 val accuracy: 0.249000\n",
      "lr 6.600000e-06 reg 7.510000e+03 train accuracy: 0.212653 val accuracy: 0.221000\n",
      "lr 6.600000e-06 reg 7.610000e+03 train accuracy: 0.297939 val accuracy: 0.301000\n",
      "lr 6.600000e-06 reg 7.710000e+03 train accuracy: 0.197898 val accuracy: 0.213000\n",
      "lr 6.600000e-06 reg 7.810000e+03 train accuracy: 0.262959 val accuracy: 0.281000\n",
      "lr 6.600000e-06 reg 7.910000e+03 train accuracy: 0.251204 val accuracy: 0.275000\n",
      "lr 6.600000e-06 reg 8.010000e+03 train accuracy: 0.256367 val accuracy: 0.290000\n",
      "lr 6.600000e-06 reg 8.110000e+03 train accuracy: 0.313633 val accuracy: 0.310000\n",
      "lr 6.600000e-06 reg 8.210000e+03 train accuracy: 0.254327 val accuracy: 0.270000\n",
      "lr 6.600000e-06 reg 8.310000e+03 train accuracy: 0.251612 val accuracy: 0.264000\n",
      "lr 6.600000e-06 reg 8.410000e+03 train accuracy: 0.228714 val accuracy: 0.230000\n",
      "lr 6.600000e-06 reg 8.510000e+03 train accuracy: 0.228592 val accuracy: 0.246000\n",
      "lr 6.600000e-06 reg 8.610000e+03 train accuracy: 0.290469 val accuracy: 0.287000\n",
      "lr 6.600000e-06 reg 8.710000e+03 train accuracy: 0.257143 val accuracy: 0.266000\n",
      "lr 6.600000e-06 reg 8.810000e+03 train accuracy: 0.247245 val accuracy: 0.240000\n",
      "lr 6.600000e-06 reg 8.910000e+03 train accuracy: 0.216000 val accuracy: 0.219000\n",
      "lr 6.600000e-06 reg 9.010000e+03 train accuracy: 0.242714 val accuracy: 0.249000\n",
      "lr 6.600000e-06 reg 9.110000e+03 train accuracy: 0.288306 val accuracy: 0.289000\n",
      "lr 6.600000e-06 reg 9.210000e+03 train accuracy: 0.273571 val accuracy: 0.267000\n",
      "lr 6.600000e-06 reg 9.310000e+03 train accuracy: 0.264184 val accuracy: 0.280000\n",
      "lr 6.600000e-06 reg 9.410000e+03 train accuracy: 0.232837 val accuracy: 0.258000\n",
      "lr 6.600000e-06 reg 9.510000e+03 train accuracy: 0.239510 val accuracy: 0.249000\n",
      "lr 6.600000e-06 reg 9.610000e+03 train accuracy: 0.258367 val accuracy: 0.266000\n",
      "lr 6.600000e-06 reg 9.710000e+03 train accuracy: 0.247531 val accuracy: 0.269000\n",
      "lr 6.600000e-06 reg 9.810000e+03 train accuracy: 0.255571 val accuracy: 0.240000\n",
      "lr 6.600000e-06 reg 9.910000e+03 train accuracy: 0.245184 val accuracy: 0.248000\n",
      "lr 7.100000e-06 reg 1.000000e+01 train accuracy: 0.330000 val accuracy: 0.310000\n",
      "lr 7.100000e-06 reg 1.100000e+02 train accuracy: 0.356531 val accuracy: 0.359000\n",
      "lr 7.100000e-06 reg 2.100000e+02 train accuracy: 0.347571 val accuracy: 0.326000\n",
      "lr 7.100000e-06 reg 3.100000e+02 train accuracy: 0.321633 val accuracy: 0.299000\n",
      "lr 7.100000e-06 reg 4.100000e+02 train accuracy: 0.377388 val accuracy: 0.360000\n",
      "lr 7.100000e-06 reg 5.100000e+02 train accuracy: 0.324041 val accuracy: 0.316000\n",
      "lr 7.100000e-06 reg 6.100000e+02 train accuracy: 0.309755 val accuracy: 0.290000\n",
      "lr 7.100000e-06 reg 7.100000e+02 train accuracy: 0.327959 val accuracy: 0.340000\n",
      "lr 7.100000e-06 reg 8.100000e+02 train accuracy: 0.311776 val accuracy: 0.321000\n",
      "lr 7.100000e-06 reg 9.100000e+02 train accuracy: 0.337082 val accuracy: 0.342000\n",
      "lr 7.100000e-06 reg 1.010000e+03 train accuracy: 0.307959 val accuracy: 0.319000\n",
      "lr 7.100000e-06 reg 1.110000e+03 train accuracy: 0.342571 val accuracy: 0.340000\n",
      "lr 7.100000e-06 reg 1.210000e+03 train accuracy: 0.286653 val accuracy: 0.310000\n",
      "lr 7.100000e-06 reg 1.310000e+03 train accuracy: 0.295816 val accuracy: 0.303000\n",
      "lr 7.100000e-06 reg 1.410000e+03 train accuracy: 0.306878 val accuracy: 0.312000\n",
      "lr 7.100000e-06 reg 1.510000e+03 train accuracy: 0.301776 val accuracy: 0.313000\n",
      "lr 7.100000e-06 reg 1.610000e+03 train accuracy: 0.295204 val accuracy: 0.297000\n",
      "lr 7.100000e-06 reg 1.710000e+03 train accuracy: 0.272000 val accuracy: 0.288000\n",
      "lr 7.100000e-06 reg 1.810000e+03 train accuracy: 0.305776 val accuracy: 0.320000\n",
      "lr 7.100000e-06 reg 1.910000e+03 train accuracy: 0.302143 val accuracy: 0.280000\n",
      "lr 7.100000e-06 reg 2.010000e+03 train accuracy: 0.332959 val accuracy: 0.346000\n",
      "lr 7.100000e-06 reg 2.110000e+03 train accuracy: 0.285653 val accuracy: 0.295000\n",
      "lr 7.100000e-06 reg 2.210000e+03 train accuracy: 0.261980 val accuracy: 0.254000\n",
      "lr 7.100000e-06 reg 2.310000e+03 train accuracy: 0.303429 val accuracy: 0.303000\n",
      "lr 7.100000e-06 reg 2.410000e+03 train accuracy: 0.277449 val accuracy: 0.291000\n",
      "lr 7.100000e-06 reg 2.510000e+03 train accuracy: 0.241204 val accuracy: 0.243000\n",
      "lr 7.100000e-06 reg 2.610000e+03 train accuracy: 0.296061 val accuracy: 0.336000\n",
      "lr 7.100000e-06 reg 2.710000e+03 train accuracy: 0.302898 val accuracy: 0.317000\n",
      "lr 7.100000e-06 reg 2.810000e+03 train accuracy: 0.259020 val accuracy: 0.265000\n",
      "lr 7.100000e-06 reg 2.910000e+03 train accuracy: 0.272041 val accuracy: 0.276000\n",
      "lr 7.100000e-06 reg 3.010000e+03 train accuracy: 0.315286 val accuracy: 0.287000\n",
      "lr 7.100000e-06 reg 3.110000e+03 train accuracy: 0.247878 val accuracy: 0.258000\n",
      "lr 7.100000e-06 reg 3.210000e+03 train accuracy: 0.274204 val accuracy: 0.281000\n",
      "lr 7.100000e-06 reg 3.310000e+03 train accuracy: 0.298245 val accuracy: 0.300000\n",
      "lr 7.100000e-06 reg 3.410000e+03 train accuracy: 0.285041 val accuracy: 0.289000\n",
      "lr 7.100000e-06 reg 3.510000e+03 train accuracy: 0.280102 val accuracy: 0.291000\n",
      "lr 7.100000e-06 reg 3.610000e+03 train accuracy: 0.289469 val accuracy: 0.301000\n",
      "lr 7.100000e-06 reg 3.710000e+03 train accuracy: 0.301429 val accuracy: 0.286000\n",
      "lr 7.100000e-06 reg 3.810000e+03 train accuracy: 0.251612 val accuracy: 0.280000\n",
      "lr 7.100000e-06 reg 3.910000e+03 train accuracy: 0.274327 val accuracy: 0.276000\n",
      "lr 7.100000e-06 reg 4.010000e+03 train accuracy: 0.264163 val accuracy: 0.278000\n",
      "lr 7.100000e-06 reg 4.110000e+03 train accuracy: 0.296939 val accuracy: 0.293000\n",
      "lr 7.100000e-06 reg 4.210000e+03 train accuracy: 0.259408 val accuracy: 0.288000\n",
      "lr 7.100000e-06 reg 4.310000e+03 train accuracy: 0.287449 val accuracy: 0.297000\n",
      "lr 7.100000e-06 reg 4.410000e+03 train accuracy: 0.252531 val accuracy: 0.259000\n",
      "lr 7.100000e-06 reg 4.510000e+03 train accuracy: 0.300449 val accuracy: 0.304000\n",
      "lr 7.100000e-06 reg 4.610000e+03 train accuracy: 0.237388 val accuracy: 0.248000\n",
      "lr 7.100000e-06 reg 4.710000e+03 train accuracy: 0.271959 val accuracy: 0.283000\n",
      "lr 7.100000e-06 reg 4.810000e+03 train accuracy: 0.250673 val accuracy: 0.257000\n",
      "lr 7.100000e-06 reg 4.910000e+03 train accuracy: 0.242327 val accuracy: 0.252000\n",
      "lr 7.100000e-06 reg 5.010000e+03 train accuracy: 0.289551 val accuracy: 0.304000\n",
      "lr 7.100000e-06 reg 5.110000e+03 train accuracy: 0.252633 val accuracy: 0.259000\n",
      "lr 7.100000e-06 reg 5.210000e+03 train accuracy: 0.260898 val accuracy: 0.283000\n",
      "lr 7.100000e-06 reg 5.310000e+03 train accuracy: 0.278306 val accuracy: 0.293000\n",
      "lr 7.100000e-06 reg 5.410000e+03 train accuracy: 0.237592 val accuracy: 0.259000\n",
      "lr 7.100000e-06 reg 5.510000e+03 train accuracy: 0.276224 val accuracy: 0.293000\n",
      "lr 7.100000e-06 reg 5.610000e+03 train accuracy: 0.266857 val accuracy: 0.270000\n",
      "lr 7.100000e-06 reg 5.710000e+03 train accuracy: 0.282020 val accuracy: 0.281000\n",
      "lr 7.100000e-06 reg 5.810000e+03 train accuracy: 0.305612 val accuracy: 0.312000\n",
      "lr 7.100000e-06 reg 5.910000e+03 train accuracy: 0.211633 val accuracy: 0.208000\n",
      "lr 7.100000e-06 reg 6.010000e+03 train accuracy: 0.297694 val accuracy: 0.314000\n",
      "lr 7.100000e-06 reg 6.110000e+03 train accuracy: 0.251714 val accuracy: 0.274000\n",
      "lr 7.100000e-06 reg 6.210000e+03 train accuracy: 0.234612 val accuracy: 0.259000\n",
      "lr 7.100000e-06 reg 6.310000e+03 train accuracy: 0.272939 val accuracy: 0.282000\n",
      "lr 7.100000e-06 reg 6.410000e+03 train accuracy: 0.289959 val accuracy: 0.293000\n",
      "lr 7.100000e-06 reg 6.510000e+03 train accuracy: 0.233347 val accuracy: 0.260000\n",
      "lr 7.100000e-06 reg 6.610000e+03 train accuracy: 0.273204 val accuracy: 0.285000\n",
      "lr 7.100000e-06 reg 6.710000e+03 train accuracy: 0.259551 val accuracy: 0.274000\n",
      "lr 7.100000e-06 reg 6.810000e+03 train accuracy: 0.220082 val accuracy: 0.231000\n",
      "lr 7.100000e-06 reg 6.910000e+03 train accuracy: 0.243469 val accuracy: 0.254000\n",
      "lr 7.100000e-06 reg 7.010000e+03 train accuracy: 0.236102 val accuracy: 0.256000\n",
      "lr 7.100000e-06 reg 7.110000e+03 train accuracy: 0.263673 val accuracy: 0.281000\n",
      "lr 7.100000e-06 reg 7.210000e+03 train accuracy: 0.216796 val accuracy: 0.221000\n",
      "lr 7.100000e-06 reg 7.310000e+03 train accuracy: 0.260918 val accuracy: 0.261000\n",
      "lr 7.100000e-06 reg 7.410000e+03 train accuracy: 0.290837 val accuracy: 0.287000\n",
      "lr 7.100000e-06 reg 7.510000e+03 train accuracy: 0.298163 val accuracy: 0.320000\n",
      "lr 7.100000e-06 reg 7.610000e+03 train accuracy: 0.241694 val accuracy: 0.246000\n",
      "lr 7.100000e-06 reg 7.710000e+03 train accuracy: 0.242224 val accuracy: 0.254000\n",
      "lr 7.100000e-06 reg 7.810000e+03 train accuracy: 0.239592 val accuracy: 0.241000\n",
      "lr 7.100000e-06 reg 7.910000e+03 train accuracy: 0.260959 val accuracy: 0.263000\n",
      "lr 7.100000e-06 reg 8.010000e+03 train accuracy: 0.228551 val accuracy: 0.239000\n",
      "lr 7.100000e-06 reg 8.110000e+03 train accuracy: 0.220755 val accuracy: 0.228000\n",
      "lr 7.100000e-06 reg 8.210000e+03 train accuracy: 0.243306 val accuracy: 0.254000\n",
      "lr 7.100000e-06 reg 8.310000e+03 train accuracy: 0.289020 val accuracy: 0.289000\n",
      "lr 7.100000e-06 reg 8.410000e+03 train accuracy: 0.241429 val accuracy: 0.245000\n",
      "lr 7.100000e-06 reg 8.510000e+03 train accuracy: 0.210041 val accuracy: 0.209000\n",
      "lr 7.100000e-06 reg 8.610000e+03 train accuracy: 0.214265 val accuracy: 0.234000\n",
      "lr 7.100000e-06 reg 8.710000e+03 train accuracy: 0.220612 val accuracy: 0.234000\n",
      "lr 7.100000e-06 reg 8.810000e+03 train accuracy: 0.279857 val accuracy: 0.305000\n",
      "lr 7.100000e-06 reg 8.910000e+03 train accuracy: 0.280020 val accuracy: 0.295000\n",
      "lr 7.100000e-06 reg 9.010000e+03 train accuracy: 0.294694 val accuracy: 0.298000\n",
      "lr 7.100000e-06 reg 9.110000e+03 train accuracy: 0.262592 val accuracy: 0.276000\n",
      "lr 7.100000e-06 reg 9.210000e+03 train accuracy: 0.261980 val accuracy: 0.284000\n",
      "lr 7.100000e-06 reg 9.310000e+03 train accuracy: 0.246673 val accuracy: 0.261000\n",
      "lr 7.100000e-06 reg 9.410000e+03 train accuracy: 0.208796 val accuracy: 0.201000\n",
      "lr 7.100000e-06 reg 9.510000e+03 train accuracy: 0.255265 val accuracy: 0.276000\n",
      "lr 7.100000e-06 reg 9.610000e+03 train accuracy: 0.205306 val accuracy: 0.210000\n",
      "lr 7.100000e-06 reg 9.710000e+03 train accuracy: 0.293449 val accuracy: 0.318000\n",
      "lr 7.100000e-06 reg 9.810000e+03 train accuracy: 0.235959 val accuracy: 0.249000\n",
      "lr 7.100000e-06 reg 9.910000e+03 train accuracy: 0.209898 val accuracy: 0.215000\n",
      "lr 7.600000e-06 reg 1.000000e+01 train accuracy: 0.337592 val accuracy: 0.326000\n",
      "lr 7.600000e-06 reg 1.100000e+02 train accuracy: 0.341061 val accuracy: 0.331000\n",
      "lr 7.600000e-06 reg 2.100000e+02 train accuracy: 0.373551 val accuracy: 0.348000\n",
      "lr 7.600000e-06 reg 3.100000e+02 train accuracy: 0.317592 val accuracy: 0.323000\n",
      "lr 7.600000e-06 reg 4.100000e+02 train accuracy: 0.295857 val accuracy: 0.283000\n",
      "lr 7.600000e-06 reg 5.100000e+02 train accuracy: 0.295000 val accuracy: 0.295000\n",
      "lr 7.600000e-06 reg 6.100000e+02 train accuracy: 0.341061 val accuracy: 0.338000\n",
      "lr 7.600000e-06 reg 7.100000e+02 train accuracy: 0.233163 val accuracy: 0.242000\n",
      "lr 7.600000e-06 reg 8.100000e+02 train accuracy: 0.294122 val accuracy: 0.293000\n",
      "lr 7.600000e-06 reg 9.100000e+02 train accuracy: 0.319204 val accuracy: 0.326000\n",
      "lr 7.600000e-06 reg 1.010000e+03 train accuracy: 0.282408 val accuracy: 0.287000\n",
      "lr 7.600000e-06 reg 1.110000e+03 train accuracy: 0.309041 val accuracy: 0.326000\n",
      "lr 7.600000e-06 reg 1.210000e+03 train accuracy: 0.298408 val accuracy: 0.307000\n",
      "lr 7.600000e-06 reg 1.310000e+03 train accuracy: 0.286939 val accuracy: 0.295000\n",
      "lr 7.600000e-06 reg 1.410000e+03 train accuracy: 0.320612 val accuracy: 0.338000\n",
      "lr 7.600000e-06 reg 1.510000e+03 train accuracy: 0.280857 val accuracy: 0.273000\n",
      "lr 7.600000e-06 reg 1.610000e+03 train accuracy: 0.275735 val accuracy: 0.295000\n",
      "lr 7.600000e-06 reg 1.710000e+03 train accuracy: 0.286163 val accuracy: 0.304000\n",
      "lr 7.600000e-06 reg 1.810000e+03 train accuracy: 0.337082 val accuracy: 0.303000\n",
      "lr 7.600000e-06 reg 1.910000e+03 train accuracy: 0.270102 val accuracy: 0.267000\n",
      "lr 7.600000e-06 reg 2.010000e+03 train accuracy: 0.286265 val accuracy: 0.314000\n",
      "lr 7.600000e-06 reg 2.110000e+03 train accuracy: 0.285857 val accuracy: 0.298000\n",
      "lr 7.600000e-06 reg 2.210000e+03 train accuracy: 0.311918 val accuracy: 0.325000\n",
      "lr 7.600000e-06 reg 2.310000e+03 train accuracy: 0.288633 val accuracy: 0.302000\n",
      "lr 7.600000e-06 reg 2.410000e+03 train accuracy: 0.294918 val accuracy: 0.295000\n",
      "lr 7.600000e-06 reg 2.510000e+03 train accuracy: 0.244102 val accuracy: 0.255000\n",
      "lr 7.600000e-06 reg 2.610000e+03 train accuracy: 0.267633 val accuracy: 0.259000\n",
      "lr 7.600000e-06 reg 2.710000e+03 train accuracy: 0.295857 val accuracy: 0.309000\n",
      "lr 7.600000e-06 reg 2.810000e+03 train accuracy: 0.248980 val accuracy: 0.263000\n",
      "lr 7.600000e-06 reg 2.910000e+03 train accuracy: 0.275898 val accuracy: 0.295000\n",
      "lr 7.600000e-06 reg 3.010000e+03 train accuracy: 0.239510 val accuracy: 0.255000\n",
      "lr 7.600000e-06 reg 3.110000e+03 train accuracy: 0.251245 val accuracy: 0.254000\n",
      "lr 7.600000e-06 reg 3.210000e+03 train accuracy: 0.254776 val accuracy: 0.250000\n",
      "lr 7.600000e-06 reg 3.310000e+03 train accuracy: 0.277306 val accuracy: 0.274000\n",
      "lr 7.600000e-06 reg 3.410000e+03 train accuracy: 0.286898 val accuracy: 0.301000\n",
      "lr 7.600000e-06 reg 3.510000e+03 train accuracy: 0.277245 val accuracy: 0.265000\n",
      "lr 7.600000e-06 reg 3.610000e+03 train accuracy: 0.282163 val accuracy: 0.304000\n",
      "lr 7.600000e-06 reg 3.710000e+03 train accuracy: 0.244224 val accuracy: 0.240000\n",
      "lr 7.600000e-06 reg 3.810000e+03 train accuracy: 0.260959 val accuracy: 0.289000\n",
      "lr 7.600000e-06 reg 3.910000e+03 train accuracy: 0.214939 val accuracy: 0.217000\n",
      "lr 7.600000e-06 reg 4.010000e+03 train accuracy: 0.262224 val accuracy: 0.285000\n",
      "lr 7.600000e-06 reg 4.110000e+03 train accuracy: 0.250653 val accuracy: 0.280000\n",
      "lr 7.600000e-06 reg 4.210000e+03 train accuracy: 0.238694 val accuracy: 0.249000\n",
      "lr 7.600000e-06 reg 4.310000e+03 train accuracy: 0.238959 val accuracy: 0.253000\n",
      "lr 7.600000e-06 reg 4.410000e+03 train accuracy: 0.276327 val accuracy: 0.282000\n",
      "lr 7.600000e-06 reg 4.510000e+03 train accuracy: 0.195143 val accuracy: 0.202000\n",
      "lr 7.600000e-06 reg 4.610000e+03 train accuracy: 0.268490 val accuracy: 0.271000\n",
      "lr 7.600000e-06 reg 4.710000e+03 train accuracy: 0.305612 val accuracy: 0.291000\n",
      "lr 7.600000e-06 reg 4.810000e+03 train accuracy: 0.233041 val accuracy: 0.253000\n",
      "lr 7.600000e-06 reg 4.910000e+03 train accuracy: 0.265755 val accuracy: 0.286000\n",
      "lr 7.600000e-06 reg 5.010000e+03 train accuracy: 0.285980 val accuracy: 0.293000\n",
      "lr 7.600000e-06 reg 5.110000e+03 train accuracy: 0.264204 val accuracy: 0.271000\n",
      "lr 7.600000e-06 reg 5.210000e+03 train accuracy: 0.260571 val accuracy: 0.267000\n",
      "lr 7.600000e-06 reg 5.310000e+03 train accuracy: 0.262184 val accuracy: 0.267000\n",
      "lr 7.600000e-06 reg 5.410000e+03 train accuracy: 0.225286 val accuracy: 0.240000\n",
      "lr 7.600000e-06 reg 5.510000e+03 train accuracy: 0.249796 val accuracy: 0.259000\n",
      "lr 7.600000e-06 reg 5.610000e+03 train accuracy: 0.293327 val accuracy: 0.276000\n",
      "lr 7.600000e-06 reg 5.710000e+03 train accuracy: 0.278816 val accuracy: 0.268000\n",
      "lr 7.600000e-06 reg 5.810000e+03 train accuracy: 0.235041 val accuracy: 0.243000\n",
      "lr 7.600000e-06 reg 5.910000e+03 train accuracy: 0.232755 val accuracy: 0.248000\n",
      "lr 7.600000e-06 reg 6.010000e+03 train accuracy: 0.189796 val accuracy: 0.205000\n",
      "lr 7.600000e-06 reg 6.110000e+03 train accuracy: 0.285061 val accuracy: 0.292000\n",
      "lr 7.600000e-06 reg 6.210000e+03 train accuracy: 0.213959 val accuracy: 0.228000\n",
      "lr 7.600000e-06 reg 6.310000e+03 train accuracy: 0.221122 val accuracy: 0.228000\n",
      "lr 7.600000e-06 reg 6.410000e+03 train accuracy: 0.270571 val accuracy: 0.280000\n",
      "lr 7.600000e-06 reg 6.510000e+03 train accuracy: 0.242306 val accuracy: 0.240000\n",
      "lr 7.600000e-06 reg 6.610000e+03 train accuracy: 0.277714 val accuracy: 0.262000\n",
      "lr 7.600000e-06 reg 6.710000e+03 train accuracy: 0.196592 val accuracy: 0.211000\n",
      "lr 7.600000e-06 reg 6.810000e+03 train accuracy: 0.203714 val accuracy: 0.209000\n",
      "lr 7.600000e-06 reg 6.910000e+03 train accuracy: 0.244653 val accuracy: 0.245000\n",
      "lr 7.600000e-06 reg 7.010000e+03 train accuracy: 0.211776 val accuracy: 0.222000\n",
      "lr 7.600000e-06 reg 7.110000e+03 train accuracy: 0.209551 val accuracy: 0.217000\n",
      "lr 7.600000e-06 reg 7.210000e+03 train accuracy: 0.262020 val accuracy: 0.265000\n",
      "lr 7.600000e-06 reg 7.310000e+03 train accuracy: 0.224755 val accuracy: 0.219000\n",
      "lr 7.600000e-06 reg 7.410000e+03 train accuracy: 0.279755 val accuracy: 0.271000\n",
      "lr 7.600000e-06 reg 7.510000e+03 train accuracy: 0.238531 val accuracy: 0.236000\n",
      "lr 7.600000e-06 reg 7.610000e+03 train accuracy: 0.274143 val accuracy: 0.292000\n",
      "lr 7.600000e-06 reg 7.710000e+03 train accuracy: 0.193918 val accuracy: 0.190000\n",
      "lr 7.600000e-06 reg 7.810000e+03 train accuracy: 0.289796 val accuracy: 0.293000\n",
      "lr 7.600000e-06 reg 7.910000e+03 train accuracy: 0.246735 val accuracy: 0.255000\n",
      "lr 7.600000e-06 reg 8.010000e+03 train accuracy: 0.255939 val accuracy: 0.255000\n",
      "lr 7.600000e-06 reg 8.110000e+03 train accuracy: 0.233592 val accuracy: 0.254000\n",
      "lr 7.600000e-06 reg 8.210000e+03 train accuracy: 0.274102 val accuracy: 0.299000\n",
      "lr 7.600000e-06 reg 8.310000e+03 train accuracy: 0.219061 val accuracy: 0.226000\n",
      "lr 7.600000e-06 reg 8.410000e+03 train accuracy: 0.205429 val accuracy: 0.207000\n",
      "lr 7.600000e-06 reg 8.510000e+03 train accuracy: 0.230714 val accuracy: 0.242000\n",
      "lr 7.600000e-06 reg 8.610000e+03 train accuracy: 0.203082 val accuracy: 0.215000\n",
      "lr 7.600000e-06 reg 8.710000e+03 train accuracy: 0.219245 val accuracy: 0.226000\n",
      "lr 7.600000e-06 reg 8.810000e+03 train accuracy: 0.246327 val accuracy: 0.288000\n",
      "lr 7.600000e-06 reg 8.910000e+03 train accuracy: 0.234653 val accuracy: 0.241000\n",
      "lr 7.600000e-06 reg 9.010000e+03 train accuracy: 0.238286 val accuracy: 0.250000\n",
      "lr 7.600000e-06 reg 9.110000e+03 train accuracy: 0.209429 val accuracy: 0.208000\n",
      "lr 7.600000e-06 reg 9.210000e+03 train accuracy: 0.250857 val accuracy: 0.252000\n",
      "lr 7.600000e-06 reg 9.310000e+03 train accuracy: 0.199816 val accuracy: 0.224000\n",
      "lr 7.600000e-06 reg 9.410000e+03 train accuracy: 0.227592 val accuracy: 0.242000\n",
      "lr 7.600000e-06 reg 9.510000e+03 train accuracy: 0.241816 val accuracy: 0.264000\n",
      "lr 7.600000e-06 reg 9.610000e+03 train accuracy: 0.248959 val accuracy: 0.237000\n",
      "lr 7.600000e-06 reg 9.710000e+03 train accuracy: 0.199857 val accuracy: 0.211000\n",
      "lr 7.600000e-06 reg 9.810000e+03 train accuracy: 0.240265 val accuracy: 0.244000\n",
      "lr 7.600000e-06 reg 9.910000e+03 train accuracy: 0.225592 val accuracy: 0.225000\n",
      "lr 8.100000e-06 reg 1.000000e+01 train accuracy: 0.337878 val accuracy: 0.344000\n",
      "lr 8.100000e-06 reg 1.100000e+02 train accuracy: 0.388367 val accuracy: 0.365000\n",
      "lr 8.100000e-06 reg 2.100000e+02 train accuracy: 0.275959 val accuracy: 0.284000\n",
      "lr 8.100000e-06 reg 3.100000e+02 train accuracy: 0.292653 val accuracy: 0.273000\n",
      "lr 8.100000e-06 reg 4.100000e+02 train accuracy: 0.314837 val accuracy: 0.315000\n",
      "lr 8.100000e-06 reg 5.100000e+02 train accuracy: 0.315041 val accuracy: 0.312000\n",
      "lr 8.100000e-06 reg 6.100000e+02 train accuracy: 0.345755 val accuracy: 0.328000\n",
      "lr 8.100000e-06 reg 7.100000e+02 train accuracy: 0.300694 val accuracy: 0.304000\n",
      "lr 8.100000e-06 reg 8.100000e+02 train accuracy: 0.275367 val accuracy: 0.284000\n",
      "lr 8.100000e-06 reg 9.100000e+02 train accuracy: 0.293327 val accuracy: 0.277000\n",
      "lr 8.100000e-06 reg 1.010000e+03 train accuracy: 0.324020 val accuracy: 0.318000\n",
      "lr 8.100000e-06 reg 1.110000e+03 train accuracy: 0.276388 val accuracy: 0.292000\n",
      "lr 8.100000e-06 reg 1.210000e+03 train accuracy: 0.280898 val accuracy: 0.266000\n",
      "lr 8.100000e-06 reg 1.310000e+03 train accuracy: 0.335571 val accuracy: 0.359000\n",
      "lr 8.100000e-06 reg 1.410000e+03 train accuracy: 0.262653 val accuracy: 0.260000\n",
      "lr 8.100000e-06 reg 1.510000e+03 train accuracy: 0.248633 val accuracy: 0.257000\n",
      "lr 8.100000e-06 reg 1.610000e+03 train accuracy: 0.301184 val accuracy: 0.310000\n",
      "lr 8.100000e-06 reg 1.710000e+03 train accuracy: 0.267837 val accuracy: 0.272000\n",
      "lr 8.100000e-06 reg 1.810000e+03 train accuracy: 0.271143 val accuracy: 0.294000\n",
      "lr 8.100000e-06 reg 1.910000e+03 train accuracy: 0.257571 val accuracy: 0.267000\n",
      "lr 8.100000e-06 reg 2.010000e+03 train accuracy: 0.286490 val accuracy: 0.281000\n",
      "lr 8.100000e-06 reg 2.110000e+03 train accuracy: 0.279429 val accuracy: 0.287000\n",
      "lr 8.100000e-06 reg 2.210000e+03 train accuracy: 0.275673 val accuracy: 0.286000\n",
      "lr 8.100000e-06 reg 2.310000e+03 train accuracy: 0.269184 val accuracy: 0.270000\n",
      "lr 8.100000e-06 reg 2.410000e+03 train accuracy: 0.260102 val accuracy: 0.273000\n",
      "lr 8.100000e-06 reg 2.510000e+03 train accuracy: 0.276857 val accuracy: 0.298000\n",
      "lr 8.100000e-06 reg 2.610000e+03 train accuracy: 0.262959 val accuracy: 0.264000\n",
      "lr 8.100000e-06 reg 2.710000e+03 train accuracy: 0.282224 val accuracy: 0.284000\n",
      "lr 8.100000e-06 reg 2.810000e+03 train accuracy: 0.269755 val accuracy: 0.287000\n",
      "lr 8.100000e-06 reg 2.910000e+03 train accuracy: 0.281143 val accuracy: 0.281000\n",
      "lr 8.100000e-06 reg 3.010000e+03 train accuracy: 0.331694 val accuracy: 0.322000\n",
      "lr 8.100000e-06 reg 3.110000e+03 train accuracy: 0.293184 val accuracy: 0.311000\n",
      "lr 8.100000e-06 reg 3.210000e+03 train accuracy: 0.214388 val accuracy: 0.202000\n",
      "lr 8.100000e-06 reg 3.310000e+03 train accuracy: 0.250776 val accuracy: 0.256000\n",
      "lr 8.100000e-06 reg 3.410000e+03 train accuracy: 0.268633 val accuracy: 0.271000\n",
      "lr 8.100000e-06 reg 3.510000e+03 train accuracy: 0.261163 val accuracy: 0.261000\n",
      "lr 8.100000e-06 reg 3.610000e+03 train accuracy: 0.261857 val accuracy: 0.270000\n",
      "lr 8.100000e-06 reg 3.710000e+03 train accuracy: 0.253735 val accuracy: 0.281000\n",
      "lr 8.100000e-06 reg 3.810000e+03 train accuracy: 0.290837 val accuracy: 0.290000\n",
      "lr 8.100000e-06 reg 3.910000e+03 train accuracy: 0.285082 val accuracy: 0.308000\n",
      "lr 8.100000e-06 reg 4.010000e+03 train accuracy: 0.250796 val accuracy: 0.243000\n",
      "lr 8.100000e-06 reg 4.110000e+03 train accuracy: 0.249061 val accuracy: 0.268000\n",
      "lr 8.100000e-06 reg 4.210000e+03 train accuracy: 0.249429 val accuracy: 0.252000\n",
      "lr 8.100000e-06 reg 4.310000e+03 train accuracy: 0.250306 val accuracy: 0.265000\n",
      "lr 8.100000e-06 reg 4.410000e+03 train accuracy: 0.207898 val accuracy: 0.242000\n",
      "lr 8.100000e-06 reg 4.510000e+03 train accuracy: 0.226796 val accuracy: 0.237000\n",
      "lr 8.100000e-06 reg 4.610000e+03 train accuracy: 0.197878 val accuracy: 0.205000\n",
      "lr 8.100000e-06 reg 4.710000e+03 train accuracy: 0.269857 val accuracy: 0.297000\n",
      "lr 8.100000e-06 reg 4.810000e+03 train accuracy: 0.246510 val accuracy: 0.254000\n",
      "lr 8.100000e-06 reg 4.910000e+03 train accuracy: 0.230592 val accuracy: 0.254000\n",
      "lr 8.100000e-06 reg 5.010000e+03 train accuracy: 0.221898 val accuracy: 0.240000\n",
      "lr 8.100000e-06 reg 5.110000e+03 train accuracy: 0.243408 val accuracy: 0.228000\n",
      "lr 8.100000e-06 reg 5.210000e+03 train accuracy: 0.226980 val accuracy: 0.238000\n",
      "lr 8.100000e-06 reg 5.310000e+03 train accuracy: 0.276755 val accuracy: 0.285000\n",
      "lr 8.100000e-06 reg 5.410000e+03 train accuracy: 0.232694 val accuracy: 0.231000\n",
      "lr 8.100000e-06 reg 5.510000e+03 train accuracy: 0.245898 val accuracy: 0.263000\n",
      "lr 8.100000e-06 reg 5.610000e+03 train accuracy: 0.199143 val accuracy: 0.205000\n",
      "lr 8.100000e-06 reg 5.710000e+03 train accuracy: 0.282449 val accuracy: 0.292000\n",
      "lr 8.100000e-06 reg 5.810000e+03 train accuracy: 0.237245 val accuracy: 0.218000\n",
      "lr 8.100000e-06 reg 5.910000e+03 train accuracy: 0.209898 val accuracy: 0.205000\n",
      "lr 8.100000e-06 reg 6.010000e+03 train accuracy: 0.234939 val accuracy: 0.235000\n",
      "lr 8.100000e-06 reg 6.110000e+03 train accuracy: 0.224510 val accuracy: 0.234000\n",
      "lr 8.100000e-06 reg 6.210000e+03 train accuracy: 0.215204 val accuracy: 0.239000\n",
      "lr 8.100000e-06 reg 6.310000e+03 train accuracy: 0.250939 val accuracy: 0.239000\n",
      "lr 8.100000e-06 reg 6.410000e+03 train accuracy: 0.257082 val accuracy: 0.256000\n",
      "lr 8.100000e-06 reg 6.510000e+03 train accuracy: 0.233449 val accuracy: 0.253000\n",
      "lr 8.100000e-06 reg 6.610000e+03 train accuracy: 0.256878 val accuracy: 0.259000\n",
      "lr 8.100000e-06 reg 6.710000e+03 train accuracy: 0.247653 val accuracy: 0.281000\n",
      "lr 8.100000e-06 reg 6.810000e+03 train accuracy: 0.210286 val accuracy: 0.215000\n",
      "lr 8.100000e-06 reg 6.910000e+03 train accuracy: 0.226061 val accuracy: 0.235000\n",
      "lr 8.100000e-06 reg 7.010000e+03 train accuracy: 0.224837 val accuracy: 0.218000\n",
      "lr 8.100000e-06 reg 7.110000e+03 train accuracy: 0.240408 val accuracy: 0.247000\n",
      "lr 8.100000e-06 reg 7.210000e+03 train accuracy: 0.226347 val accuracy: 0.218000\n",
      "lr 8.100000e-06 reg 7.310000e+03 train accuracy: 0.228694 val accuracy: 0.239000\n",
      "lr 8.100000e-06 reg 7.410000e+03 train accuracy: 0.274551 val accuracy: 0.277000\n",
      "lr 8.100000e-06 reg 7.510000e+03 train accuracy: 0.197796 val accuracy: 0.208000\n",
      "lr 8.100000e-06 reg 7.610000e+03 train accuracy: 0.183551 val accuracy: 0.202000\n",
      "lr 8.100000e-06 reg 7.710000e+03 train accuracy: 0.208694 val accuracy: 0.232000\n",
      "lr 8.100000e-06 reg 7.810000e+03 train accuracy: 0.257531 val accuracy: 0.269000\n",
      "lr 8.100000e-06 reg 7.910000e+03 train accuracy: 0.232429 val accuracy: 0.219000\n",
      "lr 8.100000e-06 reg 8.010000e+03 train accuracy: 0.254122 val accuracy: 0.246000\n",
      "lr 8.100000e-06 reg 8.110000e+03 train accuracy: 0.200714 val accuracy: 0.207000\n",
      "lr 8.100000e-06 reg 8.210000e+03 train accuracy: 0.247653 val accuracy: 0.243000\n",
      "lr 8.100000e-06 reg 8.310000e+03 train accuracy: 0.232837 val accuracy: 0.235000\n",
      "lr 8.100000e-06 reg 8.410000e+03 train accuracy: 0.241490 val accuracy: 0.258000\n",
      "lr 8.100000e-06 reg 8.510000e+03 train accuracy: 0.247286 val accuracy: 0.261000\n",
      "lr 8.100000e-06 reg 8.610000e+03 train accuracy: 0.275143 val accuracy: 0.290000\n",
      "lr 8.100000e-06 reg 8.710000e+03 train accuracy: 0.175510 val accuracy: 0.186000\n",
      "lr 8.100000e-06 reg 8.810000e+03 train accuracy: 0.235878 val accuracy: 0.245000\n",
      "lr 8.100000e-06 reg 8.910000e+03 train accuracy: 0.225673 val accuracy: 0.222000\n",
      "lr 8.100000e-06 reg 9.010000e+03 train accuracy: 0.241633 val accuracy: 0.239000\n",
      "lr 8.100000e-06 reg 9.110000e+03 train accuracy: 0.259184 val accuracy: 0.268000\n",
      "lr 8.100000e-06 reg 9.210000e+03 train accuracy: 0.233327 val accuracy: 0.252000\n",
      "lr 8.100000e-06 reg 9.310000e+03 train accuracy: 0.219061 val accuracy: 0.225000\n",
      "lr 8.100000e-06 reg 9.410000e+03 train accuracy: 0.206510 val accuracy: 0.201000\n",
      "lr 8.100000e-06 reg 9.510000e+03 train accuracy: 0.232673 val accuracy: 0.233000\n",
      "lr 8.100000e-06 reg 9.610000e+03 train accuracy: 0.267857 val accuracy: 0.270000\n",
      "lr 8.100000e-06 reg 9.710000e+03 train accuracy: 0.226367 val accuracy: 0.224000\n",
      "lr 8.100000e-06 reg 9.810000e+03 train accuracy: 0.216143 val accuracy: 0.231000\n",
      "lr 8.100000e-06 reg 9.910000e+03 train accuracy: 0.213429 val accuracy: 0.218000\n",
      "lr 8.600000e-06 reg 1.000000e+01 train accuracy: 0.362102 val accuracy: 0.326000\n",
      "lr 8.600000e-06 reg 1.100000e+02 train accuracy: 0.356041 val accuracy: 0.358000\n",
      "lr 8.600000e-06 reg 2.100000e+02 train accuracy: 0.301143 val accuracy: 0.295000\n",
      "lr 8.600000e-06 reg 3.100000e+02 train accuracy: 0.337286 val accuracy: 0.335000\n",
      "lr 8.600000e-06 reg 4.100000e+02 train accuracy: 0.336755 val accuracy: 0.332000\n",
      "lr 8.600000e-06 reg 5.100000e+02 train accuracy: 0.347000 val accuracy: 0.345000\n",
      "lr 8.600000e-06 reg 6.100000e+02 train accuracy: 0.252857 val accuracy: 0.248000\n",
      "lr 8.600000e-06 reg 7.100000e+02 train accuracy: 0.299163 val accuracy: 0.300000\n",
      "lr 8.600000e-06 reg 8.100000e+02 train accuracy: 0.283796 val accuracy: 0.287000\n",
      "lr 8.600000e-06 reg 9.100000e+02 train accuracy: 0.301673 val accuracy: 0.310000\n",
      "lr 8.600000e-06 reg 1.010000e+03 train accuracy: 0.295673 val accuracy: 0.308000\n",
      "lr 8.600000e-06 reg 1.110000e+03 train accuracy: 0.297327 val accuracy: 0.309000\n",
      "lr 8.600000e-06 reg 1.210000e+03 train accuracy: 0.225857 val accuracy: 0.246000\n",
      "lr 8.600000e-06 reg 1.310000e+03 train accuracy: 0.277469 val accuracy: 0.267000\n",
      "lr 8.600000e-06 reg 1.410000e+03 train accuracy: 0.262347 val accuracy: 0.273000\n",
      "lr 8.600000e-06 reg 1.510000e+03 train accuracy: 0.309694 val accuracy: 0.332000\n",
      "lr 8.600000e-06 reg 1.610000e+03 train accuracy: 0.267184 val accuracy: 0.267000\n",
      "lr 8.600000e-06 reg 1.710000e+03 train accuracy: 0.292082 val accuracy: 0.313000\n",
      "lr 8.600000e-06 reg 1.810000e+03 train accuracy: 0.288102 val accuracy: 0.299000\n",
      "lr 8.600000e-06 reg 1.910000e+03 train accuracy: 0.259939 val accuracy: 0.290000\n",
      "lr 8.600000e-06 reg 2.010000e+03 train accuracy: 0.262612 val accuracy: 0.270000\n",
      "lr 8.600000e-06 reg 2.110000e+03 train accuracy: 0.261551 val accuracy: 0.271000\n",
      "lr 8.600000e-06 reg 2.210000e+03 train accuracy: 0.302714 val accuracy: 0.306000\n",
      "lr 8.600000e-06 reg 2.310000e+03 train accuracy: 0.246429 val accuracy: 0.247000\n",
      "lr 8.600000e-06 reg 2.410000e+03 train accuracy: 0.268959 val accuracy: 0.271000\n",
      "lr 8.600000e-06 reg 2.510000e+03 train accuracy: 0.232041 val accuracy: 0.222000\n",
      "lr 8.600000e-06 reg 2.610000e+03 train accuracy: 0.309592 val accuracy: 0.320000\n",
      "lr 8.600000e-06 reg 2.710000e+03 train accuracy: 0.278122 val accuracy: 0.258000\n",
      "lr 8.600000e-06 reg 2.810000e+03 train accuracy: 0.282571 val accuracy: 0.276000\n",
      "lr 8.600000e-06 reg 2.910000e+03 train accuracy: 0.300673 val accuracy: 0.298000\n",
      "lr 8.600000e-06 reg 3.010000e+03 train accuracy: 0.257327 val accuracy: 0.251000\n",
      "lr 8.600000e-06 reg 3.110000e+03 train accuracy: 0.261959 val accuracy: 0.265000\n",
      "lr 8.600000e-06 reg 3.210000e+03 train accuracy: 0.272816 val accuracy: 0.279000\n",
      "lr 8.600000e-06 reg 3.310000e+03 train accuracy: 0.266408 val accuracy: 0.266000\n",
      "lr 8.600000e-06 reg 3.410000e+03 train accuracy: 0.236918 val accuracy: 0.256000\n",
      "lr 8.600000e-06 reg 3.510000e+03 train accuracy: 0.232020 val accuracy: 0.253000\n",
      "lr 8.600000e-06 reg 3.610000e+03 train accuracy: 0.269857 val accuracy: 0.278000\n",
      "lr 8.600000e-06 reg 3.710000e+03 train accuracy: 0.235878 val accuracy: 0.218000\n",
      "lr 8.600000e-06 reg 3.810000e+03 train accuracy: 0.222061 val accuracy: 0.228000\n",
      "lr 8.600000e-06 reg 3.910000e+03 train accuracy: 0.282306 val accuracy: 0.292000\n",
      "lr 8.600000e-06 reg 4.010000e+03 train accuracy: 0.222816 val accuracy: 0.222000\n",
      "lr 8.600000e-06 reg 4.110000e+03 train accuracy: 0.278878 val accuracy: 0.303000\n",
      "lr 8.600000e-06 reg 4.210000e+03 train accuracy: 0.264551 val accuracy: 0.253000\n",
      "lr 8.600000e-06 reg 4.310000e+03 train accuracy: 0.238673 val accuracy: 0.254000\n",
      "lr 8.600000e-06 reg 4.410000e+03 train accuracy: 0.274878 val accuracy: 0.273000\n",
      "lr 8.600000e-06 reg 4.510000e+03 train accuracy: 0.234857 val accuracy: 0.246000\n",
      "lr 8.600000e-06 reg 4.610000e+03 train accuracy: 0.227551 val accuracy: 0.241000\n",
      "lr 8.600000e-06 reg 4.710000e+03 train accuracy: 0.243959 val accuracy: 0.243000\n",
      "lr 8.600000e-06 reg 4.810000e+03 train accuracy: 0.191980 val accuracy: 0.205000\n",
      "lr 8.600000e-06 reg 4.910000e+03 train accuracy: 0.284347 val accuracy: 0.310000\n",
      "lr 8.600000e-06 reg 5.010000e+03 train accuracy: 0.211939 val accuracy: 0.207000\n",
      "lr 8.600000e-06 reg 5.110000e+03 train accuracy: 0.207286 val accuracy: 0.230000\n",
      "lr 8.600000e-06 reg 5.210000e+03 train accuracy: 0.233735 val accuracy: 0.242000\n",
      "lr 8.600000e-06 reg 5.310000e+03 train accuracy: 0.265020 val accuracy: 0.266000\n",
      "lr 8.600000e-06 reg 5.410000e+03 train accuracy: 0.250469 val accuracy: 0.250000\n",
      "lr 8.600000e-06 reg 5.510000e+03 train accuracy: 0.260122 val accuracy: 0.253000\n",
      "lr 8.600000e-06 reg 5.610000e+03 train accuracy: 0.225102 val accuracy: 0.225000\n",
      "lr 8.600000e-06 reg 5.710000e+03 train accuracy: 0.263184 val accuracy: 0.263000\n",
      "lr 8.600000e-06 reg 5.810000e+03 train accuracy: 0.231837 val accuracy: 0.234000\n",
      "lr 8.600000e-06 reg 5.910000e+03 train accuracy: 0.251898 val accuracy: 0.257000\n",
      "lr 8.600000e-06 reg 6.010000e+03 train accuracy: 0.220735 val accuracy: 0.249000\n",
      "lr 8.600000e-06 reg 6.110000e+03 train accuracy: 0.248878 val accuracy: 0.271000\n",
      "lr 8.600000e-06 reg 6.210000e+03 train accuracy: 0.250531 val accuracy: 0.266000\n",
      "lr 8.600000e-06 reg 6.310000e+03 train accuracy: 0.242898 val accuracy: 0.244000\n",
      "lr 8.600000e-06 reg 6.410000e+03 train accuracy: 0.221816 val accuracy: 0.231000\n",
      "lr 8.600000e-06 reg 6.510000e+03 train accuracy: 0.248980 val accuracy: 0.261000\n",
      "lr 8.600000e-06 reg 6.610000e+03 train accuracy: 0.206939 val accuracy: 0.217000\n",
      "lr 8.600000e-06 reg 6.710000e+03 train accuracy: 0.238388 val accuracy: 0.253000\n",
      "lr 8.600000e-06 reg 6.810000e+03 train accuracy: 0.253469 val accuracy: 0.253000\n",
      "lr 8.600000e-06 reg 6.910000e+03 train accuracy: 0.199837 val accuracy: 0.207000\n",
      "lr 8.600000e-06 reg 7.010000e+03 train accuracy: 0.280653 val accuracy: 0.297000\n",
      "lr 8.600000e-06 reg 7.110000e+03 train accuracy: 0.211327 val accuracy: 0.238000\n",
      "lr 8.600000e-06 reg 7.210000e+03 train accuracy: 0.229735 val accuracy: 0.243000\n",
      "lr 8.600000e-06 reg 7.310000e+03 train accuracy: 0.215469 val accuracy: 0.227000\n",
      "lr 8.600000e-06 reg 7.410000e+03 train accuracy: 0.206878 val accuracy: 0.231000\n",
      "lr 8.600000e-06 reg 7.510000e+03 train accuracy: 0.224224 val accuracy: 0.233000\n",
      "lr 8.600000e-06 reg 7.610000e+03 train accuracy: 0.235163 val accuracy: 0.234000\n",
      "lr 8.600000e-06 reg 7.710000e+03 train accuracy: 0.271102 val accuracy: 0.285000\n",
      "lr 8.600000e-06 reg 7.810000e+03 train accuracy: 0.194367 val accuracy: 0.201000\n",
      "lr 8.600000e-06 reg 7.910000e+03 train accuracy: 0.239041 val accuracy: 0.247000\n",
      "lr 8.600000e-06 reg 8.010000e+03 train accuracy: 0.208653 val accuracy: 0.221000\n",
      "lr 8.600000e-06 reg 8.110000e+03 train accuracy: 0.249714 val accuracy: 0.252000\n",
      "lr 8.600000e-06 reg 8.210000e+03 train accuracy: 0.173755 val accuracy: 0.184000\n",
      "lr 8.600000e-06 reg 8.310000e+03 train accuracy: 0.247633 val accuracy: 0.266000\n",
      "lr 8.600000e-06 reg 8.410000e+03 train accuracy: 0.252041 val accuracy: 0.261000\n",
      "lr 8.600000e-06 reg 8.510000e+03 train accuracy: 0.233673 val accuracy: 0.254000\n",
      "lr 8.600000e-06 reg 8.610000e+03 train accuracy: 0.257184 val accuracy: 0.281000\n",
      "lr 8.600000e-06 reg 8.710000e+03 train accuracy: 0.243347 val accuracy: 0.257000\n",
      "lr 8.600000e-06 reg 8.810000e+03 train accuracy: 0.229449 val accuracy: 0.231000\n",
      "lr 8.600000e-06 reg 8.910000e+03 train accuracy: 0.250449 val accuracy: 0.251000\n",
      "lr 8.600000e-06 reg 9.010000e+03 train accuracy: 0.188184 val accuracy: 0.191000\n",
      "lr 8.600000e-06 reg 9.110000e+03 train accuracy: 0.190102 val accuracy: 0.185000\n",
      "lr 8.600000e-06 reg 9.210000e+03 train accuracy: 0.190612 val accuracy: 0.196000\n",
      "lr 8.600000e-06 reg 9.310000e+03 train accuracy: 0.198633 val accuracy: 0.217000\n",
      "lr 8.600000e-06 reg 9.410000e+03 train accuracy: 0.221408 val accuracy: 0.233000\n",
      "lr 8.600000e-06 reg 9.510000e+03 train accuracy: 0.231816 val accuracy: 0.226000\n",
      "lr 8.600000e-06 reg 9.610000e+03 train accuracy: 0.185592 val accuracy: 0.176000\n",
      "lr 8.600000e-06 reg 9.710000e+03 train accuracy: 0.233939 val accuracy: 0.242000\n",
      "lr 8.600000e-06 reg 9.810000e+03 train accuracy: 0.227163 val accuracy: 0.235000\n",
      "lr 8.600000e-06 reg 9.910000e+03 train accuracy: 0.181469 val accuracy: 0.180000\n",
      "lr 9.100000e-06 reg 1.000000e+01 train accuracy: 0.352551 val accuracy: 0.352000\n",
      "lr 9.100000e-06 reg 1.100000e+02 train accuracy: 0.337367 val accuracy: 0.348000\n",
      "lr 9.100000e-06 reg 2.100000e+02 train accuracy: 0.346347 val accuracy: 0.342000\n",
      "lr 9.100000e-06 reg 3.100000e+02 train accuracy: 0.305939 val accuracy: 0.325000\n",
      "lr 9.100000e-06 reg 4.100000e+02 train accuracy: 0.321041 val accuracy: 0.323000\n",
      "lr 9.100000e-06 reg 5.100000e+02 train accuracy: 0.275367 val accuracy: 0.283000\n",
      "lr 9.100000e-06 reg 6.100000e+02 train accuracy: 0.317388 val accuracy: 0.343000\n",
      "lr 9.100000e-06 reg 7.100000e+02 train accuracy: 0.276510 val accuracy: 0.289000\n",
      "lr 9.100000e-06 reg 8.100000e+02 train accuracy: 0.287939 val accuracy: 0.283000\n",
      "lr 9.100000e-06 reg 9.100000e+02 train accuracy: 0.259122 val accuracy: 0.268000\n",
      "lr 9.100000e-06 reg 1.010000e+03 train accuracy: 0.275816 val accuracy: 0.275000\n",
      "lr 9.100000e-06 reg 1.110000e+03 train accuracy: 0.253939 val accuracy: 0.250000\n",
      "lr 9.100000e-06 reg 1.210000e+03 train accuracy: 0.307531 val accuracy: 0.307000\n",
      "lr 9.100000e-06 reg 1.310000e+03 train accuracy: 0.279449 val accuracy: 0.281000\n",
      "lr 9.100000e-06 reg 1.410000e+03 train accuracy: 0.256735 val accuracy: 0.264000\n",
      "lr 9.100000e-06 reg 1.510000e+03 train accuracy: 0.251531 val accuracy: 0.256000\n",
      "lr 9.100000e-06 reg 1.610000e+03 train accuracy: 0.263020 val accuracy: 0.253000\n",
      "lr 9.100000e-06 reg 1.710000e+03 train accuracy: 0.234510 val accuracy: 0.242000\n",
      "lr 9.100000e-06 reg 1.810000e+03 train accuracy: 0.298551 val accuracy: 0.299000\n",
      "lr 9.100000e-06 reg 1.910000e+03 train accuracy: 0.270959 val accuracy: 0.256000\n",
      "lr 9.100000e-06 reg 2.010000e+03 train accuracy: 0.325306 val accuracy: 0.332000\n",
      "lr 9.100000e-06 reg 2.110000e+03 train accuracy: 0.293122 val accuracy: 0.286000\n",
      "lr 9.100000e-06 reg 2.210000e+03 train accuracy: 0.263041 val accuracy: 0.279000\n",
      "lr 9.100000e-06 reg 2.310000e+03 train accuracy: 0.243041 val accuracy: 0.244000\n",
      "lr 9.100000e-06 reg 2.410000e+03 train accuracy: 0.286673 val accuracy: 0.293000\n",
      "lr 9.100000e-06 reg 2.510000e+03 train accuracy: 0.233531 val accuracy: 0.258000\n",
      "lr 9.100000e-06 reg 2.610000e+03 train accuracy: 0.271184 val accuracy: 0.282000\n",
      "lr 9.100000e-06 reg 2.710000e+03 train accuracy: 0.271122 val accuracy: 0.256000\n",
      "lr 9.100000e-06 reg 2.810000e+03 train accuracy: 0.253673 val accuracy: 0.249000\n",
      "lr 9.100000e-06 reg 2.910000e+03 train accuracy: 0.208388 val accuracy: 0.223000\n",
      "lr 9.100000e-06 reg 3.010000e+03 train accuracy: 0.263878 val accuracy: 0.262000\n",
      "lr 9.100000e-06 reg 3.110000e+03 train accuracy: 0.229122 val accuracy: 0.208000\n",
      "lr 9.100000e-06 reg 3.210000e+03 train accuracy: 0.279490 val accuracy: 0.269000\n",
      "lr 9.100000e-06 reg 3.310000e+03 train accuracy: 0.242571 val accuracy: 0.235000\n",
      "lr 9.100000e-06 reg 3.410000e+03 train accuracy: 0.218306 val accuracy: 0.204000\n",
      "lr 9.100000e-06 reg 3.510000e+03 train accuracy: 0.309673 val accuracy: 0.316000\n",
      "lr 9.100000e-06 reg 3.610000e+03 train accuracy: 0.239673 val accuracy: 0.225000\n",
      "lr 9.100000e-06 reg 3.710000e+03 train accuracy: 0.196163 val accuracy: 0.188000\n",
      "lr 9.100000e-06 reg 3.810000e+03 train accuracy: 0.278102 val accuracy: 0.272000\n",
      "lr 9.100000e-06 reg 3.910000e+03 train accuracy: 0.262020 val accuracy: 0.256000\n",
      "lr 9.100000e-06 reg 4.010000e+03 train accuracy: 0.254388 val accuracy: 0.289000\n",
      "lr 9.100000e-06 reg 4.110000e+03 train accuracy: 0.218245 val accuracy: 0.217000\n",
      "lr 9.100000e-06 reg 4.210000e+03 train accuracy: 0.274143 val accuracy: 0.280000\n",
      "lr 9.100000e-06 reg 4.310000e+03 train accuracy: 0.257816 val accuracy: 0.254000\n",
      "lr 9.100000e-06 reg 4.410000e+03 train accuracy: 0.228245 val accuracy: 0.243000\n",
      "lr 9.100000e-06 reg 4.510000e+03 train accuracy: 0.255429 val accuracy: 0.280000\n",
      "lr 9.100000e-06 reg 4.610000e+03 train accuracy: 0.249490 val accuracy: 0.253000\n",
      "lr 9.100000e-06 reg 4.710000e+03 train accuracy: 0.207163 val accuracy: 0.211000\n",
      "lr 9.100000e-06 reg 4.810000e+03 train accuracy: 0.232367 val accuracy: 0.230000\n",
      "lr 9.100000e-06 reg 4.910000e+03 train accuracy: 0.215857 val accuracy: 0.215000\n",
      "lr 9.100000e-06 reg 5.010000e+03 train accuracy: 0.262429 val accuracy: 0.277000\n",
      "lr 9.100000e-06 reg 5.110000e+03 train accuracy: 0.221347 val accuracy: 0.225000\n",
      "lr 9.100000e-06 reg 5.210000e+03 train accuracy: 0.215306 val accuracy: 0.235000\n",
      "lr 9.100000e-06 reg 5.310000e+03 train accuracy: 0.241367 val accuracy: 0.252000\n",
      "lr 9.100000e-06 reg 5.410000e+03 train accuracy: 0.243306 val accuracy: 0.260000\n",
      "lr 9.100000e-06 reg 5.510000e+03 train accuracy: 0.254694 val accuracy: 0.231000\n",
      "lr 9.100000e-06 reg 5.610000e+03 train accuracy: 0.222204 val accuracy: 0.225000\n",
      "lr 9.100000e-06 reg 5.710000e+03 train accuracy: 0.223184 val accuracy: 0.212000\n",
      "lr 9.100000e-06 reg 5.810000e+03 train accuracy: 0.259163 val accuracy: 0.275000\n",
      "lr 9.100000e-06 reg 5.910000e+03 train accuracy: 0.239673 val accuracy: 0.239000\n",
      "lr 9.100000e-06 reg 6.010000e+03 train accuracy: 0.281816 val accuracy: 0.283000\n",
      "lr 9.100000e-06 reg 6.110000e+03 train accuracy: 0.204082 val accuracy: 0.204000\n",
      "lr 9.100000e-06 reg 6.210000e+03 train accuracy: 0.236939 val accuracy: 0.239000\n",
      "lr 9.100000e-06 reg 6.310000e+03 train accuracy: 0.250143 val accuracy: 0.272000\n",
      "lr 9.100000e-06 reg 6.410000e+03 train accuracy: 0.221633 val accuracy: 0.231000\n",
      "lr 9.100000e-06 reg 6.510000e+03 train accuracy: 0.244204 val accuracy: 0.252000\n",
      "lr 9.100000e-06 reg 6.610000e+03 train accuracy: 0.235429 val accuracy: 0.234000\n",
      "lr 9.100000e-06 reg 6.710000e+03 train accuracy: 0.187204 val accuracy: 0.200000\n",
      "lr 9.100000e-06 reg 6.810000e+03 train accuracy: 0.247122 val accuracy: 0.258000\n",
      "lr 9.100000e-06 reg 6.910000e+03 train accuracy: 0.273837 val accuracy: 0.275000\n",
      "lr 9.100000e-06 reg 7.010000e+03 train accuracy: 0.263735 val accuracy: 0.281000\n",
      "lr 9.100000e-06 reg 7.110000e+03 train accuracy: 0.275510 val accuracy: 0.276000\n",
      "lr 9.100000e-06 reg 7.210000e+03 train accuracy: 0.224633 val accuracy: 0.242000\n",
      "lr 9.100000e-06 reg 7.310000e+03 train accuracy: 0.223163 val accuracy: 0.227000\n",
      "lr 9.100000e-06 reg 7.410000e+03 train accuracy: 0.248980 val accuracy: 0.239000\n",
      "lr 9.100000e-06 reg 7.510000e+03 train accuracy: 0.200163 val accuracy: 0.221000\n",
      "lr 9.100000e-06 reg 7.610000e+03 train accuracy: 0.170082 val accuracy: 0.179000\n",
      "lr 9.100000e-06 reg 7.710000e+03 train accuracy: 0.217796 val accuracy: 0.217000\n",
      "lr 9.100000e-06 reg 7.810000e+03 train accuracy: 0.235367 val accuracy: 0.246000\n",
      "lr 9.100000e-06 reg 7.910000e+03 train accuracy: 0.227735 val accuracy: 0.213000\n",
      "lr 9.100000e-06 reg 8.010000e+03 train accuracy: 0.196327 val accuracy: 0.199000\n",
      "lr 9.100000e-06 reg 8.110000e+03 train accuracy: 0.250245 val accuracy: 0.279000\n",
      "lr 9.100000e-06 reg 8.210000e+03 train accuracy: 0.249571 val accuracy: 0.256000\n",
      "lr 9.100000e-06 reg 8.310000e+03 train accuracy: 0.167633 val accuracy: 0.167000\n",
      "lr 9.100000e-06 reg 8.410000e+03 train accuracy: 0.183857 val accuracy: 0.198000\n",
      "lr 9.100000e-06 reg 8.510000e+03 train accuracy: 0.229980 val accuracy: 0.235000\n",
      "lr 9.100000e-06 reg 8.610000e+03 train accuracy: 0.234306 val accuracy: 0.253000\n",
      "lr 9.100000e-06 reg 8.710000e+03 train accuracy: 0.231612 val accuracy: 0.260000\n",
      "lr 9.100000e-06 reg 8.810000e+03 train accuracy: 0.223449 val accuracy: 0.255000\n",
      "lr 9.100000e-06 reg 8.910000e+03 train accuracy: 0.159878 val accuracy: 0.178000\n",
      "lr 9.100000e-06 reg 9.010000e+03 train accuracy: 0.145633 val accuracy: 0.155000\n",
      "lr 9.100000e-06 reg 9.110000e+03 train accuracy: 0.187857 val accuracy: 0.203000\n",
      "lr 9.100000e-06 reg 9.210000e+03 train accuracy: 0.262061 val accuracy: 0.264000\n",
      "lr 9.100000e-06 reg 9.310000e+03 train accuracy: 0.194592 val accuracy: 0.205000\n",
      "lr 9.100000e-06 reg 9.410000e+03 train accuracy: 0.209714 val accuracy: 0.210000\n",
      "lr 9.100000e-06 reg 9.510000e+03 train accuracy: 0.200224 val accuracy: 0.213000\n",
      "lr 9.100000e-06 reg 9.610000e+03 train accuracy: 0.164469 val accuracy: 0.173000\n",
      "lr 9.100000e-06 reg 9.710000e+03 train accuracy: 0.219061 val accuracy: 0.217000\n",
      "lr 9.100000e-06 reg 9.810000e+03 train accuracy: 0.228388 val accuracy: 0.240000\n",
      "lr 9.100000e-06 reg 9.910000e+03 train accuracy: 0.277102 val accuracy: 0.280000\n",
      "lr 9.600000e-06 reg 1.000000e+01 train accuracy: 0.322122 val accuracy: 0.335000\n",
      "lr 9.600000e-06 reg 1.100000e+02 train accuracy: 0.338041 val accuracy: 0.323000\n",
      "lr 9.600000e-06 reg 2.100000e+02 train accuracy: 0.304143 val accuracy: 0.294000\n",
      "lr 9.600000e-06 reg 3.100000e+02 train accuracy: 0.254469 val accuracy: 0.262000\n",
      "lr 9.600000e-06 reg 4.100000e+02 train accuracy: 0.352939 val accuracy: 0.328000\n",
      "lr 9.600000e-06 reg 5.100000e+02 train accuracy: 0.305918 val accuracy: 0.333000\n",
      "lr 9.600000e-06 reg 6.100000e+02 train accuracy: 0.246980 val accuracy: 0.266000\n",
      "lr 9.600000e-06 reg 7.100000e+02 train accuracy: 0.313245 val accuracy: 0.304000\n",
      "lr 9.600000e-06 reg 8.100000e+02 train accuracy: 0.260755 val accuracy: 0.253000\n",
      "lr 9.600000e-06 reg 9.100000e+02 train accuracy: 0.267633 val accuracy: 0.275000\n",
      "lr 9.600000e-06 reg 1.010000e+03 train accuracy: 0.246898 val accuracy: 0.258000\n",
      "lr 9.600000e-06 reg 1.110000e+03 train accuracy: 0.296469 val accuracy: 0.305000\n",
      "lr 9.600000e-06 reg 1.210000e+03 train accuracy: 0.268796 val accuracy: 0.272000\n",
      "lr 9.600000e-06 reg 1.310000e+03 train accuracy: 0.254408 val accuracy: 0.237000\n",
      "lr 9.600000e-06 reg 1.410000e+03 train accuracy: 0.211245 val accuracy: 0.219000\n",
      "lr 9.600000e-06 reg 1.510000e+03 train accuracy: 0.270367 val accuracy: 0.281000\n",
      "lr 9.600000e-06 reg 1.610000e+03 train accuracy: 0.245898 val accuracy: 0.265000\n",
      "lr 9.600000e-06 reg 1.710000e+03 train accuracy: 0.298265 val accuracy: 0.322000\n",
      "lr 9.600000e-06 reg 1.810000e+03 train accuracy: 0.286020 val accuracy: 0.280000\n",
      "lr 9.600000e-06 reg 1.910000e+03 train accuracy: 0.275347 val accuracy: 0.281000\n",
      "lr 9.600000e-06 reg 2.010000e+03 train accuracy: 0.203367 val accuracy: 0.211000\n",
      "lr 9.600000e-06 reg 2.110000e+03 train accuracy: 0.283837 val accuracy: 0.299000\n",
      "lr 9.600000e-06 reg 2.210000e+03 train accuracy: 0.232898 val accuracy: 0.229000\n",
      "lr 9.600000e-06 reg 2.310000e+03 train accuracy: 0.278469 val accuracy: 0.270000\n",
      "lr 9.600000e-06 reg 2.410000e+03 train accuracy: 0.277184 val accuracy: 0.310000\n",
      "lr 9.600000e-06 reg 2.510000e+03 train accuracy: 0.245143 val accuracy: 0.241000\n",
      "lr 9.600000e-06 reg 2.610000e+03 train accuracy: 0.223163 val accuracy: 0.246000\n",
      "lr 9.600000e-06 reg 2.710000e+03 train accuracy: 0.221673 val accuracy: 0.228000\n",
      "lr 9.600000e-06 reg 2.810000e+03 train accuracy: 0.248939 val accuracy: 0.253000\n",
      "lr 9.600000e-06 reg 2.910000e+03 train accuracy: 0.238571 val accuracy: 0.236000\n",
      "lr 9.600000e-06 reg 3.010000e+03 train accuracy: 0.271816 val accuracy: 0.305000\n",
      "lr 9.600000e-06 reg 3.110000e+03 train accuracy: 0.221449 val accuracy: 0.243000\n",
      "lr 9.600000e-06 reg 3.210000e+03 train accuracy: 0.230408 val accuracy: 0.229000\n",
      "lr 9.600000e-06 reg 3.310000e+03 train accuracy: 0.215306 val accuracy: 0.214000\n",
      "lr 9.600000e-06 reg 3.410000e+03 train accuracy: 0.254000 val accuracy: 0.241000\n",
      "lr 9.600000e-06 reg 3.510000e+03 train accuracy: 0.250306 val accuracy: 0.253000\n",
      "lr 9.600000e-06 reg 3.610000e+03 train accuracy: 0.192000 val accuracy: 0.205000\n",
      "lr 9.600000e-06 reg 3.710000e+03 train accuracy: 0.177163 val accuracy: 0.179000\n",
      "lr 9.600000e-06 reg 3.810000e+03 train accuracy: 0.230980 val accuracy: 0.237000\n",
      "lr 9.600000e-06 reg 3.910000e+03 train accuracy: 0.260020 val accuracy: 0.263000\n",
      "lr 9.600000e-06 reg 4.010000e+03 train accuracy: 0.256776 val accuracy: 0.271000\n",
      "lr 9.600000e-06 reg 4.110000e+03 train accuracy: 0.224857 val accuracy: 0.220000\n",
      "lr 9.600000e-06 reg 4.210000e+03 train accuracy: 0.261755 val accuracy: 0.286000\n",
      "lr 9.600000e-06 reg 4.310000e+03 train accuracy: 0.237592 val accuracy: 0.229000\n",
      "lr 9.600000e-06 reg 4.410000e+03 train accuracy: 0.215531 val accuracy: 0.197000\n",
      "lr 9.600000e-06 reg 4.510000e+03 train accuracy: 0.246612 val accuracy: 0.231000\n",
      "lr 9.600000e-06 reg 4.610000e+03 train accuracy: 0.190878 val accuracy: 0.193000\n",
      "lr 9.600000e-06 reg 4.710000e+03 train accuracy: 0.270245 val accuracy: 0.268000\n",
      "lr 9.600000e-06 reg 4.810000e+03 train accuracy: 0.214327 val accuracy: 0.233000\n",
      "lr 9.600000e-06 reg 4.910000e+03 train accuracy: 0.236163 val accuracy: 0.236000\n",
      "lr 9.600000e-06 reg 5.010000e+03 train accuracy: 0.258531 val accuracy: 0.263000\n",
      "lr 9.600000e-06 reg 5.110000e+03 train accuracy: 0.238735 val accuracy: 0.247000\n",
      "lr 9.600000e-06 reg 5.210000e+03 train accuracy: 0.268490 val accuracy: 0.254000\n",
      "lr 9.600000e-06 reg 5.310000e+03 train accuracy: 0.251143 val accuracy: 0.271000\n",
      "lr 9.600000e-06 reg 5.410000e+03 train accuracy: 0.243714 val accuracy: 0.232000\n",
      "lr 9.600000e-06 reg 5.510000e+03 train accuracy: 0.249980 val accuracy: 0.254000\n",
      "lr 9.600000e-06 reg 5.610000e+03 train accuracy: 0.285000 val accuracy: 0.309000\n",
      "lr 9.600000e-06 reg 5.710000e+03 train accuracy: 0.231265 val accuracy: 0.222000\n",
      "lr 9.600000e-06 reg 5.810000e+03 train accuracy: 0.194204 val accuracy: 0.202000\n",
      "lr 9.600000e-06 reg 5.910000e+03 train accuracy: 0.241776 val accuracy: 0.246000\n",
      "lr 9.600000e-06 reg 6.010000e+03 train accuracy: 0.181918 val accuracy: 0.185000\n",
      "lr 9.600000e-06 reg 6.110000e+03 train accuracy: 0.164347 val accuracy: 0.155000\n",
      "lr 9.600000e-06 reg 6.210000e+03 train accuracy: 0.177082 val accuracy: 0.176000\n",
      "lr 9.600000e-06 reg 6.310000e+03 train accuracy: 0.211776 val accuracy: 0.233000\n",
      "lr 9.600000e-06 reg 6.410000e+03 train accuracy: 0.164286 val accuracy: 0.156000\n",
      "lr 9.600000e-06 reg 6.510000e+03 train accuracy: 0.188041 val accuracy: 0.203000\n",
      "lr 9.600000e-06 reg 6.610000e+03 train accuracy: 0.205571 val accuracy: 0.222000\n",
      "lr 9.600000e-06 reg 6.710000e+03 train accuracy: 0.205408 val accuracy: 0.222000\n",
      "lr 9.600000e-06 reg 6.810000e+03 train accuracy: 0.242551 val accuracy: 0.252000\n",
      "lr 9.600000e-06 reg 6.910000e+03 train accuracy: 0.260184 val accuracy: 0.275000\n",
      "lr 9.600000e-06 reg 7.010000e+03 train accuracy: 0.217857 val accuracy: 0.217000\n",
      "lr 9.600000e-06 reg 7.110000e+03 train accuracy: 0.251041 val accuracy: 0.267000\n",
      "lr 9.600000e-06 reg 7.210000e+03 train accuracy: 0.242041 val accuracy: 0.228000\n",
      "lr 9.600000e-06 reg 7.310000e+03 train accuracy: 0.179857 val accuracy: 0.154000\n",
      "lr 9.600000e-06 reg 7.410000e+03 train accuracy: 0.207041 val accuracy: 0.211000\n",
      "lr 9.600000e-06 reg 7.510000e+03 train accuracy: 0.214041 val accuracy: 0.226000\n",
      "lr 9.600000e-06 reg 7.610000e+03 train accuracy: 0.219367 val accuracy: 0.247000\n",
      "lr 9.600000e-06 reg 7.710000e+03 train accuracy: 0.217878 val accuracy: 0.231000\n",
      "lr 9.600000e-06 reg 7.810000e+03 train accuracy: 0.223878 val accuracy: 0.219000\n",
      "lr 9.600000e-06 reg 7.910000e+03 train accuracy: 0.167082 val accuracy: 0.174000\n",
      "lr 9.600000e-06 reg 8.010000e+03 train accuracy: 0.234245 val accuracy: 0.247000\n",
      "lr 9.600000e-06 reg 8.110000e+03 train accuracy: 0.220898 val accuracy: 0.220000\n",
      "lr 9.600000e-06 reg 8.210000e+03 train accuracy: 0.225449 val accuracy: 0.240000\n",
      "lr 9.600000e-06 reg 8.310000e+03 train accuracy: 0.216102 val accuracy: 0.230000\n",
      "lr 9.600000e-06 reg 8.410000e+03 train accuracy: 0.217714 val accuracy: 0.208000\n",
      "lr 9.600000e-06 reg 8.510000e+03 train accuracy: 0.214286 val accuracy: 0.224000\n",
      "lr 9.600000e-06 reg 8.610000e+03 train accuracy: 0.189878 val accuracy: 0.196000\n",
      "lr 9.600000e-06 reg 8.710000e+03 train accuracy: 0.210531 val accuracy: 0.207000\n",
      "lr 9.600000e-06 reg 8.810000e+03 train accuracy: 0.225980 val accuracy: 0.250000\n",
      "lr 9.600000e-06 reg 8.910000e+03 train accuracy: 0.196673 val accuracy: 0.221000\n",
      "lr 9.600000e-06 reg 9.010000e+03 train accuracy: 0.236531 val accuracy: 0.256000\n",
      "lr 9.600000e-06 reg 9.110000e+03 train accuracy: 0.198918 val accuracy: 0.201000\n",
      "lr 9.600000e-06 reg 9.210000e+03 train accuracy: 0.179673 val accuracy: 0.174000\n",
      "lr 9.600000e-06 reg 9.310000e+03 train accuracy: 0.210531 val accuracy: 0.218000\n",
      "lr 9.600000e-06 reg 9.410000e+03 train accuracy: 0.190469 val accuracy: 0.190000\n",
      "lr 9.600000e-06 reg 9.510000e+03 train accuracy: 0.208245 val accuracy: 0.217000\n",
      "lr 9.600000e-06 reg 9.610000e+03 train accuracy: 0.172959 val accuracy: 0.193000\n",
      "lr 9.600000e-06 reg 9.710000e+03 train accuracy: 0.216571 val accuracy: 0.217000\n",
      "lr 9.600000e-06 reg 9.810000e+03 train accuracy: 0.219755 val accuracy: 0.228000\n",
      "lr 9.600000e-06 reg 9.910000e+03 train accuracy: 0.255592 val accuracy: 0.244000\n",
      "best validation accuracy achieved during cross-validation: 0.415000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "from cs231n.classifiers import Softmax\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "learning_rates = list(np.arange(1e-7,1e-5,5e-7))\n",
    "regularization_strengths = list(np.arange(1e1, 1e4,1e2))\n",
    "#import pdb; pdb.set_trace()\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "for lr in learning_rates:\n",
    "    for rs in regularization_strengths:\n",
    "        softmax  = Softmax()\n",
    "        loss_hist = softmax.train(X_train, y_train, lr, rs, num_iters=1000, verbose=False)\n",
    "        y_train_pred = softmax.predict(X_train)\n",
    "        y_val_pred = softmax.predict(X_val)\n",
    "        acc_train = np.mean(y_train == y_train_pred)\n",
    "        acc_val = np.mean(y_val == y_val_pred)\n",
    "        results[(lr,rs)] = [acc_train, acc_val]\n",
    "        if acc_val> best_val:\n",
    "            best_val = acc_val\n",
    "            best_svm = softmax   #committed an error of writing best_softmax as best_svm\n",
    "        print(lr,rs, results[(lr,rs)])       \n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.380000\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_svm.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inline Question** - *True or False*\n",
    "\n",
    "It's possible to add a new datapoint to a training set that would leave the SVM loss unchanged, but this is not the case with the Softmax classifier loss.\n",
    "\n",
    "*Your answer*:\n",
    "\n",
    "*Your explanation*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAF8CAYAAADrUz6WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6kBepgRBEARBEOrgfwHD0K0e6OczCQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110675320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_svm.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
